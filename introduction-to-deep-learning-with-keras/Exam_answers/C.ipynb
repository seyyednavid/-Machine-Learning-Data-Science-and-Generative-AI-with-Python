{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yJ-KXr6djOzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8e8c2d88-d01f-4d03-863a-eae15720886b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==2.0.2\n",
            "  Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "scikit-learn 1.3.1 requires numpy<2.0,>=1.17.3, but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.1 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.18.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Requirement already satisfied: tensorflow_cpu==2.18.0 in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_cpu==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow_cpu==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn==1.3.1 in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Collecting numpy<2.0,>=1.17.3 (from scikit-learn==1.3.1)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (3.5.0)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "# All Libraries required\n",
        "\n",
        "!pip install numpy==2.0.2\n",
        "!pip install pandas==2.2.2\n",
        "!pip install tensorflow_cpu==2.18.0\n",
        "!pip install scikit-learn==1.3.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "DxKPklj2StPH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ML/concrete_data.csv\")"
      ],
      "metadata": {
        "id": "E6PYU7rxSz1c"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and target\n",
        "X = data.drop(columns=[\"Strength\"])\n",
        "y = data[\"Strength\"]"
      ],
      "metadata": {
        "id": "EvCrC4ebUoOH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the predictors manually using the formula\n",
        "X_normalized = (X - X.mean()) / X.std()"
      ],
      "metadata": {
        "id": "rrz63dZcbQLs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zhCIpzuqbXOE",
        "outputId": "5b821d3a-3e4d-413c-fa70-3296476336e4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
            "0     2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
            "1     2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
            "2     0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
            "3     0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
            "4    -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
            "...        ...                 ...       ...       ...               ...   \n",
            "1025 -0.045623            0.487998  0.564271 -0.092126          0.451190   \n",
            "1026  0.392628           -0.856472  0.959602  0.675872          0.702285   \n",
            "1027 -1.269472            0.759210  0.850222  0.521336         -0.017520   \n",
            "1028 -1.168042            1.307430 -0.846733 -0.279443          0.852942   \n",
            "1029 -0.193939            0.308349  0.376762  0.891286          0.400971   \n",
            "\n",
            "      Coarse Aggregate  Fine Aggregate       Age  \n",
            "0             0.862735       -1.217079 -0.279597  \n",
            "1             1.055651       -1.217079 -0.279597  \n",
            "2            -0.526262       -2.239829  3.551340  \n",
            "3            -0.526262       -2.239829  5.055221  \n",
            "4             0.070492        0.647569  4.976069  \n",
            "...                ...             ...       ...  \n",
            "1025         -1.322363       -0.065861 -0.279597  \n",
            "1026         -1.993711        0.496651 -0.279597  \n",
            "1027         -1.035561        0.080068 -0.279597  \n",
            "1028          0.214537        0.191074 -0.279597  \n",
            "1029         -1.394385       -0.150675 -0.279597  \n",
            "\n",
            "[1030 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize list to store MSE values\n",
        "mse_list = []\n",
        "\n",
        "# Repeat 50 times\n",
        "for _ in range(50):\n",
        "    # 1. Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=np.random.randint(0, 1000))\n",
        "\n",
        "    # 2. Build the model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=10, verbose=2)\n",
        "\n",
        "    # 3. Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Store MSE\n",
        "    mse_list.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a_9uGoLcVDuw",
        "outputId": "3b233607-104e-469e-f595-7ea9a820260e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1634.6860 - val_loss: 1479.5114\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1594.3662 - val_loss: 1445.5970\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1558.6063 - val_loss: 1413.5592\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1521.5579 - val_loss: 1377.9753\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1480.6033 - val_loss: 1337.4692\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1432.9224 - val_loss: 1289.8729\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1377.4747 - val_loss: 1236.4517\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 2ms/step - loss: 1315.8844 - val_loss: 1177.7065\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1247.9115 - val_loss: 1113.5631\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 5ms/step - loss: 1176.2360 - val_loss: 1046.7496\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 1097.3192 - val_loss: 973.2015\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 1009.9346 - val_loss: 892.9365\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 917.4434 - val_loss: 809.5549\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 821.0396 - val_loss: 725.1516\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 722.9743 - val_loss: 642.8362\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 632.6123 - val_loss: 566.4954\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 550.2184 - val_loss: 495.3421\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 5ms/step - loss: 475.1568 - val_loss: 430.7587\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 409.4447 - val_loss: 373.8313\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 354.1063 - val_loss: 326.1354\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 5ms/step - loss: 308.8762 - val_loss: 284.9601\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 271.2612 - val_loss: 252.5873\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 244.3590 - val_loss: 227.7876\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 5ms/step - loss: 223.7677 - val_loss: 208.4149\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 209.0396 - val_loss: 193.5536\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 197.4877 - val_loss: 182.0450\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 189.2325 - val_loss: 173.5974\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 5ms/step - loss: 183.2300 - val_loss: 167.3565\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.5732 - val_loss: 162.2000\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.4382 - val_loss: 157.7464\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 170.8139 - val_loss: 154.2107\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 168.1466 - val_loss: 151.4585\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 5ms/step - loss: 165.4770 - val_loss: 149.0263\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 163.0268 - val_loss: 146.9242\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.9465 - val_loss: 144.9153\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.4662 - val_loss: 143.0706\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.4553 - val_loss: 140.9692\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 154.2538 - val_loss: 139.0779\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.2481 - val_loss: 137.2003\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 2ms/step - loss: 150.0513 - val_loss: 135.9523\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.2796 - val_loss: 134.8764\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.5819 - val_loss: 133.5020\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 144.8492 - val_loss: 132.1507\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.2984 - val_loss: 130.9715\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 5ms/step - loss: 141.7002 - val_loss: 129.7656\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.9881 - val_loss: 128.5727\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 5ms/step - loss: 138.3457 - val_loss: 127.4325\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.8245 - val_loss: 126.5231\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.0716 - val_loss: 125.2773\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 5ms/step - loss: 133.3612 - val_loss: 123.6811\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.4789 - val_loss: 122.8665\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.7694 - val_loss: 121.6637\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.0170 - val_loss: 120.3820\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 2ms/step - loss: 126.2841 - val_loss: 119.1545\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.7352 - val_loss: 118.0458\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.8619 - val_loss: 116.9147\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.1158 - val_loss: 116.0807\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.5835 - val_loss: 114.6444\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.8888 - val_loss: 113.0122\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.4447 - val_loss: 111.9861\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.9106 - val_loss: 110.6628\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.4266 - val_loss: 109.6018\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.0815 - val_loss: 108.3635\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.5746 - val_loss: 107.1848\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.2185 - val_loss: 106.0299\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.8738 - val_loss: 104.7670\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.4672 - val_loss: 103.6553\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.0489 - val_loss: 102.6891\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.8013 - val_loss: 101.4783\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.2811 - val_loss: 100.4443\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.0262 - val_loss: 99.3344\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.5024 - val_loss: 98.0839\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 5ms/step - loss: 98.0448 - val_loss: 96.9706\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.8093 - val_loss: 95.7494\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.6266 - val_loss: 94.6722\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.3175 - val_loss: 93.5732\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.1033 - val_loss: 92.4704\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.0868 - val_loss: 91.6000\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 90.9030 - val_loss: 90.5020\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.7603 - val_loss: 89.5983\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.7019 - val_loss: 88.7230\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.7124 - val_loss: 87.8938\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.7147 - val_loss: 86.9411\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.7682 - val_loss: 86.1391\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.8056 - val_loss: 85.3559\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.9744 - val_loss: 84.5750\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 83.3005 - val_loss: 83.8422\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.4777 - val_loss: 83.4029\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.6014 - val_loss: 82.9293\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.9624 - val_loss: 82.2253\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.3223 - val_loss: 81.6097\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 5ms/step - loss: 79.7587 - val_loss: 81.1836\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.1424 - val_loss: 80.6819\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.5931 - val_loss: 80.1120\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.9967 - val_loss: 79.3954\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.5482 - val_loss: 79.0158\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 2ms/step - loss: 77.0077 - val_loss: 78.4821\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.4277 - val_loss: 77.9945\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.9509 - val_loss: 77.4749\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 5ms/step - loss: 75.6047 - val_loss: 77.1686\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1569.0685 - val_loss: 1517.6445\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1522.5874 - val_loss: 1467.5442\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1473.9209 - val_loss: 1413.8564\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1419.7950 - val_loss: 1355.1818\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1360.9001 - val_loss: 1290.2123\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1295.8492 - val_loss: 1222.3352\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1226.9541 - val_loss: 1148.9733\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 5ms/step - loss: 1152.0651 - val_loss: 1072.5271\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1075.1205 - val_loss: 992.9958\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 2ms/step - loss: 995.2889 - val_loss: 910.9996\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 910.9402 - val_loss: 826.8669\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 828.1947 - val_loss: 745.0216\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 745.9061 - val_loss: 663.9512\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 5ms/step - loss: 662.5747 - val_loss: 583.5067\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 584.9288 - val_loss: 510.0222\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 513.0034 - val_loss: 443.3862\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 448.2702 - val_loss: 385.2154\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 392.4948 - val_loss: 336.5280\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 5ms/step - loss: 345.5023 - val_loss: 297.2205\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 307.9647 - val_loss: 266.5159\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 278.1174 - val_loss: 243.2256\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 254.9777 - val_loss: 225.3549\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 236.3906 - val_loss: 212.4159\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 3ms/step - loss: 222.0417 - val_loss: 202.0292\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 209.6589 - val_loss: 194.1121\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 200.4427 - val_loss: 187.7053\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 192.2429 - val_loss: 182.6001\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 185.6244 - val_loss: 178.3583\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 179.8874 - val_loss: 174.6527\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.8681 - val_loss: 171.1620\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 170.0973 - val_loss: 168.1382\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 166.0862 - val_loss: 165.4930\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.1776 - val_loss: 162.6975\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.6766 - val_loss: 160.0863\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.3192 - val_loss: 157.5900\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 152.0936 - val_loss: 155.3669\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.2162 - val_loss: 153.2355\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.4893 - val_loss: 150.6502\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 143.8022 - val_loss: 148.4615\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 2ms/step - loss: 141.4652 - val_loss: 146.7080\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.0120 - val_loss: 144.0838\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.7628 - val_loss: 142.1833\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 134.5399 - val_loss: 140.5966\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.4315 - val_loss: 138.8349\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 5ms/step - loss: 130.4235 - val_loss: 137.2791\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.3493 - val_loss: 135.3035\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.4710 - val_loss: 133.6124\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.5875 - val_loss: 132.1369\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 2ms/step - loss: 122.9588 - val_loss: 130.1701\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 121.4254 - val_loss: 128.8868\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 2ms/step - loss: 120.1221 - val_loss: 127.4579\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.4235 - val_loss: 126.5026\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.9953 - val_loss: 125.1741\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.5540 - val_loss: 123.8979\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.1441 - val_loss: 122.8577\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7752 - val_loss: 121.6795\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.5626 - val_loss: 120.6606\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.1888 - val_loss: 119.3517\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.8852 - val_loss: 118.0857\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 107.7025 - val_loss: 117.4160\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.5218 - val_loss: 116.1960\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.2289 - val_loss: 114.9359\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 2ms/step - loss: 104.0197 - val_loss: 113.8395\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 102.9141 - val_loss: 112.6488\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.6866 - val_loss: 111.4514\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.6129 - val_loss: 110.4472\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.4938 - val_loss: 109.3310\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.2436 - val_loss: 108.4037\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.2662 - val_loss: 107.6353\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 5ms/step - loss: 96.2733 - val_loss: 106.5334\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.2075 - val_loss: 105.3503\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.3977 - val_loss: 104.3915\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.5861 - val_loss: 103.8582\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.6033 - val_loss: 102.9966\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.6069 - val_loss: 101.8028\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 90.8887 - val_loss: 101.1187\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.1964 - val_loss: 100.4824\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 5ms/step - loss: 89.3420 - val_loss: 99.6042\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.5183 - val_loss: 98.9279\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.6349 - val_loss: 98.2736\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.9754 - val_loss: 97.3412\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 5ms/step - loss: 86.2422 - val_loss: 96.8216\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 7ms/step - loss: 85.5931 - val_loss: 96.0870\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 5ms/step - loss: 84.9642 - val_loss: 95.1860\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.3023 - val_loss: 94.5811\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 2ms/step - loss: 83.7702 - val_loss: 93.5998\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 2ms/step - loss: 83.1669 - val_loss: 93.2121\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.5119 - val_loss: 92.8840\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.0529 - val_loss: 92.2921\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.3967 - val_loss: 91.5549\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.9594 - val_loss: 90.7075\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.3796 - val_loss: 90.3175\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 79.9011 - val_loss: 89.5250\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 5ms/step - loss: 79.3117 - val_loss: 89.0337\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.9093 - val_loss: 88.4971\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.5364 - val_loss: 87.9773\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 5ms/step - loss: 78.0049 - val_loss: 87.6307\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.5968 - val_loss: 87.2225\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.2520 - val_loss: 86.5946\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.7919 - val_loss: 86.2463\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1548.5083 - val_loss: 1525.7179\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1496.3309 - val_loss: 1475.4673\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1441.6365 - val_loss: 1421.8655\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1383.4429 - val_loss: 1363.2072\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1318.7717 - val_loss: 1299.2897\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 2ms/step - loss: 1248.7474 - val_loss: 1228.5933\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 5ms/step - loss: 1173.4626 - val_loss: 1154.5315\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1094.0435 - val_loss: 1077.9786\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1011.7054 - val_loss: 998.6870\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 930.4458 - val_loss: 919.9581\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 849.7143 - val_loss: 843.5028\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 771.4341 - val_loss: 769.1458\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 694.8444 - val_loss: 696.9513\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 5ms/step - loss: 623.3903 - val_loss: 630.8628\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 559.1445 - val_loss: 569.3352\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 500.5397 - val_loss: 514.7167\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 5ms/step - loss: 447.5117 - val_loss: 465.3931\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 402.0924 - val_loss: 423.0670\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 361.7280 - val_loss: 385.3816\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 6ms/step - loss: 328.0407 - val_loss: 355.1930\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 3ms/step - loss: 300.9400 - val_loss: 329.3295\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 278.3826 - val_loss: 307.8770\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 260.1461 - val_loss: 289.4669\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 244.6352 - val_loss: 274.9436\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 231.8326 - val_loss: 262.0326\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 5ms/step - loss: 221.4529 - val_loss: 251.3399\n",
            "Epoch 27/100\n",
            "73/73 - 1s - 7ms/step - loss: 212.7651 - val_loss: 242.2548\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 205.4180 - val_loss: 234.3839\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 199.1630 - val_loss: 226.7551\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 193.3628 - val_loss: 220.4654\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 188.5456 - val_loss: 214.8988\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 184.5808 - val_loss: 209.8049\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 180.2424 - val_loss: 204.9796\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 2ms/step - loss: 176.2871 - val_loss: 200.3846\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 172.4958 - val_loss: 195.8938\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.9710 - val_loss: 191.8242\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.8140 - val_loss: 188.0735\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.7818 - val_loss: 184.3697\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 159.9511 - val_loss: 180.7751\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.0784 - val_loss: 177.1656\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.1448 - val_loss: 173.7865\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.4323 - val_loss: 170.2693\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.5816 - val_loss: 166.9542\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.8594 - val_loss: 163.8113\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.3601 - val_loss: 161.5303\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.6634 - val_loss: 158.6710\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.3944 - val_loss: 155.7768\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 136.0724 - val_loss: 153.1964\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.8067 - val_loss: 150.3808\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 5ms/step - loss: 131.6916 - val_loss: 147.8286\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.5606 - val_loss: 145.2943\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.5363 - val_loss: 143.0272\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.5596 - val_loss: 140.6050\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.6160 - val_loss: 138.3477\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.9740 - val_loss: 136.0644\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.3221 - val_loss: 134.2697\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.3721 - val_loss: 132.4835\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 5ms/step - loss: 116.7059 - val_loss: 130.5242\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.0687 - val_loss: 128.6775\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 5ms/step - loss: 113.4304 - val_loss: 127.0353\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 5ms/step - loss: 111.9920 - val_loss: 125.2607\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.3597 - val_loss: 123.2943\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.7714 - val_loss: 121.7031\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.3147 - val_loss: 120.1596\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.8993 - val_loss: 118.6755\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.4756 - val_loss: 117.1184\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.1098 - val_loss: 115.6726\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.7752 - val_loss: 114.5897\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 5ms/step - loss: 100.4930 - val_loss: 112.9600\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.1859 - val_loss: 111.8051\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.9813 - val_loss: 110.4240\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.7691 - val_loss: 109.0654\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.6041 - val_loss: 107.7533\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.5319 - val_loss: 106.5690\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.3525 - val_loss: 105.2442\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.0981 - val_loss: 104.0176\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.0278 - val_loss: 102.7850\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.9759 - val_loss: 101.5001\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.0398 - val_loss: 100.3330\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.9065 - val_loss: 99.2967\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.9523 - val_loss: 98.5955\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.8508 - val_loss: 97.6433\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.0864 - val_loss: 96.2250\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.0169 - val_loss: 95.7869\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 83.2202 - val_loss: 94.4963\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.4444 - val_loss: 94.0622\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.7108 - val_loss: 93.9709\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.0136 - val_loss: 92.9597\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.3087 - val_loss: 91.8636\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.6481 - val_loss: 91.0810\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.9235 - val_loss: 90.5195\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.1640 - val_loss: 89.3728\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 77.4459 - val_loss: 88.7293\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.5833 - val_loss: 87.6047\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 75.9152 - val_loss: 86.6807\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.9733 - val_loss: 85.4622\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.2178 - val_loss: 84.6531\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.4379 - val_loss: 83.6953\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 2ms/step - loss: 72.7768 - val_loss: 83.2590\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.0409 - val_loss: 81.8945\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1557.4509 - val_loss: 1561.0601\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1511.2042 - val_loss: 1507.6099\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1458.6222 - val_loss: 1447.7834\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1399.0659 - val_loss: 1379.6798\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1331.2664 - val_loss: 1304.3279\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1256.4620 - val_loss: 1221.7266\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1172.8812 - val_loss: 1131.0020\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1080.9827 - val_loss: 1031.3104\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 3ms/step - loss: 981.0052 - val_loss: 928.5243\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 882.5772 - val_loss: 827.7103\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 784.2097 - val_loss: 728.6624\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 692.6359 - val_loss: 639.8469\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 606.0095 - val_loss: 556.3471\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 5ms/step - loss: 526.6737 - val_loss: 480.3410\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 458.3444 - val_loss: 417.7132\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 400.4668 - val_loss: 363.2553\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 350.3655 - val_loss: 318.8448\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 310.4381 - val_loss: 282.6616\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 277.3484 - val_loss: 253.0490\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 250.0602 - val_loss: 229.9574\n",
            "Epoch 21/100\n",
            "73/73 - 1s - 8ms/step - loss: 228.2624 - val_loss: 212.5408\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 211.6734 - val_loss: 199.4857\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 2ms/step - loss: 199.2872 - val_loss: 190.2702\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 5ms/step - loss: 188.4158 - val_loss: 182.6850\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 180.0979 - val_loss: 177.1715\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.6259 - val_loss: 172.7050\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 5ms/step - loss: 168.4418 - val_loss: 169.1312\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.1735 - val_loss: 166.4310\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.5494 - val_loss: 163.6694\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.2106 - val_loss: 161.3991\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.3930 - val_loss: 159.1402\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.5856 - val_loss: 157.1276\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.0747 - val_loss: 154.8512\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.5502 - val_loss: 152.7590\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.2533 - val_loss: 150.6628\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.0046 - val_loss: 148.7609\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.9671 - val_loss: 147.2979\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.1568 - val_loss: 145.8220\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 136.6771 - val_loss: 144.6266\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 135.3615 - val_loss: 143.3431\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.1680 - val_loss: 142.0785\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.0686 - val_loss: 141.0643\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.7418 - val_loss: 139.7158\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.0087 - val_loss: 138.6050\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.7746 - val_loss: 137.7076\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.0068 - val_loss: 136.9859\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.0072 - val_loss: 135.9961\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 127.1875 - val_loss: 135.2106\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.1581 - val_loss: 134.2761\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.2856 - val_loss: 133.4366\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.4581 - val_loss: 132.5505\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 123.8144 - val_loss: 131.7870\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.6667 - val_loss: 131.1641\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 2ms/step - loss: 122.0491 - val_loss: 130.3460\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 2ms/step - loss: 121.0081 - val_loss: 129.7682\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.3057 - val_loss: 128.8936\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 5ms/step - loss: 119.7505 - val_loss: 128.0752\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.9003 - val_loss: 127.7348\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.1294 - val_loss: 126.9754\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.4641 - val_loss: 126.5470\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.7446 - val_loss: 125.7459\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.0679 - val_loss: 125.2232\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.3958 - val_loss: 124.6006\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.8995 - val_loss: 124.4809\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.2236 - val_loss: 123.8565\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.5972 - val_loss: 123.3535\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 6ms/step - loss: 112.9963 - val_loss: 123.0028\n",
            "Epoch 68/100\n",
            "73/73 - 1s - 7ms/step - loss: 112.3829 - val_loss: 122.3486\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.8376 - val_loss: 121.8071\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.3470 - val_loss: 121.1293\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.6973 - val_loss: 120.4779\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.1041 - val_loss: 120.0703\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 109.5591 - val_loss: 119.2953\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.0792 - val_loss: 118.9884\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.4395 - val_loss: 118.8210\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.9039 - val_loss: 118.3116\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.4476 - val_loss: 117.7708\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 5ms/step - loss: 106.8974 - val_loss: 117.2794\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.5288 - val_loss: 116.7590\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 2ms/step - loss: 105.8526 - val_loss: 115.9417\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 5ms/step - loss: 105.7418 - val_loss: 115.4274\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.0269 - val_loss: 115.0448\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.5084 - val_loss: 114.6556\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.9219 - val_loss: 114.6366\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.4885 - val_loss: 114.1753\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.1840 - val_loss: 113.5853\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 2ms/step - loss: 102.5639 - val_loss: 113.3360\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.1275 - val_loss: 112.7982\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.6672 - val_loss: 112.2009\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.1250 - val_loss: 111.9481\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.7622 - val_loss: 111.3738\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.2912 - val_loss: 111.0834\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 5ms/step - loss: 99.7863 - val_loss: 110.8067\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.4370 - val_loss: 110.1065\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.7813 - val_loss: 110.1302\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.3171 - val_loss: 109.3251\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 5ms/step - loss: 98.0332 - val_loss: 108.9871\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.6492 - val_loss: 108.7730\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.9879 - val_loss: 108.1673\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 5ms/step - loss: 96.6287 - val_loss: 107.5865\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 16ms/step - loss: 1587.6283 - val_loss: 1617.5552\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 5ms/step - loss: 1549.1354 - val_loss: 1579.6820\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1511.7777 - val_loss: 1540.7692\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1469.8136 - val_loss: 1494.5178\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1419.6442 - val_loss: 1439.6102\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1360.3734 - val_loss: 1375.8411\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1291.7279 - val_loss: 1303.6860\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1215.9290 - val_loss: 1225.1420\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1133.1494 - val_loss: 1140.4690\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1047.5800 - val_loss: 1054.4409\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 958.8066 - val_loss: 966.1600\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 871.6562 - val_loss: 880.1720\n",
            "Epoch 13/100\n",
            "73/73 - 1s - 7ms/step - loss: 787.3809 - val_loss: 799.0370\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 707.8040 - val_loss: 721.9967\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 632.7750 - val_loss: 651.3223\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 565.1973 - val_loss: 587.2695\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 2ms/step - loss: 504.7972 - val_loss: 530.8365\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 450.0388 - val_loss: 480.6071\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 402.1192 - val_loss: 436.5639\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 360.7661 - val_loss: 398.4225\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 5ms/step - loss: 324.6939 - val_loss: 364.6706\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 293.3086 - val_loss: 337.3072\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 266.7644 - val_loss: 313.1467\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 244.3590 - val_loss: 293.6328\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 2ms/step - loss: 225.8508 - val_loss: 276.8242\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 5ms/step - loss: 210.0909 - val_loss: 263.0985\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 197.3272 - val_loss: 251.5753\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 186.9522 - val_loss: 242.1595\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.3181 - val_loss: 234.3473\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.2680 - val_loss: 228.2236\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.4214 - val_loss: 222.3727\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.4095 - val_loss: 217.9883\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.0804 - val_loss: 213.1292\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.1963 - val_loss: 209.0729\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.5124 - val_loss: 205.3870\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.4603 - val_loss: 201.5478\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 3ms/step - loss: 142.5733 - val_loss: 198.0198\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.8846 - val_loss: 194.4866\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 137.2387 - val_loss: 191.2265\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 3ms/step - loss: 134.9119 - val_loss: 188.3840\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.5849 - val_loss: 184.9955\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.4407 - val_loss: 182.3470\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.4400 - val_loss: 178.6337\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.4029 - val_loss: 175.3286\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 5ms/step - loss: 124.6065 - val_loss: 172.4923\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.7790 - val_loss: 169.7270\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.0961 - val_loss: 166.8664\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 119.3342 - val_loss: 164.0925\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.7713 - val_loss: 161.3866\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.2688 - val_loss: 158.7706\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.6016 - val_loss: 156.6032\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.1861 - val_loss: 154.0728\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.7469 - val_loss: 151.5818\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.2780 - val_loss: 149.3356\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.9027 - val_loss: 147.4875\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.4168 - val_loss: 145.3330\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 5ms/step - loss: 106.1415 - val_loss: 143.1775\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.8666 - val_loss: 141.4565\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.5397 - val_loss: 138.9965\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 5ms/step - loss: 102.1526 - val_loss: 136.9640\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 6ms/step - loss: 101.0127 - val_loss: 135.0219\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.6609 - val_loss: 133.1688\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.4826 - val_loss: 131.3727\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.2186 - val_loss: 129.6589\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.9267 - val_loss: 127.6307\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.8023 - val_loss: 126.1064\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.5565 - val_loss: 124.4801\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.4187 - val_loss: 122.6039\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.3802 - val_loss: 121.0202\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.3198 - val_loss: 119.2018\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.1893 - val_loss: 117.9167\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.1217 - val_loss: 116.6103\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.1663 - val_loss: 115.1327\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.1698 - val_loss: 113.6621\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.1010 - val_loss: 112.1642\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.1496 - val_loss: 110.8412\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 5ms/step - loss: 83.3390 - val_loss: 108.6943\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.1228 - val_loss: 107.6255\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.1998 - val_loss: 106.6328\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 5ms/step - loss: 80.3677 - val_loss: 105.4643\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.4351 - val_loss: 104.2565\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.5574 - val_loss: 103.0859\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.6797 - val_loss: 101.9748\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.8526 - val_loss: 100.9995\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 5ms/step - loss: 75.9302 - val_loss: 99.6579\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.0964 - val_loss: 98.5172\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.2482 - val_loss: 97.3158\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.3221 - val_loss: 96.0974\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.5459 - val_loss: 95.0199\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 5ms/step - loss: 71.7287 - val_loss: 93.8993\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 70.9059 - val_loss: 92.7133\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 5ms/step - loss: 70.0725 - val_loss: 91.4766\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.2214 - val_loss: 90.6526\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.3259 - val_loss: 89.5742\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 6ms/step - loss: 67.5783 - val_loss: 88.4087\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 66.8506 - val_loss: 87.2970\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.9372 - val_loss: 86.1736\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.1180 - val_loss: 85.0064\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.0878 - val_loss: 83.9620\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.4620 - val_loss: 82.6813\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 20ms/step - loss: 1595.1993 - val_loss: 1460.6837\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1531.2174 - val_loss: 1397.8422\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1468.2932 - val_loss: 1335.0443\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 2ms/step - loss: 1403.5804 - val_loss: 1268.5321\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1335.2002 - val_loss: 1200.0607\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1263.5477 - val_loss: 1127.7581\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1189.7480 - val_loss: 1054.6304\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1113.0509 - val_loss: 980.7320\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1034.5793 - val_loss: 905.0717\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 957.0483 - val_loss: 833.5278\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 2ms/step - loss: 880.6580 - val_loss: 762.3588\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 808.0679 - val_loss: 696.2657\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 738.4482 - val_loss: 634.6333\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 672.8392 - val_loss: 577.6609\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 5ms/step - loss: 610.2874 - val_loss: 524.9749\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 555.0538 - val_loss: 479.2451\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 504.7272 - val_loss: 437.9020\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 459.7252 - val_loss: 400.6444\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 418.5157 - val_loss: 368.3463\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 2ms/step - loss: 381.7614 - val_loss: 339.4379\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 5ms/step - loss: 350.0294 - val_loss: 314.7923\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 320.6341 - val_loss: 292.2762\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 295.8587 - val_loss: 273.0466\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 3ms/step - loss: 274.6745 - val_loss: 257.0766\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 256.2087 - val_loss: 242.5987\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 239.6504 - val_loss: 229.8685\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 224.8714 - val_loss: 218.6546\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 212.0491 - val_loss: 208.8015\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 200.8568 - val_loss: 201.1939\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 191.4477 - val_loss: 193.6769\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 5ms/step - loss: 182.8667 - val_loss: 187.1872\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 175.4313 - val_loss: 181.9737\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 3ms/step - loss: 168.8357 - val_loss: 177.4825\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.7717 - val_loss: 172.8062\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.3241 - val_loss: 169.0336\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.2662 - val_loss: 165.2578\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.9518 - val_loss: 162.0542\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.9937 - val_loss: 159.5269\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 140.6534 - val_loss: 156.5903\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 136.8286 - val_loss: 153.7535\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.6954 - val_loss: 151.5920\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 130.6960 - val_loss: 148.8742\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.9628 - val_loss: 146.6706\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.9890 - val_loss: 143.9799\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.4135 - val_loss: 141.3793\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.9533 - val_loss: 139.5972\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.5915 - val_loss: 137.2668\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.3471 - val_loss: 135.1847\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.2036 - val_loss: 132.9138\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.0443 - val_loss: 130.9035\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.9868 - val_loss: 128.9873\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.0936 - val_loss: 126.8627\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.2327 - val_loss: 125.3235\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.4851 - val_loss: 123.1209\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.6669 - val_loss: 121.8955\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.0063 - val_loss: 119.5510\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.6585 - val_loss: 118.4428\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.9205 - val_loss: 117.1347\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.3621 - val_loss: 115.6516\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.1238 - val_loss: 113.9749\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 2ms/step - loss: 92.7915 - val_loss: 112.7915\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.6586 - val_loss: 111.6061\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.5358 - val_loss: 111.0843\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.4077 - val_loss: 109.4853\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.3400 - val_loss: 108.3430\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3217 - val_loss: 107.2105\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 5ms/step - loss: 86.2998 - val_loss: 105.8536\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 85.4961 - val_loss: 105.1038\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.7803 - val_loss: 104.4308\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.9564 - val_loss: 103.7701\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.0654 - val_loss: 102.5384\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.3263 - val_loss: 101.9466\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.5553 - val_loss: 100.8439\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.8972 - val_loss: 100.0896\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.2446 - val_loss: 99.5701\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.4929 - val_loss: 98.8620\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.8797 - val_loss: 97.7131\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.2008 - val_loss: 96.9632\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 5ms/step - loss: 77.5112 - val_loss: 95.7484\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.7916 - val_loss: 94.9741\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 5ms/step - loss: 76.0364 - val_loss: 94.2066\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.4205 - val_loss: 93.2547\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.6590 - val_loss: 93.0389\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.0678 - val_loss: 91.8002\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.4670 - val_loss: 91.1061\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.8440 - val_loss: 90.4847\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.2576 - val_loss: 89.6475\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.5903 - val_loss: 89.0893\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.1094 - val_loss: 88.1309\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.5487 - val_loss: 87.6519\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.9772 - val_loss: 87.0720\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.3880 - val_loss: 86.6300\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.9437 - val_loss: 86.0825\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.3274 - val_loss: 85.1872\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.9159 - val_loss: 84.5496\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.2701 - val_loss: 84.3829\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.8372 - val_loss: 83.7909\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.3798 - val_loss: 82.9820\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.8347 - val_loss: 82.1609\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 65.3470 - val_loss: 81.8783\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 15ms/step - loss: 1593.3967 - val_loss: 1672.8541\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 7ms/step - loss: 1554.2346 - val_loss: 1637.5645\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1522.5376 - val_loss: 1607.4194\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1494.5306 - val_loss: 1579.9882\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1466.7520 - val_loss: 1550.6965\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 5ms/step - loss: 1435.0089 - val_loss: 1514.1459\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1393.5562 - val_loss: 1464.1478\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1339.0731 - val_loss: 1400.3361\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 3ms/step - loss: 1271.9371 - val_loss: 1324.5204\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1194.5364 - val_loss: 1238.4065\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 1107.8225 - val_loss: 1144.8655\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 1016.2645 - val_loss: 1049.7395\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 923.9579 - val_loss: 953.9747\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 2ms/step - loss: 832.0636 - val_loss: 860.4925\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 5ms/step - loss: 744.0438 - val_loss: 770.7614\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 2ms/step - loss: 660.1623 - val_loss: 685.7662\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 584.7105 - val_loss: 611.8539\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 516.7311 - val_loss: 545.7432\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 457.0893 - val_loss: 487.1687\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 405.5101 - val_loss: 437.3065\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 362.0018 - val_loss: 396.2454\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 324.9007 - val_loss: 360.3259\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 293.7113 - val_loss: 331.5681\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 269.0293 - val_loss: 308.0700\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 249.4098 - val_loss: 290.1892\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 234.1590 - val_loss: 275.7262\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 221.5797 - val_loss: 263.7763\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 211.1561 - val_loss: 253.9473\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 202.6772 - val_loss: 245.8303\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 3ms/step - loss: 196.0495 - val_loss: 239.0453\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 190.0300 - val_loss: 233.2079\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 184.6570 - val_loss: 227.8087\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 180.3764 - val_loss: 223.0531\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 176.4960 - val_loss: 218.7537\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.2049 - val_loss: 214.9568\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 169.9990 - val_loss: 211.3713\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.0616 - val_loss: 208.0083\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 5ms/step - loss: 164.4692 - val_loss: 204.5936\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.0490 - val_loss: 201.5919\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.5975 - val_loss: 198.6518\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.2546 - val_loss: 195.4005\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.2120 - val_loss: 192.5361\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.9954 - val_loss: 189.7701\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.0910 - val_loss: 186.9452\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.9233 - val_loss: 184.0962\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 146.9457 - val_loss: 181.4640\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.9674 - val_loss: 178.7537\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.0052 - val_loss: 175.9368\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 140.9613 - val_loss: 172.8631\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 138.8210 - val_loss: 170.0396\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.6328 - val_loss: 167.1287\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.4688 - val_loss: 164.3328\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.4015 - val_loss: 160.9533\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.2223 - val_loss: 158.3020\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.0796 - val_loss: 155.6271\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.0416 - val_loss: 152.7384\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 5ms/step - loss: 124.1067 - val_loss: 150.2126\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.0268 - val_loss: 147.4185\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.1323 - val_loss: 144.9807\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.1671 - val_loss: 142.3910\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 5ms/step - loss: 116.2158 - val_loss: 139.6302\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.2125 - val_loss: 137.0007\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.3014 - val_loss: 133.7026\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.5509 - val_loss: 131.5883\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.6284 - val_loss: 128.9643\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 2ms/step - loss: 106.8380 - val_loss: 126.8369\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.0733 - val_loss: 124.6099\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.5014 - val_loss: 122.3283\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.8414 - val_loss: 120.1148\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.1036 - val_loss: 118.0095\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.2226 - val_loss: 115.8576\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.6672 - val_loss: 113.7450\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.1008 - val_loss: 111.8039\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 2ms/step - loss: 93.4797 - val_loss: 109.8885\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.8446 - val_loss: 108.0459\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.3435 - val_loss: 106.0631\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.8192 - val_loss: 104.2878\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.1985 - val_loss: 102.3353\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 5ms/step - loss: 85.6754 - val_loss: 100.5188\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.0286 - val_loss: 98.6546\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.5679 - val_loss: 97.3239\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.0316 - val_loss: 95.5330\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.5976 - val_loss: 93.9270\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 5ms/step - loss: 78.4719 - val_loss: 92.3774\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.0878 - val_loss: 90.6261\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 5ms/step - loss: 75.8241 - val_loss: 89.2913\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.6900 - val_loss: 87.8951\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.5020 - val_loss: 86.4649\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.3556 - val_loss: 85.0833\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.0379 - val_loss: 83.8324\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.8284 - val_loss: 82.4805\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 68.8034 - val_loss: 81.2094\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.7558 - val_loss: 80.0494\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 66.8055 - val_loss: 78.7927\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 5ms/step - loss: 65.7551 - val_loss: 77.8880\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.7642 - val_loss: 76.7071\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.9842 - val_loss: 75.8172\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.9372 - val_loss: 74.9209\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.0394 - val_loss: 73.8559\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 61.2736 - val_loss: 72.9062\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1558.5383 - val_loss: 1604.3099\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1516.6239 - val_loss: 1559.2875\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1472.0751 - val_loss: 1509.9259\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1422.3862 - val_loss: 1452.7703\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1364.4750 - val_loss: 1387.8481\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1297.2684 - val_loss: 1313.0657\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1223.3169 - val_loss: 1231.5637\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1142.6738 - val_loss: 1144.3289\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 5ms/step - loss: 1059.6898 - val_loss: 1056.3478\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 3ms/step - loss: 973.8121 - val_loss: 964.9669\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 5ms/step - loss: 885.6828 - val_loss: 873.0096\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 798.8553 - val_loss: 782.0267\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 5ms/step - loss: 714.0811 - val_loss: 694.6373\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 635.0146 - val_loss: 614.6166\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 561.2267 - val_loss: 539.8987\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 5ms/step - loss: 493.2511 - val_loss: 471.8832\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 433.0800 - val_loss: 412.9021\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 379.5941 - val_loss: 359.2115\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 335.8481 - val_loss: 316.1331\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 299.0768 - val_loss: 280.0938\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 269.3910 - val_loss: 250.2047\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 246.3840 - val_loss: 224.8033\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 227.5984 - val_loss: 207.1247\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 213.2650 - val_loss: 192.1702\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 201.8353 - val_loss: 180.1421\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 192.9862 - val_loss: 171.7102\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 5ms/step - loss: 185.8940 - val_loss: 163.6747\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 179.6884 - val_loss: 158.3477\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.7640 - val_loss: 154.2166\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 169.9908 - val_loss: 150.4602\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 166.0493 - val_loss: 146.3397\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 5ms/step - loss: 162.1924 - val_loss: 144.2261\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 5ms/step - loss: 158.9944 - val_loss: 141.1882\n",
            "Epoch 34/100\n",
            "73/73 - 1s - 8ms/step - loss: 155.8322 - val_loss: 139.2506\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.9363 - val_loss: 137.3079\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.2070 - val_loss: 135.4568\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.6948 - val_loss: 133.9089\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.6260 - val_loss: 131.1839\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 142.3175 - val_loss: 130.0104\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 139.9365 - val_loss: 128.5515\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.7761 - val_loss: 127.5295\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.6667 - val_loss: 126.4458\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.4064 - val_loss: 124.8424\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.3253 - val_loss: 123.0961\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 129.4715 - val_loss: 121.9117\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.4929 - val_loss: 120.6704\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 2ms/step - loss: 125.5763 - val_loss: 119.1625\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 2ms/step - loss: 123.9139 - val_loss: 117.8862\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.2454 - val_loss: 116.8376\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 120.6395 - val_loss: 115.8844\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 119.0845 - val_loss: 114.6700\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.3383 - val_loss: 113.8707\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.8744 - val_loss: 112.3789\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.2270 - val_loss: 111.1076\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7025 - val_loss: 109.5940\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.0618 - val_loss: 108.5315\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.5023 - val_loss: 107.2042\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 2ms/step - loss: 108.0502 - val_loss: 105.9570\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 2ms/step - loss: 106.6281 - val_loss: 104.9369\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.0659 - val_loss: 103.6353\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.6161 - val_loss: 102.5400\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 102.1127 - val_loss: 101.3864\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 2ms/step - loss: 100.7436 - val_loss: 100.4013\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 5ms/step - loss: 99.3817 - val_loss: 99.4378\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.9846 - val_loss: 98.4167\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.7184 - val_loss: 97.2342\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.5357 - val_loss: 96.3979\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 94.0806 - val_loss: 95.2603\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.8481 - val_loss: 93.9707\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.5334 - val_loss: 92.7200\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 90.3647 - val_loss: 91.6104\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.1229 - val_loss: 90.9182\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.0660 - val_loss: 89.9693\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.8747 - val_loss: 88.4984\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.7260 - val_loss: 87.9337\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.4808 - val_loss: 87.0245\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.1623 - val_loss: 86.1560\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.9025 - val_loss: 85.1829\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.9112 - val_loss: 84.1195\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 2ms/step - loss: 79.6104 - val_loss: 83.3340\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.4417 - val_loss: 82.4080\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 77.4404 - val_loss: 81.5362\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.3149 - val_loss: 80.9513\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 5ms/step - loss: 75.2289 - val_loss: 80.2360\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.1231 - val_loss: 79.4632\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.1421 - val_loss: 78.2607\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.8942 - val_loss: 77.8208\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.8762 - val_loss: 77.0880\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.8268 - val_loss: 76.3492\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.8154 - val_loss: 75.7376\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.8591 - val_loss: 75.2374\n",
            "Epoch 92/100\n",
            "73/73 - 1s - 8ms/step - loss: 66.9062 - val_loss: 74.6172\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.9956 - val_loss: 73.9853\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.6705 - val_loss: 73.8329\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 64.5178 - val_loss: 72.8100\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 63.5772 - val_loss: 72.0462\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.8961 - val_loss: 71.7143\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 2ms/step - loss: 62.1805 - val_loss: 71.0297\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 61.4544 - val_loss: 70.2906\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 60.9590 - val_loss: 70.2940\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1543.7438 - val_loss: 1459.5327\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1496.7909 - val_loss: 1412.1301\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1444.6631 - val_loss: 1359.2593\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1385.8685 - val_loss: 1300.4089\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1319.5713 - val_loss: 1232.9271\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1246.2181 - val_loss: 1159.0198\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1165.6078 - val_loss: 1077.1727\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1076.5088 - val_loss: 989.6047\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 980.4780 - val_loss: 895.9253\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 882.4080 - val_loss: 801.7293\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 786.0569 - val_loss: 712.3038\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 693.7381 - val_loss: 626.2066\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 606.9291 - val_loss: 544.2479\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 528.5603 - val_loss: 472.8071\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 458.8594 - val_loss: 410.2609\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 399.1731 - val_loss: 355.0650\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 348.3587 - val_loss: 309.8430\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 307.0914 - val_loss: 272.8727\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 273.9864 - val_loss: 243.3804\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 2ms/step - loss: 248.1995 - val_loss: 220.4295\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 228.0690 - val_loss: 201.7033\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 5ms/step - loss: 212.2279 - val_loss: 187.7560\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 199.6542 - val_loss: 176.1355\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 5ms/step - loss: 190.6268 - val_loss: 168.1064\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 183.9709 - val_loss: 162.1057\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.6259 - val_loss: 156.9345\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.2077 - val_loss: 153.0486\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 5ms/step - loss: 170.5042 - val_loss: 149.8350\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.6704 - val_loss: 147.3645\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 5ms/step - loss: 165.3157 - val_loss: 145.0717\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 5ms/step - loss: 162.9014 - val_loss: 143.0937\n",
            "Epoch 32/100\n",
            "73/73 - 1s - 8ms/step - loss: 160.7014 - val_loss: 141.3557\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.5295 - val_loss: 139.7336\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.5839 - val_loss: 138.3054\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.9505 - val_loss: 136.9120\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.1371 - val_loss: 135.6881\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.4436 - val_loss: 134.4147\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 149.9059 - val_loss: 133.3471\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.3494 - val_loss: 132.2175\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.6828 - val_loss: 131.0890\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 145.1962 - val_loss: 129.9818\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.6081 - val_loss: 129.0493\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 142.3717 - val_loss: 128.1407\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.9900 - val_loss: 127.2568\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.7408 - val_loss: 126.2797\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 2ms/step - loss: 138.4167 - val_loss: 125.3504\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 2ms/step - loss: 137.2072 - val_loss: 124.4042\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 135.7889 - val_loss: 123.4426\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 134.6154 - val_loss: 122.3743\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 133.1207 - val_loss: 121.2794\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.6979 - val_loss: 120.2698\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.3512 - val_loss: 119.1758\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 5ms/step - loss: 128.8711 - val_loss: 118.0947\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.4303 - val_loss: 117.1451\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.3001 - val_loss: 116.0056\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 5ms/step - loss: 124.7635 - val_loss: 114.9192\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 2ms/step - loss: 123.4354 - val_loss: 113.5495\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 5ms/step - loss: 121.9394 - val_loss: 112.3046\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.5883 - val_loss: 111.2504\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.1917 - val_loss: 110.0638\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.7257 - val_loss: 108.8762\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.2756 - val_loss: 107.7780\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.7189 - val_loss: 106.2155\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.2598 - val_loss: 105.1197\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.6513 - val_loss: 103.6421\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.0200 - val_loss: 102.2924\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 5ms/step - loss: 108.0892 - val_loss: 100.8091\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.4496 - val_loss: 99.4386\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.7900 - val_loss: 98.1868\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.1420 - val_loss: 96.7804\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.5344 - val_loss: 95.5191\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 99.9153 - val_loss: 94.2737\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.4432 - val_loss: 92.9532\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 2ms/step - loss: 96.7782 - val_loss: 91.6578\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.2875 - val_loss: 90.3535\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.8113 - val_loss: 89.0657\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.2971 - val_loss: 87.9473\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 6ms/step - loss: 90.8048 - val_loss: 86.6761\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.3930 - val_loss: 85.3943\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.8113 - val_loss: 84.1348\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.2233 - val_loss: 82.7987\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.9144 - val_loss: 81.4791\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.3932 - val_loss: 80.3425\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.0059 - val_loss: 79.1295\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.6715 - val_loss: 77.6639\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3357 - val_loss: 76.6286\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.1242 - val_loss: 75.6980\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 5ms/step - loss: 76.9359 - val_loss: 74.7722\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.7834 - val_loss: 73.7322\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.7279 - val_loss: 72.7206\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.4022 - val_loss: 71.8291\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 5ms/step - loss: 72.3281 - val_loss: 71.1569\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.2892 - val_loss: 70.0870\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.2881 - val_loss: 69.1893\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 69.2026 - val_loss: 68.5475\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 68.3174 - val_loss: 67.6797\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.3339 - val_loss: 66.9975\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.4505 - val_loss: 66.2191\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.6755 - val_loss: 65.6818\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.9809 - val_loss: 65.1091\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1518.7998 - val_loss: 1530.7469\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1464.6064 - val_loss: 1470.9008\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1402.6045 - val_loss: 1401.6974\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1329.2277 - val_loss: 1321.9781\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1245.0718 - val_loss: 1230.6853\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 2ms/step - loss: 1153.4958 - val_loss: 1134.0840\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 2ms/step - loss: 1054.6530 - val_loss: 1031.0980\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 952.1093 - val_loss: 926.4475\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 850.5438 - val_loss: 826.0747\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 752.9775 - val_loss: 729.1204\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 659.4266 - val_loss: 638.2475\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 574.7173 - val_loss: 557.6846\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 499.3230 - val_loss: 485.8298\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 433.2022 - val_loss: 424.6050\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 375.9549 - val_loss: 372.7847\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 331.0526 - val_loss: 332.1815\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 295.1305 - val_loss: 298.5677\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 266.7909 - val_loss: 274.2436\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 244.2977 - val_loss: 254.3315\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 226.7820 - val_loss: 237.7672\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 5ms/step - loss: 212.9526 - val_loss: 225.3150\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 202.4013 - val_loss: 215.7767\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 194.3569 - val_loss: 207.9126\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 187.6460 - val_loss: 201.6565\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 182.2798 - val_loss: 196.4212\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 5ms/step - loss: 177.5625 - val_loss: 191.3397\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.4222 - val_loss: 186.6798\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 169.8675 - val_loss: 182.1345\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 166.7072 - val_loss: 179.4431\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 163.5906 - val_loss: 175.0612\n",
            "Epoch 31/100\n",
            "73/73 - 1s - 8ms/step - loss: 160.7352 - val_loss: 171.5390\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.2625 - val_loss: 168.5365\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.7114 - val_loss: 165.9081\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.2871 - val_loss: 163.1607\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.9930 - val_loss: 160.6261\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.7926 - val_loss: 158.3974\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.7471 - val_loss: 155.8364\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.6358 - val_loss: 153.5510\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 142.5534 - val_loss: 151.1444\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.5506 - val_loss: 149.2769\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.6883 - val_loss: 146.9027\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.9141 - val_loss: 145.1022\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.2674 - val_loss: 143.2102\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 2ms/step - loss: 133.4991 - val_loss: 141.4380\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 5ms/step - loss: 131.8416 - val_loss: 139.7676\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 130.1733 - val_loss: 137.7573\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 5ms/step - loss: 128.6617 - val_loss: 136.5749\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.1529 - val_loss: 134.4983\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.5151 - val_loss: 133.2674\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.9015 - val_loss: 131.5874\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.5166 - val_loss: 130.3112\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.1192 - val_loss: 129.1849\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 2ms/step - loss: 120.0102 - val_loss: 128.2817\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 3ms/step - loss: 118.3577 - val_loss: 126.6412\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.0006 - val_loss: 125.1873\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 2ms/step - loss: 115.9586 - val_loss: 124.0745\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 5ms/step - loss: 114.5586 - val_loss: 122.3231\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.1960 - val_loss: 121.4290\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.0463 - val_loss: 120.3855\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.7258 - val_loss: 119.3668\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.5732 - val_loss: 117.7639\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.3669 - val_loss: 116.7678\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.3237 - val_loss: 115.2883\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.1682 - val_loss: 114.4609\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.1112 - val_loss: 113.5138\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.2565 - val_loss: 112.4471\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.2358 - val_loss: 111.3617\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.2395 - val_loss: 110.2725\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.3052 - val_loss: 109.2855\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.2554 - val_loss: 108.3711\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.1901 - val_loss: 106.6485\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.2885 - val_loss: 105.8996\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.2698 - val_loss: 105.1319\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.5779 - val_loss: 104.4194\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.4070 - val_loss: 103.3379\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.6462 - val_loss: 102.5855\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.7737 - val_loss: 101.4571\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.8671 - val_loss: 101.2121\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.0474 - val_loss: 99.9114\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.2125 - val_loss: 99.0815\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.5101 - val_loss: 98.6671\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.5355 - val_loss: 97.6891\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.8359 - val_loss: 97.1207\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.0828 - val_loss: 96.7960\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3285 - val_loss: 95.1886\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.6887 - val_loss: 94.5076\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 85.9784 - val_loss: 94.2170\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.3517 - val_loss: 93.6387\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.6620 - val_loss: 92.9407\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 84.1236 - val_loss: 92.3525\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.5714 - val_loss: 91.7683\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 2ms/step - loss: 82.9436 - val_loss: 91.3809\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.3834 - val_loss: 90.3436\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.7299 - val_loss: 89.5516\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 81.4112 - val_loss: 88.9337\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 5ms/step - loss: 80.7529 - val_loss: 88.2093\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.2025 - val_loss: 87.5746\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 79.5150 - val_loss: 87.4092\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.9594 - val_loss: 86.6722\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.2818 - val_loss: 86.5199\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1546.8242 - val_loss: 1526.6401\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1497.3824 - val_loss: 1477.7952\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1445.0090 - val_loss: 1425.1598\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1388.5745 - val_loss: 1368.0292\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 2ms/step - loss: 1326.0492 - val_loss: 1305.1879\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 5ms/step - loss: 1257.4510 - val_loss: 1234.7433\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1181.9359 - val_loss: 1157.5077\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1098.0833 - val_loss: 1072.9525\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1008.1855 - val_loss: 983.1201\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 917.4464 - val_loss: 893.7610\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 824.4214 - val_loss: 805.1930\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 736.2304 - val_loss: 720.3030\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 5ms/step - loss: 655.6074 - val_loss: 643.9536\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 5ms/step - loss: 581.1805 - val_loss: 573.2475\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 513.6870 - val_loss: 508.9710\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 453.7650 - val_loss: 452.4315\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 5ms/step - loss: 401.5251 - val_loss: 403.7632\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 357.8886 - val_loss: 362.9060\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 321.7820 - val_loss: 329.2662\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 2ms/step - loss: 291.9928 - val_loss: 300.4936\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 268.4866 - val_loss: 279.3041\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 249.6452 - val_loss: 261.5544\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 5ms/step - loss: 234.2493 - val_loss: 246.1716\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 222.2350 - val_loss: 234.9367\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 212.6985 - val_loss: 225.5261\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 5ms/step - loss: 204.8439 - val_loss: 218.0609\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 198.5201 - val_loss: 211.7056\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 192.6173 - val_loss: 206.1486\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 187.5621 - val_loss: 201.6417\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 183.2210 - val_loss: 197.9610\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 179.2986 - val_loss: 194.2835\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 175.4925 - val_loss: 190.7503\n",
            "Epoch 33/100\n",
            "73/73 - 1s - 8ms/step - loss: 171.9603 - val_loss: 187.2376\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.5772 - val_loss: 184.1404\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 165.5417 - val_loss: 181.5675\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.9327 - val_loss: 178.8246\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.3133 - val_loss: 176.5778\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.8687 - val_loss: 174.0372\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.1135 - val_loss: 171.4000\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 3ms/step - loss: 152.5888 - val_loss: 168.8297\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 149.9783 - val_loss: 166.2902\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.4014 - val_loss: 163.1449\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 5ms/step - loss: 144.6493 - val_loss: 160.1289\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.9837 - val_loss: 157.4413\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.6529 - val_loss: 154.9157\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.2029 - val_loss: 152.8710\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.9037 - val_loss: 150.6672\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 132.6283 - val_loss: 148.4787\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.5007 - val_loss: 146.2329\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.4022 - val_loss: 144.1017\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.2474 - val_loss: 141.9054\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 124.2008 - val_loss: 140.0385\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.2575 - val_loss: 137.6900\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.2520 - val_loss: 135.7273\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 118.3008 - val_loss: 133.5639\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.4654 - val_loss: 131.8557\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.5756 - val_loss: 129.9896\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7441 - val_loss: 127.7824\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.7946 - val_loss: 125.7980\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.1974 - val_loss: 124.1821\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.4124 - val_loss: 122.4688\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.1016 - val_loss: 120.8269\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 2ms/step - loss: 104.4372 - val_loss: 118.8873\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 2ms/step - loss: 103.0014 - val_loss: 117.4185\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 5ms/step - loss: 101.4331 - val_loss: 115.9736\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.0707 - val_loss: 114.1642\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.6329 - val_loss: 112.7870\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.3768 - val_loss: 111.3141\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.0860 - val_loss: 110.1160\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.8190 - val_loss: 108.6738\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.5714 - val_loss: 107.2813\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.4006 - val_loss: 106.0448\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 91.1653 - val_loss: 104.9889\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 90.1758 - val_loss: 103.8721\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.1128 - val_loss: 103.1675\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.9990 - val_loss: 101.7313\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.9049 - val_loss: 100.2588\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.9125 - val_loss: 99.0755\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.0043 - val_loss: 98.0926\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.0518 - val_loss: 97.2235\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 6ms/step - loss: 83.1805 - val_loss: 96.0247\n",
            "Epoch 82/100\n",
            "73/73 - 1s - 7ms/step - loss: 82.3313 - val_loss: 95.3537\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.4823 - val_loss: 94.3836\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.6623 - val_loss: 93.2445\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.7818 - val_loss: 92.3662\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.9901 - val_loss: 91.7767\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 5ms/step - loss: 78.1023 - val_loss: 90.6933\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.3868 - val_loss: 90.1129\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.5891 - val_loss: 89.2422\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.0834 - val_loss: 88.0257\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.1782 - val_loss: 87.4693\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.5804 - val_loss: 86.8939\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 2ms/step - loss: 73.9347 - val_loss: 86.1608\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 2ms/step - loss: 73.2046 - val_loss: 84.9959\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 5ms/step - loss: 72.6677 - val_loss: 84.6551\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.0682 - val_loss: 84.2145\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.4621 - val_loss: 83.6838\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 2ms/step - loss: 70.9763 - val_loss: 83.0553\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.3900 - val_loss: 82.7630\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 69.8937 - val_loss: 81.7857\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1528.0713 - val_loss: 1619.7882\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1481.2534 - val_loss: 1571.0906\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1433.3129 - val_loss: 1519.9734\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1383.0381 - val_loss: 1463.0248\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1327.2346 - val_loss: 1400.8768\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1265.8961 - val_loss: 1331.4935\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1198.8813 - val_loss: 1256.3562\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1126.6410 - val_loss: 1176.0192\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1048.6038 - val_loss: 1086.4178\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 5ms/step - loss: 964.5452 - val_loss: 993.1689\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 875.9895 - val_loss: 893.9020\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 785.4948 - val_loss: 795.0612\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 695.9866 - val_loss: 697.1411\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 610.2405 - val_loss: 606.1752\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 532.9524 - val_loss: 524.4819\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 5ms/step - loss: 464.9974 - val_loss: 454.9507\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 406.5565 - val_loss: 396.3592\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 358.7958 - val_loss: 349.2818\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 319.3114 - val_loss: 310.2495\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 287.2532 - val_loss: 279.9928\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 262.6253 - val_loss: 255.0667\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 242.5459 - val_loss: 235.1492\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 226.3417 - val_loss: 220.0117\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 213.3661 - val_loss: 207.9472\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 202.6096 - val_loss: 197.8588\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 193.7480 - val_loss: 189.6569\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 186.7408 - val_loss: 183.1045\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 180.7429 - val_loss: 177.8310\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 5ms/step - loss: 175.6621 - val_loss: 173.3579\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.5421 - val_loss: 169.4421\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 167.8155 - val_loss: 166.1180\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.5586 - val_loss: 163.1766\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 2ms/step - loss: 161.3115 - val_loss: 160.5955\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.5354 - val_loss: 158.2008\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 156.1537 - val_loss: 156.1226\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.5089 - val_loss: 153.7529\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.3719 - val_loss: 151.6037\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 149.2760 - val_loss: 149.8830\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 147.3305 - val_loss: 148.1039\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 145.4202 - val_loss: 145.9086\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 143.5074 - val_loss: 143.6015\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 141.7820 - val_loss: 142.2333\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 140.0049 - val_loss: 140.5903\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 5ms/step - loss: 138.3222 - val_loss: 139.1101\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.9475 - val_loss: 137.9244\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.5385 - val_loss: 136.2834\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.9599 - val_loss: 134.5809\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 2ms/step - loss: 132.7376 - val_loss: 133.6889\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.4921 - val_loss: 132.5831\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.2487 - val_loss: 131.3670\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.0258 - val_loss: 130.4801\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.8524 - val_loss: 129.2252\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.7079 - val_loss: 128.5556\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.3758 - val_loss: 127.2686\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.4060 - val_loss: 126.0272\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.2189 - val_loss: 124.9141\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 2ms/step - loss: 122.1366 - val_loss: 124.2382\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 2ms/step - loss: 120.9193 - val_loss: 122.9662\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 3ms/step - loss: 119.8613 - val_loss: 121.8912\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 2ms/step - loss: 118.4164 - val_loss: 121.0016\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.1873 - val_loss: 120.0366\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 2ms/step - loss: 116.0571 - val_loss: 118.6935\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 2ms/step - loss: 114.8839 - val_loss: 117.3162\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.5581 - val_loss: 116.2990\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 5ms/step - loss: 112.5225 - val_loss: 115.0050\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.9943 - val_loss: 113.7731\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 5ms/step - loss: 109.6608 - val_loss: 112.4623\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 2ms/step - loss: 108.2916 - val_loss: 111.0288\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.7816 - val_loss: 109.7900\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.3031 - val_loss: 108.3500\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.8238 - val_loss: 107.4572\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.2438 - val_loss: 105.3358\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 5ms/step - loss: 100.6313 - val_loss: 103.9032\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.0490 - val_loss: 102.2830\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 5ms/step - loss: 97.5132 - val_loss: 100.7348\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.9639 - val_loss: 98.8168\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.3408 - val_loss: 97.2643\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.0086 - val_loss: 96.1363\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.4908 - val_loss: 94.4703\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.1574 - val_loss: 92.9177\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 5ms/step - loss: 88.8690 - val_loss: 91.6248\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 6ms/step - loss: 87.5369 - val_loss: 90.1209\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 2ms/step - loss: 86.3972 - val_loss: 88.6472\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.1139 - val_loss: 87.1963\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 5ms/step - loss: 84.0606 - val_loss: 86.1086\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 82.7071 - val_loss: 84.5856\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.5301 - val_loss: 83.3082\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 5ms/step - loss: 80.5113 - val_loss: 82.0594\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3684 - val_loss: 81.0304\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.2175 - val_loss: 79.7437\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.9329 - val_loss: 78.6066\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.8082 - val_loss: 77.4626\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.5676 - val_loss: 76.2472\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 5ms/step - loss: 73.5381 - val_loss: 75.1799\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.5072 - val_loss: 74.1426\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.4647 - val_loss: 73.0999\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.6639 - val_loss: 72.0963\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.7375 - val_loss: 71.2213\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.8323 - val_loss: 70.3144\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 2ms/step - loss: 67.9644 - val_loss: 69.3141\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1601.6881 - val_loss: 1532.8838\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1556.6146 - val_loss: 1490.5651\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1514.4274 - val_loss: 1447.8835\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1470.0104 - val_loss: 1400.4514\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1419.5387 - val_loss: 1345.5154\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 2ms/step - loss: 1361.6027 - val_loss: 1284.2109\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1296.6460 - val_loss: 1216.1066\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1225.7914 - val_loss: 1141.2299\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 3ms/step - loss: 1149.0146 - val_loss: 1061.7080\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1068.5797 - val_loss: 980.9888\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 5ms/step - loss: 986.5965 - val_loss: 896.0951\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 901.5291 - val_loss: 809.9598\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 812.9539 - val_loss: 718.7625\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 721.3185 - val_loss: 631.2049\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 6ms/step - loss: 637.0733 - val_loss: 549.8433\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 557.3022 - val_loss: 475.3622\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 483.5951 - val_loss: 407.5523\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 5ms/step - loss: 417.2902 - val_loss: 348.6566\n",
            "Epoch 19/100\n",
            "73/73 - 1s - 8ms/step - loss: 361.3218 - val_loss: 301.5976\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 314.2722 - val_loss: 263.1354\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 276.4991 - val_loss: 234.0223\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 247.3612 - val_loss: 213.1499\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 225.3178 - val_loss: 197.7814\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 209.1935 - val_loss: 187.6410\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 197.6159 - val_loss: 180.8033\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 188.9658 - val_loss: 176.4238\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 182.8308 - val_loss: 173.3395\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.1200 - val_loss: 170.8413\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.4137 - val_loss: 169.0305\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.4926 - val_loss: 166.9757\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.9218 - val_loss: 165.4494\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 166.5150 - val_loss: 163.5993\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.5529 - val_loss: 161.9445\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.6502 - val_loss: 160.1811\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 160.6748 - val_loss: 158.3821\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.8008 - val_loss: 155.9816\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.9933 - val_loss: 154.3740\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 155.1214 - val_loss: 152.8842\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.2078 - val_loss: 151.3737\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.4270 - val_loss: 149.3567\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.7703 - val_loss: 147.5004\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.0555 - val_loss: 145.2178\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 146.4319 - val_loss: 143.3774\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 5ms/step - loss: 144.5671 - val_loss: 141.2318\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 142.7073 - val_loss: 139.4756\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.8560 - val_loss: 137.7294\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 2ms/step - loss: 139.0844 - val_loss: 135.7248\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 136.8647 - val_loss: 132.6967\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.9658 - val_loss: 130.7253\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.8961 - val_loss: 128.1628\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.2292 - val_loss: 125.3424\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.3904 - val_loss: 124.0524\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.4828 - val_loss: 121.8654\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.6050 - val_loss: 120.1462\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.8640 - val_loss: 118.6115\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 3ms/step - loss: 121.8495 - val_loss: 116.5142\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.2267 - val_loss: 114.6276\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 118.5886 - val_loss: 112.6562\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.6760 - val_loss: 111.1240\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.1434 - val_loss: 109.4630\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.5607 - val_loss: 107.3335\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.9324 - val_loss: 105.7230\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.3210 - val_loss: 103.7508\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.8683 - val_loss: 102.1496\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 107.2803 - val_loss: 100.7789\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.8332 - val_loss: 98.8738\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 6ms/step - loss: 104.3066 - val_loss: 97.2065\n",
            "Epoch 68/100\n",
            "73/73 - 1s - 8ms/step - loss: 103.0931 - val_loss: 95.6852\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.5473 - val_loss: 94.0017\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.0191 - val_loss: 92.3056\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.7945 - val_loss: 90.6328\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.7112 - val_loss: 90.1998\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 5ms/step - loss: 96.4533 - val_loss: 88.6553\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.1145 - val_loss: 86.7500\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.9594 - val_loss: 85.6111\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.9041 - val_loss: 84.5639\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.8780 - val_loss: 83.1273\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.6814 - val_loss: 81.9940\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.7065 - val_loss: 80.3073\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.4021 - val_loss: 79.0105\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.2659 - val_loss: 78.0529\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.1513 - val_loss: 76.6078\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.8067 - val_loss: 75.4427\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.8792 - val_loss: 73.8947\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.7272 - val_loss: 73.1799\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.5376 - val_loss: 72.0749\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.6225 - val_loss: 70.8601\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 3ms/step - loss: 79.5474 - val_loss: 69.6942\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.7033 - val_loss: 69.1383\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.9055 - val_loss: 67.9536\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.9090 - val_loss: 66.6757\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.0574 - val_loss: 65.9494\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.1682 - val_loss: 65.1357\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.2557 - val_loss: 63.8343\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.4739 - val_loss: 63.2062\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.5937 - val_loss: 62.3313\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.7022 - val_loss: 61.7413\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.9551 - val_loss: 60.8183\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.1113 - val_loss: 59.9576\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 2ms/step - loss: 69.4689 - val_loss: 59.2933\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 15ms/step - loss: 1521.5618 - val_loss: 1470.3411\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1468.0305 - val_loss: 1413.3258\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1404.6349 - val_loss: 1346.5304\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1331.0533 - val_loss: 1270.2463\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1248.3381 - val_loss: 1185.2799\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1156.5525 - val_loss: 1092.1968\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1058.6948 - val_loss: 994.2595\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 956.1121 - val_loss: 891.8453\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 5ms/step - loss: 854.5027 - val_loss: 794.8519\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 755.2376 - val_loss: 698.5416\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 5ms/step - loss: 660.5739 - val_loss: 610.1022\n",
            "Epoch 12/100\n",
            "73/73 - 1s - 8ms/step - loss: 577.8886 - val_loss: 533.2976\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 503.7751 - val_loss: 463.7135\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 5ms/step - loss: 439.3902 - val_loss: 404.5681\n",
            "Epoch 15/100\n",
            "73/73 - 1s - 7ms/step - loss: 385.5352 - val_loss: 353.7410\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 338.7514 - val_loss: 309.7479\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 302.4452 - val_loss: 276.1972\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 274.6112 - val_loss: 250.0195\n",
            "Epoch 19/100\n",
            "73/73 - 1s - 8ms/step - loss: 251.7732 - val_loss: 227.9905\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 233.2310 - val_loss: 211.5606\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 3ms/step - loss: 219.0414 - val_loss: 198.0271\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 207.2460 - val_loss: 187.1673\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 197.6558 - val_loss: 178.2466\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 3ms/step - loss: 189.8893 - val_loss: 171.7213\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 183.5138 - val_loss: 166.3047\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 177.9773 - val_loss: 161.7118\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 2ms/step - loss: 173.2481 - val_loss: 158.1317\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 169.0697 - val_loss: 154.4910\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.2582 - val_loss: 151.6498\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 161.8996 - val_loss: 149.1869\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.8214 - val_loss: 147.2634\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.3386 - val_loss: 145.4712\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.0131 - val_loss: 143.6649\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 5ms/step - loss: 151.8122 - val_loss: 142.2441\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.7838 - val_loss: 140.5685\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.9488 - val_loss: 139.4332\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 2ms/step - loss: 146.2723 - val_loss: 138.1917\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 5ms/step - loss: 144.9189 - val_loss: 137.1920\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.3181 - val_loss: 136.1718\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.9413 - val_loss: 134.8898\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.5603 - val_loss: 134.2989\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.3180 - val_loss: 133.5600\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 137.9861 - val_loss: 132.0749\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.8755 - val_loss: 131.2732\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 2ms/step - loss: 135.6084 - val_loss: 130.2766\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 5ms/step - loss: 134.3356 - val_loss: 128.8665\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.2754 - val_loss: 128.0671\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 131.9459 - val_loss: 126.6727\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.9761 - val_loss: 125.3221\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.6491 - val_loss: 124.4482\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 2ms/step - loss: 128.4352 - val_loss: 123.1055\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.1482 - val_loss: 122.0604\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.9075 - val_loss: 120.9907\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.6120 - val_loss: 119.7783\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 123.4993 - val_loss: 119.1116\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.2254 - val_loss: 117.9125\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.9491 - val_loss: 116.8828\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.7113 - val_loss: 115.6549\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 5ms/step - loss: 118.3385 - val_loss: 114.4745\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.9720 - val_loss: 113.2397\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.7000 - val_loss: 112.0530\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 5ms/step - loss: 114.3122 - val_loss: 110.8750\n",
            "Epoch 63/100\n",
            "73/73 - 1s - 8ms/step - loss: 113.0300 - val_loss: 109.6456\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 5ms/step - loss: 111.7251 - val_loss: 108.1007\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.2363 - val_loss: 107.0895\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.7266 - val_loss: 105.8202\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 5ms/step - loss: 107.4106 - val_loss: 104.6988\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.0766 - val_loss: 103.4521\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.6534 - val_loss: 101.8875\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.1085 - val_loss: 100.8499\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.6172 - val_loss: 99.3025\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 3ms/step - loss: 100.2137 - val_loss: 98.4004\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.0334 - val_loss: 96.9479\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 97.5849 - val_loss: 94.7966\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.3892 - val_loss: 93.6329\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.9194 - val_loss: 92.6458\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 5ms/step - loss: 93.8812 - val_loss: 91.9961\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 2ms/step - loss: 92.6184 - val_loss: 90.5710\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 5ms/step - loss: 91.5398 - val_loss: 89.4775\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.5633 - val_loss: 88.1438\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.1534 - val_loss: 87.6731\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.2237 - val_loss: 86.4371\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.1583 - val_loss: 85.3231\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.0563 - val_loss: 84.3417\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.0818 - val_loss: 83.1527\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.1285 - val_loss: 82.0927\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 83.1253 - val_loss: 81.2421\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.2540 - val_loss: 80.6398\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.2199 - val_loss: 79.1938\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.3568 - val_loss: 78.5971\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.6247 - val_loss: 77.2361\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.6147 - val_loss: 76.5789\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.6106 - val_loss: 75.8287\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.9799 - val_loss: 74.8440\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.0990 - val_loss: 73.9709\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.4184 - val_loss: 73.1695\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.6681 - val_loss: 72.2881\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.0163 - val_loss: 71.4322\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.1878 - val_loss: 70.5989\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.6031 - val_loss: 69.9286\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1579.7340 - val_loss: 1561.8645\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1538.6068 - val_loss: 1521.1418\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1495.6064 - val_loss: 1477.7498\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1447.4122 - val_loss: 1429.3010\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1393.5552 - val_loss: 1375.6796\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1332.4370 - val_loss: 1315.4113\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1266.9313 - val_loss: 1251.8936\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1197.2477 - val_loss: 1184.2052\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1124.2697 - val_loss: 1112.2046\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1047.9425 - val_loss: 1039.5554\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 970.8114 - val_loss: 965.5494\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 894.0180 - val_loss: 891.7092\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 817.6562 - val_loss: 819.0550\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 745.9561 - val_loss: 749.9537\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 677.7531 - val_loss: 685.1491\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 5ms/step - loss: 613.4075 - val_loss: 621.6089\n",
            "Epoch 17/100\n",
            "73/73 - 1s - 7ms/step - loss: 551.4122 - val_loss: 560.1034\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 490.9971 - val_loss: 497.3557\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 430.4661 - val_loss: 435.3465\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 376.5413 - val_loss: 380.8088\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 329.4179 - val_loss: 332.6571\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 289.1027 - val_loss: 292.6463\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 257.6757 - val_loss: 260.7270\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 3ms/step - loss: 232.8551 - val_loss: 235.3122\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 213.8946 - val_loss: 216.0487\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 199.7923 - val_loss: 200.9695\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 189.8395 - val_loss: 190.1343\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 181.7184 - val_loss: 181.4529\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 5ms/step - loss: 175.7671 - val_loss: 174.9147\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 3ms/step - loss: 171.6526 - val_loss: 169.8147\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 167.8925 - val_loss: 165.6930\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 2ms/step - loss: 165.2245 - val_loss: 162.7375\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 5ms/step - loss: 162.8956 - val_loss: 159.8251\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.9533 - val_loss: 157.9573\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 5ms/step - loss: 159.2469 - val_loss: 155.4619\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 157.5587 - val_loss: 153.8207\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.9439 - val_loss: 152.1262\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.3285 - val_loss: 150.7478\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 152.8846 - val_loss: 148.9348\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 151.3288 - val_loss: 147.5082\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 149.9075 - val_loss: 146.0153\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.4061 - val_loss: 144.2126\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 146.6049 - val_loss: 142.2130\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 145.0260 - val_loss: 140.7837\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 2ms/step - loss: 143.2470 - val_loss: 139.3013\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.5993 - val_loss: 137.9265\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.0133 - val_loss: 136.5861\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 138.4679 - val_loss: 135.3864\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.0447 - val_loss: 133.7625\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 135.1263 - val_loss: 132.1472\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.3463 - val_loss: 130.4671\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.5424 - val_loss: 128.5410\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.6558 - val_loss: 126.7472\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.8235 - val_loss: 125.0716\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 126.0982 - val_loss: 123.2923\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.2401 - val_loss: 121.3541\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 5ms/step - loss: 122.1834 - val_loss: 119.5665\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.4271 - val_loss: 117.6056\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.5648 - val_loss: 115.6917\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.6593 - val_loss: 114.0761\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.8689 - val_loss: 112.0826\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.9772 - val_loss: 110.3122\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.2257 - val_loss: 108.6358\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.4978 - val_loss: 106.7616\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.8119 - val_loss: 105.2678\n",
            "Epoch 66/100\n",
            "73/73 - 1s - 9ms/step - loss: 106.0372 - val_loss: 103.4243\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.3270 - val_loss: 101.7408\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.6600 - val_loss: 99.9716\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.7617 - val_loss: 98.3727\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.0728 - val_loss: 96.7283\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.3886 - val_loss: 94.9288\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.7630 - val_loss: 93.2338\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.2062 - val_loss: 91.8126\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 2ms/step - loss: 92.5802 - val_loss: 90.0950\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 5ms/step - loss: 91.1922 - val_loss: 88.4312\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.6317 - val_loss: 86.9139\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.1536 - val_loss: 85.2272\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.6387 - val_loss: 84.1101\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.2937 - val_loss: 82.6029\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.8778 - val_loss: 81.2125\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.5003 - val_loss: 79.8542\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 2ms/step - loss: 81.3123 - val_loss: 78.7654\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.9641 - val_loss: 77.4893\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.7907 - val_loss: 76.3173\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.6251 - val_loss: 75.1596\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 5ms/step - loss: 76.4337 - val_loss: 73.9415\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.2334 - val_loss: 73.0791\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.0680 - val_loss: 71.8586\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 2ms/step - loss: 73.0334 - val_loss: 70.8644\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.9659 - val_loss: 69.7572\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 70.8787 - val_loss: 68.8509\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.9948 - val_loss: 67.9112\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.8701 - val_loss: 66.7687\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 67.9075 - val_loss: 65.9048\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.0336 - val_loss: 65.0413\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.1148 - val_loss: 64.1519\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.2266 - val_loss: 63.5442\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 64.4768 - val_loss: 62.6233\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 2ms/step - loss: 64.1089 - val_loss: 61.9101\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.9280 - val_loss: 61.0921\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 16ms/step - loss: 1595.0913 - val_loss: 1537.7408\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 7ms/step - loss: 1553.9424 - val_loss: 1499.1252\n",
            "Epoch 3/100\n",
            "73/73 - 1s - 8ms/step - loss: 1514.1832 - val_loss: 1458.5938\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1470.0673 - val_loss: 1412.4934\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1418.9739 - val_loss: 1358.8641\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1357.1771 - val_loss: 1294.7878\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1286.5216 - val_loss: 1222.7780\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1206.2435 - val_loss: 1141.7915\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1118.5026 - val_loss: 1055.1841\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1024.5277 - val_loss: 960.9814\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 925.0126 - val_loss: 865.7106\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 2ms/step - loss: 826.0998 - val_loss: 774.1140\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 732.8484 - val_loss: 686.1633\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 647.8734 - val_loss: 607.2275\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 5ms/step - loss: 572.9276 - val_loss: 538.0249\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 2ms/step - loss: 508.4244 - val_loss: 477.0426\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 453.3893 - val_loss: 424.2232\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 405.8471 - val_loss: 378.1120\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 365.9497 - val_loss: 338.0840\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 331.7468 - val_loss: 304.5963\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 301.8754 - val_loss: 274.3976\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 276.4112 - val_loss: 249.6733\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 255.2970 - val_loss: 229.8468\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 236.3337 - val_loss: 211.9350\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 220.7224 - val_loss: 197.4053\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 2ms/step - loss: 208.1181 - val_loss: 186.6904\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 197.7883 - val_loss: 178.0406\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 189.3232 - val_loss: 170.7697\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 182.3357 - val_loss: 165.4711\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 176.6694 - val_loss: 161.6965\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 5ms/step - loss: 172.0587 - val_loss: 157.9983\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.3754 - val_loss: 155.3434\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.1262 - val_loss: 152.8643\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 5ms/step - loss: 162.3074 - val_loss: 150.7546\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.7040 - val_loss: 148.7929\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 3ms/step - loss: 157.4152 - val_loss: 147.1395\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 2ms/step - loss: 155.2000 - val_loss: 145.4763\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.0996 - val_loss: 144.0153\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 5ms/step - loss: 151.2677 - val_loss: 142.5582\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.4851 - val_loss: 141.0686\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.4900 - val_loss: 139.6876\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.0429 - val_loss: 138.2661\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 143.8848 - val_loss: 136.7829\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 2ms/step - loss: 142.4958 - val_loss: 135.2303\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 2ms/step - loss: 140.6470 - val_loss: 133.7082\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 2ms/step - loss: 138.9812 - val_loss: 132.1971\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.2843 - val_loss: 130.7617\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 2ms/step - loss: 135.4906 - val_loss: 129.3876\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.9506 - val_loss: 128.0590\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 5ms/step - loss: 132.4867 - val_loss: 126.6626\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.8261 - val_loss: 125.3772\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.3205 - val_loss: 124.2050\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.7155 - val_loss: 122.9844\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.2340 - val_loss: 121.4304\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.6222 - val_loss: 120.3009\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.3644 - val_loss: 118.8648\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.8101 - val_loss: 117.8966\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 120.4658 - val_loss: 116.5632\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 5ms/step - loss: 118.9868 - val_loss: 115.4912\n",
            "Epoch 60/100\n",
            "73/73 - 1s - 8ms/step - loss: 117.5787 - val_loss: 114.3998\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 5ms/step - loss: 116.3736 - val_loss: 113.4116\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.0671 - val_loss: 112.2732\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.7297 - val_loss: 111.1810\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.4467 - val_loss: 110.0182\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.2053 - val_loss: 108.6819\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.9617 - val_loss: 107.5949\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.8410 - val_loss: 106.6570\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.6435 - val_loss: 105.7604\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 2ms/step - loss: 106.6634 - val_loss: 104.8097\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.3354 - val_loss: 103.9618\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.0289 - val_loss: 102.6859\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 103.0346 - val_loss: 101.8680\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 101.9862 - val_loss: 100.7675\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 100.9444 - val_loss: 99.9526\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 2ms/step - loss: 99.8558 - val_loss: 99.0468\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.8520 - val_loss: 98.0775\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.8408 - val_loss: 97.2469\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.0778 - val_loss: 96.3322\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.9855 - val_loss: 95.5989\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.0384 - val_loss: 94.9008\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 2ms/step - loss: 94.1186 - val_loss: 94.1024\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.3002 - val_loss: 93.4120\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.5305 - val_loss: 92.6581\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.6759 - val_loss: 91.8937\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.9468 - val_loss: 91.1864\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.2187 - val_loss: 90.6062\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.4965 - val_loss: 89.8531\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.7520 - val_loss: 89.2463\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 2ms/step - loss: 88.0500 - val_loss: 88.6284\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.4013 - val_loss: 88.0144\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.7080 - val_loss: 87.4405\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 2ms/step - loss: 85.9926 - val_loss: 86.8618\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 5ms/step - loss: 85.3105 - val_loss: 86.2228\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.6667 - val_loss: 85.7493\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 84.0587 - val_loss: 85.1250\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 83.3897 - val_loss: 84.5719\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.0442 - val_loss: 83.8921\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.3572 - val_loss: 83.4104\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.8817 - val_loss: 82.9954\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.2971 - val_loss: 82.4940\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 20ms/step - loss: 1544.8367 - val_loss: 1519.4885\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1499.7654 - val_loss: 1471.0205\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1446.1125 - val_loss: 1411.8776\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1383.1930 - val_loss: 1343.2461\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1307.7866 - val_loss: 1261.8075\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1223.1655 - val_loss: 1171.4362\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1129.8707 - val_loss: 1073.7738\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1029.8728 - val_loss: 971.4747\n",
            "Epoch 9/100\n",
            "73/73 - 1s - 8ms/step - loss: 929.5520 - val_loss: 871.6263\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 3ms/step - loss: 829.2073 - val_loss: 771.5168\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 2ms/step - loss: 729.2354 - val_loss: 676.0500\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 633.9888 - val_loss: 586.3567\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 2ms/step - loss: 548.2275 - val_loss: 507.5456\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 472.6597 - val_loss: 440.5930\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 408.7748 - val_loss: 384.5992\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 355.7455 - val_loss: 340.1176\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 2ms/step - loss: 313.0841 - val_loss: 303.3590\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 5ms/step - loss: 278.9106 - val_loss: 277.5992\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 253.1247 - val_loss: 257.4001\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 233.7863 - val_loss: 242.9260\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 219.2008 - val_loss: 232.5008\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 208.2370 - val_loss: 224.0468\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 5ms/step - loss: 199.2144 - val_loss: 217.7873\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 192.3283 - val_loss: 212.9815\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 186.8054 - val_loss: 208.7168\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 5ms/step - loss: 182.1730 - val_loss: 205.1732\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 178.0203 - val_loss: 202.0387\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.2854 - val_loss: 199.3927\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 170.6768 - val_loss: 196.4492\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.4585 - val_loss: 193.5022\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 164.2230 - val_loss: 190.9776\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 161.1689 - val_loss: 188.8364\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.3305 - val_loss: 186.3103\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 5ms/step - loss: 155.6147 - val_loss: 183.7180\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 153.0561 - val_loss: 181.3933\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 150.5888 - val_loss: 179.3049\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 3ms/step - loss: 148.3495 - val_loss: 177.0531\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.1569 - val_loss: 175.2550\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 144.2039 - val_loss: 173.1359\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 2ms/step - loss: 142.1505 - val_loss: 171.4650\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.1953 - val_loss: 170.1971\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.5425 - val_loss: 168.2556\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.7695 - val_loss: 166.5674\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 135.2299 - val_loss: 165.4649\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.7578 - val_loss: 163.7459\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.2988 - val_loss: 162.7681\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 5ms/step - loss: 130.9783 - val_loss: 161.3671\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 129.8231 - val_loss: 160.6062\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 5ms/step - loss: 128.5583 - val_loss: 159.7766\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.5109 - val_loss: 158.7260\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 126.1212 - val_loss: 157.6411\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.1296 - val_loss: 156.7415\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.0300 - val_loss: 155.7283\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.0446 - val_loss: 155.0372\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 121.9682 - val_loss: 153.8606\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 3ms/step - loss: 120.9013 - val_loss: 153.1309\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 119.8581 - val_loss: 152.2422\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.1438 - val_loss: 151.2824\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.9552 - val_loss: 150.3105\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.9710 - val_loss: 149.7271\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.9011 - val_loss: 148.6862\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.0111 - val_loss: 147.9707\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 5ms/step - loss: 114.2648 - val_loss: 147.0782\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.2056 - val_loss: 146.3722\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.3101 - val_loss: 144.7141\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.4830 - val_loss: 144.5510\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 2ms/step - loss: 110.6793 - val_loss: 143.5266\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.7491 - val_loss: 142.9968\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.9336 - val_loss: 142.4082\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.1855 - val_loss: 141.4413\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 107.4407 - val_loss: 140.9680\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.9952 - val_loss: 140.2594\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 106.0032 - val_loss: 139.0852\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.3960 - val_loss: 138.2909\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.8550 - val_loss: 137.4527\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.0245 - val_loss: 136.9786\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.2739 - val_loss: 136.4712\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.7615 - val_loss: 135.3652\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 102.2000 - val_loss: 134.7757\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.5990 - val_loss: 134.2256\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 2ms/step - loss: 100.9984 - val_loss: 133.7029\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 100.4015 - val_loss: 132.6224\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 2ms/step - loss: 99.9803 - val_loss: 132.3422\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.5429 - val_loss: 131.2871\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 99.0326 - val_loss: 131.0527\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.4273 - val_loss: 130.5166\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.8942 - val_loss: 130.4070\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 97.4244 - val_loss: 129.5605\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.9998 - val_loss: 129.0291\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.6053 - val_loss: 128.7887\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.0454 - val_loss: 127.7484\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.5850 - val_loss: 127.2114\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.1984 - val_loss: 126.5373\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 94.7679 - val_loss: 126.0166\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.4393 - val_loss: 125.4259\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 2ms/step - loss: 93.9241 - val_loss: 125.1223\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 5ms/step - loss: 93.5089 - val_loss: 124.3881\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.2191 - val_loss: 123.8744\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.7689 - val_loss: 123.3583\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 2ms/step - loss: 92.3686 - val_loss: 122.9966\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 5s - 63ms/step - loss: 1530.0647 - val_loss: 1573.9535\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 5ms/step - loss: 1478.2637 - val_loss: 1519.9403\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1425.4314 - val_loss: 1462.6434\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1368.5409 - val_loss: 1401.2097\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1306.8993 - val_loss: 1333.3923\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1238.9211 - val_loss: 1259.9708\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1165.2349 - val_loss: 1181.2889\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1086.4523 - val_loss: 1097.5568\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1005.4915 - val_loss: 1011.8728\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 3ms/step - loss: 921.9623 - val_loss: 926.9332\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 840.5561 - val_loss: 841.9047\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 761.6114 - val_loss: 761.7534\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 686.9089 - val_loss: 685.8345\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 616.7797 - val_loss: 615.0942\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 551.2226 - val_loss: 550.1390\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 493.1059 - val_loss: 493.1587\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 441.6215 - val_loss: 443.5388\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 396.9896 - val_loss: 401.1534\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 358.1951 - val_loss: 364.1135\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 2ms/step - loss: 324.5185 - val_loss: 332.6369\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 295.9708 - val_loss: 305.7147\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 270.9366 - val_loss: 283.4958\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 250.0451 - val_loss: 263.8958\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 233.0288 - val_loss: 249.0379\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 219.0825 - val_loss: 236.9582\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 207.1745 - val_loss: 226.0994\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 196.9451 - val_loss: 217.3775\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 188.3565 - val_loss: 209.6979\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 5ms/step - loss: 181.0334 - val_loss: 203.3587\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 175.0019 - val_loss: 197.9468\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 169.4391 - val_loss: 193.3523\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.7437 - val_loss: 189.3332\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.7194 - val_loss: 185.6922\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 156.9472 - val_loss: 182.4785\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.5873 - val_loss: 178.9102\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 150.1820 - val_loss: 175.7172\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.2056 - val_loss: 172.6143\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.1357 - val_loss: 169.9142\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.3954 - val_loss: 166.9840\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.6325 - val_loss: 164.5785\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.1098 - val_loss: 161.8808\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.6691 - val_loss: 159.0100\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.2925 - val_loss: 156.1118\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.0651 - val_loss: 153.9398\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.0354 - val_loss: 151.3142\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.8724 - val_loss: 149.0480\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.7286 - val_loss: 146.6398\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 121.0629 - val_loss: 144.5406\n",
            "Epoch 49/100\n",
            "73/73 - 1s - 8ms/step - loss: 119.0240 - val_loss: 142.9375\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.2932 - val_loss: 140.8559\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.6533 - val_loss: 139.1708\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.9210 - val_loss: 137.5309\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.2254 - val_loss: 135.2108\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.6956 - val_loss: 133.5296\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.0524 - val_loss: 132.1030\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.5588 - val_loss: 130.4722\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.1551 - val_loss: 129.0824\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.7677 - val_loss: 127.8255\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.3510 - val_loss: 126.0289\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.9302 - val_loss: 124.5650\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.6058 - val_loss: 123.1417\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 5ms/step - loss: 99.2647 - val_loss: 121.6959\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.8432 - val_loss: 119.9657\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.4361 - val_loss: 118.5458\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.1167 - val_loss: 117.0458\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.7946 - val_loss: 115.3317\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.3492 - val_loss: 113.7351\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.0674 - val_loss: 112.7813\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 2ms/step - loss: 89.8784 - val_loss: 110.9220\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 5ms/step - loss: 88.4775 - val_loss: 109.2652\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3048 - val_loss: 107.8826\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.0483 - val_loss: 106.2686\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 5ms/step - loss: 84.6421 - val_loss: 104.8889\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 83.5857 - val_loss: 103.3679\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.4159 - val_loss: 101.6489\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.0627 - val_loss: 100.2815\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.9190 - val_loss: 98.6548\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.9391 - val_loss: 97.2875\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 77.7413 - val_loss: 95.8846\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.6077 - val_loss: 94.6539\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.4892 - val_loss: 93.1703\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.4153 - val_loss: 91.9399\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.4809 - val_loss: 90.1872\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.4372 - val_loss: 89.2005\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.4269 - val_loss: 88.0427\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 70.5349 - val_loss: 87.6510\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.6313 - val_loss: 86.3637\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 68.8348 - val_loss: 85.5837\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.8075 - val_loss: 84.3325\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.0077 - val_loss: 83.3257\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.2496 - val_loss: 82.1711\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.4892 - val_loss: 81.0541\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.7810 - val_loss: 80.9824\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.9710 - val_loss: 79.3519\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.3101 - val_loss: 78.5740\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.7712 - val_loss: 77.3656\n",
            "Epoch 97/100\n",
            "73/73 - 1s - 9ms/step - loss: 61.8834 - val_loss: 76.5102\n",
            "Epoch 98/100\n",
            "73/73 - 1s - 9ms/step - loss: 61.1418 - val_loss: 75.6755\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 60.5268 - val_loss: 74.4643\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 59.7883 - val_loss: 73.9610\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1495.9117 - val_loss: 1548.2428\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1448.4833 - val_loss: 1499.9324\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 2ms/step - loss: 1395.0863 - val_loss: 1444.9622\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 2ms/step - loss: 1333.1146 - val_loss: 1379.9573\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1261.2889 - val_loss: 1305.8796\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1179.6356 - val_loss: 1223.1350\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1091.9829 - val_loss: 1134.7389\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 999.4738 - val_loss: 1042.2780\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 903.5795 - val_loss: 946.0757\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 3ms/step - loss: 805.4555 - val_loss: 848.0540\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 708.5204 - val_loss: 752.3208\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 615.3644 - val_loss: 657.9038\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 530.4944 - val_loss: 576.4484\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 456.3484 - val_loss: 501.7307\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 392.4745 - val_loss: 438.6921\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 337.1993 - val_loss: 384.4718\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 5ms/step - loss: 292.6611 - val_loss: 338.9460\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 258.2894 - val_loss: 303.7492\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 231.2466 - val_loss: 275.4648\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 210.5048 - val_loss: 253.2874\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 196.4603 - val_loss: 237.2816\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 185.5190 - val_loss: 224.7376\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 177.9172 - val_loss: 216.0521\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 172.1886 - val_loss: 208.7619\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 2ms/step - loss: 167.7457 - val_loss: 203.4566\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.1730 - val_loss: 198.5556\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 161.0761 - val_loss: 195.0930\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.3969 - val_loss: 191.7363\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 5ms/step - loss: 155.9069 - val_loss: 189.0049\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.7875 - val_loss: 185.5115\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.7947 - val_loss: 183.0870\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 5ms/step - loss: 150.1990 - val_loss: 181.6546\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.5619 - val_loss: 179.8193\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.0295 - val_loss: 177.7574\n",
            "Epoch 35/100\n",
            "73/73 - 1s - 8ms/step - loss: 145.6117 - val_loss: 176.2810\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.1668 - val_loss: 174.6661\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.8158 - val_loss: 172.5914\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.2094 - val_loss: 171.2002\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.8489 - val_loss: 169.5481\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.4392 - val_loss: 167.6485\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.9298 - val_loss: 165.9650\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.3855 - val_loss: 164.1653\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 5ms/step - loss: 134.0695 - val_loss: 162.2621\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 7ms/step - loss: 132.6572 - val_loss: 161.0377\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.7755 - val_loss: 158.4324\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.2142 - val_loss: 156.8487\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.5186 - val_loss: 155.1775\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.8044 - val_loss: 153.5308\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.1402 - val_loss: 151.6520\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.5013 - val_loss: 149.6569\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.1143 - val_loss: 147.7250\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.3150 - val_loss: 145.7856\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.8325 - val_loss: 143.8490\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.2094 - val_loss: 141.8429\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.5540 - val_loss: 140.4030\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.8338 - val_loss: 138.1650\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.2220 - val_loss: 135.7541\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.5893 - val_loss: 134.0240\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.0648 - val_loss: 132.2353\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.4629 - val_loss: 130.1311\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.9404 - val_loss: 128.5415\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.5105 - val_loss: 126.3054\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.9047 - val_loss: 124.9449\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 100.4011 - val_loss: 123.1438\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.9531 - val_loss: 121.1627\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.6556 - val_loss: 120.1617\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.1223 - val_loss: 118.2213\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.7522 - val_loss: 116.2685\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.4452 - val_loss: 114.4087\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.1163 - val_loss: 112.7555\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.7500 - val_loss: 111.0409\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.3680 - val_loss: 109.7510\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 87.9848 - val_loss: 107.8259\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 2ms/step - loss: 86.7235 - val_loss: 106.3410\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 5ms/step - loss: 85.4029 - val_loss: 104.7544\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 84.1678 - val_loss: 102.5709\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.9834 - val_loss: 101.4510\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.8889 - val_loss: 100.1346\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.7559 - val_loss: 99.6606\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 5ms/step - loss: 79.5985 - val_loss: 97.7341\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.4484 - val_loss: 96.0793\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.4420 - val_loss: 94.2436\n",
            "Epoch 83/100\n",
            "73/73 - 1s - 8ms/step - loss: 76.4992 - val_loss: 92.8265\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.4250 - val_loss: 92.2127\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.5637 - val_loss: 90.6553\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.7919 - val_loss: 89.4552\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.9235 - val_loss: 88.8278\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.9259 - val_loss: 87.2932\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.9769 - val_loss: 86.1225\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 5ms/step - loss: 70.1932 - val_loss: 85.4475\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 7ms/step - loss: 69.2960 - val_loss: 84.2776\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.4563 - val_loss: 82.6690\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.7895 - val_loss: 81.4749\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 67.0057 - val_loss: 80.7657\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.1270 - val_loss: 79.9226\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.5091 - val_loss: 78.8707\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 2ms/step - loss: 64.7934 - val_loss: 78.3426\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.0039 - val_loss: 77.5917\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 2ms/step - loss: 63.4618 - val_loss: 76.3845\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.8706 - val_loss: 75.4605\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1534.9926 - val_loss: 1503.0905\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 7ms/step - loss: 1493.4108 - val_loss: 1453.4714\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1441.5166 - val_loss: 1391.4779\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1378.0181 - val_loss: 1319.5310\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1307.4296 - val_loss: 1238.5496\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1227.2637 - val_loss: 1151.5214\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 2ms/step - loss: 1137.6075 - val_loss: 1052.8827\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1041.1472 - val_loss: 949.6347\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 940.7151 - val_loss: 845.1027\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 840.9875 - val_loss: 745.0120\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 743.3133 - val_loss: 650.3040\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 650.8652 - val_loss: 563.6335\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 569.2830 - val_loss: 489.9279\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 496.6050 - val_loss: 422.4862\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 432.0744 - val_loss: 367.0243\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 377.7418 - val_loss: 319.5630\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 331.1732 - val_loss: 280.0700\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 2ms/step - loss: 293.1923 - val_loss: 248.8148\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 262.0193 - val_loss: 223.9644\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 237.0671 - val_loss: 203.5711\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 216.8802 - val_loss: 187.6640\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 202.2605 - val_loss: 176.2356\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 5ms/step - loss: 191.0904 - val_loss: 167.6745\n",
            "Epoch 24/100\n",
            "73/73 - 1s - 9ms/step - loss: 182.6141 - val_loss: 161.1987\n",
            "Epoch 25/100\n",
            "73/73 - 1s - 9ms/step - loss: 176.2574 - val_loss: 156.0154\n",
            "Epoch 26/100\n",
            "73/73 - 1s - 8ms/step - loss: 171.1978 - val_loss: 152.2738\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.2327 - val_loss: 149.4143\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.1630 - val_loss: 146.6456\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 161.5592 - val_loss: 144.4509\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.8796 - val_loss: 142.3119\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 5ms/step - loss: 156.7912 - val_loss: 140.4650\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 7ms/step - loss: 154.6932 - val_loss: 138.6847\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 3ms/step - loss: 152.8056 - val_loss: 136.9504\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 2ms/step - loss: 150.9620 - val_loss: 135.5114\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 5ms/step - loss: 148.9156 - val_loss: 133.4654\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 147.1118 - val_loss: 132.1171\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 3ms/step - loss: 145.4882 - val_loss: 130.0793\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.5492 - val_loss: 128.5597\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.8205 - val_loss: 127.1562\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.2130 - val_loss: 125.4164\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 5ms/step - loss: 138.3898 - val_loss: 124.0641\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.6179 - val_loss: 122.0883\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 134.7458 - val_loss: 120.5867\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.1355 - val_loss: 118.8021\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.1933 - val_loss: 116.8801\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 129.3931 - val_loss: 115.2078\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.7927 - val_loss: 113.5809\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 2ms/step - loss: 126.0077 - val_loss: 112.0739\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 5ms/step - loss: 124.3939 - val_loss: 110.3208\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.7177 - val_loss: 108.4816\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.1356 - val_loss: 107.2265\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.6786 - val_loss: 105.8633\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 118.1237 - val_loss: 104.4193\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.6541 - val_loss: 103.0752\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.2429 - val_loss: 101.7395\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.7993 - val_loss: 100.3908\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.5357 - val_loss: 99.2811\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.1364 - val_loss: 97.9948\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.7850 - val_loss: 96.7057\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 2ms/step - loss: 108.4635 - val_loss: 95.5689\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 107.3450 - val_loss: 93.9783\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.0611 - val_loss: 92.9607\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.1132 - val_loss: 92.0838\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 2ms/step - loss: 103.8960 - val_loss: 91.3825\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.9035 - val_loss: 90.1893\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.7460 - val_loss: 89.2351\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.6956 - val_loss: 88.1342\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.7058 - val_loss: 86.9700\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.6583 - val_loss: 86.3461\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 6ms/step - loss: 97.7002 - val_loss: 85.2732\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.6209 - val_loss: 84.1363\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.7673 - val_loss: 83.2631\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.6204 - val_loss: 82.2698\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.6770 - val_loss: 81.1436\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.7838 - val_loss: 80.4574\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 5ms/step - loss: 91.7926 - val_loss: 79.5111\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 3ms/step - loss: 91.0375 - val_loss: 78.8883\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 90.0360 - val_loss: 78.1275\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.3858 - val_loss: 77.3960\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.4105 - val_loss: 76.4487\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.6075 - val_loss: 75.9279\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.8176 - val_loss: 75.1237\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.0023 - val_loss: 74.4327\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.2757 - val_loss: 73.5774\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 3ms/step - loss: 84.5962 - val_loss: 72.8438\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 83.8290 - val_loss: 72.2015\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.1213 - val_loss: 71.3189\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.4080 - val_loss: 70.9100\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.6931 - val_loss: 70.0541\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.9631 - val_loss: 69.4100\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.3824 - val_loss: 68.5606\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.7001 - val_loss: 68.1051\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.1307 - val_loss: 67.5265\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.2420 - val_loss: 66.7253\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 5ms/step - loss: 77.7530 - val_loss: 66.1488\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.9311 - val_loss: 65.6802\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.2922 - val_loss: 65.1522\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.6198 - val_loss: 64.4511\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.1360 - val_loss: 63.9069\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.4932 - val_loss: 63.2473\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 15ms/step - loss: 1595.5417 - val_loss: 1502.4677\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1558.5907 - val_loss: 1468.9175\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1524.4175 - val_loss: 1434.8693\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 2ms/step - loss: 1487.8425 - val_loss: 1395.8260\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 5ms/step - loss: 1445.4640 - val_loss: 1350.5514\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1395.9658 - val_loss: 1297.7333\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1339.1176 - val_loss: 1235.2290\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1271.4257 - val_loss: 1163.6837\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 1193.9677 - val_loss: 1082.4757\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1107.4327 - val_loss: 995.0645\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 1014.9506 - val_loss: 902.4304\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 918.3707 - val_loss: 809.1440\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 821.7607 - val_loss: 718.0919\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 728.4348 - val_loss: 631.7369\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 641.7399 - val_loss: 550.1443\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 2ms/step - loss: 561.8563 - val_loss: 478.2029\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 489.7488 - val_loss: 414.2680\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 426.1714 - val_loss: 359.6296\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 5ms/step - loss: 372.3954 - val_loss: 314.3023\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 327.2738 - val_loss: 276.4771\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 290.1539 - val_loss: 246.3700\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 5ms/step - loss: 260.6734 - val_loss: 223.2627\n",
            "Epoch 23/100\n",
            "73/73 - 1s - 8ms/step - loss: 238.1306 - val_loss: 204.9969\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 220.0815 - val_loss: 192.2364\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 205.7542 - val_loss: 181.4599\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 194.2382 - val_loss: 173.6828\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 185.5495 - val_loss: 167.6071\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.8286 - val_loss: 162.9648\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.4971 - val_loss: 159.3439\n",
            "Epoch 30/100\n",
            "73/73 - 1s - 7ms/step - loss: 169.1543 - val_loss: 156.0830\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 165.3495 - val_loss: 153.5689\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 2ms/step - loss: 162.2844 - val_loss: 151.4819\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.6225 - val_loss: 149.6950\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.2502 - val_loss: 148.0649\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.4107 - val_loss: 146.6946\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 3ms/step - loss: 153.4600 - val_loss: 145.1530\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.5450 - val_loss: 143.6677\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 2ms/step - loss: 149.5876 - val_loss: 142.1727\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 147.6627 - val_loss: 140.7154\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.6189 - val_loss: 138.8473\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.5615 - val_loss: 137.4153\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 141.7406 - val_loss: 136.0801\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 139.8184 - val_loss: 134.6508\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.9790 - val_loss: 133.1294\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.2469 - val_loss: 131.7423\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 2ms/step - loss: 134.5365 - val_loss: 130.2794\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 132.4997 - val_loss: 128.6889\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 130.8847 - val_loss: 127.2890\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.0803 - val_loss: 126.1574\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 127.3813 - val_loss: 124.7697\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.7466 - val_loss: 123.4668\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.0418 - val_loss: 122.0046\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.4508 - val_loss: 120.7695\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 2ms/step - loss: 120.7430 - val_loss: 119.3355\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.1055 - val_loss: 118.1507\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.5228 - val_loss: 116.7043\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.9411 - val_loss: 115.3497\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.3220 - val_loss: 114.0274\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 5ms/step - loss: 112.7530 - val_loss: 112.5359\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.2932 - val_loss: 111.1763\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 2ms/step - loss: 109.6337 - val_loss: 109.9061\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.2462 - val_loss: 109.0024\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 5ms/step - loss: 106.7406 - val_loss: 107.8332\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.3531 - val_loss: 106.6849\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.0723 - val_loss: 105.5433\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.6349 - val_loss: 104.2621\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.3556 - val_loss: 103.1836\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.1162 - val_loss: 102.0715\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.8600 - val_loss: 100.8458\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 5ms/step - loss: 97.6411 - val_loss: 100.2068\n",
            "Epoch 71/100\n",
            "73/73 - 1s - 8ms/step - loss: 96.6070 - val_loss: 99.1493\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.4805 - val_loss: 98.2284\n",
            "Epoch 73/100\n",
            "73/73 - 1s - 8ms/step - loss: 94.4262 - val_loss: 97.2885\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.5497 - val_loss: 96.2416\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 5ms/step - loss: 92.3306 - val_loss: 94.9940\n",
            "Epoch 76/100\n",
            "73/73 - 1s - 8ms/step - loss: 91.4829 - val_loss: 94.1844\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 5ms/step - loss: 90.2936 - val_loss: 93.2179\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.2892 - val_loss: 92.1473\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.3331 - val_loss: 91.4436\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.4400 - val_loss: 90.2922\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.1800 - val_loss: 89.2164\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.4050 - val_loss: 88.2063\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 84.3379 - val_loss: 87.2534\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 3ms/step - loss: 83.3175 - val_loss: 86.6020\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.6007 - val_loss: 85.7373\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.6697 - val_loss: 84.6210\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.8245 - val_loss: 83.7855\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.9968 - val_loss: 83.0468\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.1835 - val_loss: 82.1688\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.3004 - val_loss: 81.6803\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.4833 - val_loss: 80.3341\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 2ms/step - loss: 76.5184 - val_loss: 79.7339\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 2ms/step - loss: 75.9822 - val_loss: 78.8028\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 2ms/step - loss: 75.0961 - val_loss: 78.2002\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.4706 - val_loss: 77.6190\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.7233 - val_loss: 76.8829\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.2482 - val_loss: 76.2020\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 5ms/step - loss: 72.4859 - val_loss: 75.3731\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.7812 - val_loss: 74.8066\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.1785 - val_loss: 74.0889\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1551.2792 - val_loss: 1491.6345\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 7ms/step - loss: 1502.2292 - val_loss: 1442.2124\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 2ms/step - loss: 1447.9219 - val_loss: 1386.6506\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1386.5881 - val_loss: 1323.6506\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1316.9973 - val_loss: 1253.9530\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 2ms/step - loss: 1240.1637 - val_loss: 1177.6506\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1155.4209 - val_loss: 1097.0656\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1067.1610 - val_loss: 1010.4857\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 974.8436 - val_loss: 922.1797\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 5ms/step - loss: 883.5235 - val_loss: 835.2175\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 5ms/step - loss: 792.4965 - val_loss: 748.8775\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 703.8141 - val_loss: 664.8596\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 5ms/step - loss: 619.7989 - val_loss: 587.2509\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 541.7466 - val_loss: 516.4919\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 5ms/step - loss: 471.8255 - val_loss: 451.2980\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 410.3326 - val_loss: 396.1191\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 358.0687 - val_loss: 348.5036\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 314.6878 - val_loss: 309.8740\n",
            "Epoch 19/100\n",
            "73/73 - 1s - 8ms/step - loss: 279.4623 - val_loss: 278.7527\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 250.9214 - val_loss: 253.1214\n",
            "Epoch 21/100\n",
            "73/73 - 1s - 8ms/step - loss: 228.6422 - val_loss: 233.4703\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 212.0564 - val_loss: 218.2404\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 199.1251 - val_loss: 206.8292\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 189.5566 - val_loss: 197.7659\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 181.6410 - val_loss: 190.7301\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 175.5650 - val_loss: 184.5875\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 170.4313 - val_loss: 179.7067\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 166.3896 - val_loss: 175.4154\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 3ms/step - loss: 162.7170 - val_loss: 171.7583\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.5791 - val_loss: 168.2907\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.6052 - val_loss: 165.3546\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 153.8968 - val_loss: 162.1703\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 3ms/step - loss: 151.5075 - val_loss: 159.6890\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 149.1825 - val_loss: 156.8371\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.1178 - val_loss: 154.7965\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 145.2673 - val_loss: 152.8631\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.4818 - val_loss: 151.1487\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.9059 - val_loss: 149.5325\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 5ms/step - loss: 140.4405 - val_loss: 148.2164\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.0293 - val_loss: 146.4395\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.8445 - val_loss: 145.2175\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 5ms/step - loss: 136.5407 - val_loss: 144.0521\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.2760 - val_loss: 142.7363\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 134.0340 - val_loss: 141.5570\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 2ms/step - loss: 132.7324 - val_loss: 140.3535\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 5ms/step - loss: 131.6460 - val_loss: 139.4787\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 130.4859 - val_loss: 138.2744\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.1802 - val_loss: 137.2954\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.9487 - val_loss: 135.8884\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 126.5695 - val_loss: 134.6202\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.3067 - val_loss: 133.4713\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 123.9365 - val_loss: 132.3412\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.4691 - val_loss: 130.7027\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.0302 - val_loss: 129.3057\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 5ms/step - loss: 119.4147 - val_loss: 127.5877\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.7708 - val_loss: 125.9445\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.1346 - val_loss: 124.3488\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.5140 - val_loss: 122.7315\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 5ms/step - loss: 112.9130 - val_loss: 121.1662\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.1943 - val_loss: 119.6035\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.6150 - val_loss: 117.8777\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.8812 - val_loss: 116.2416\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 5ms/step - loss: 106.3105 - val_loss: 114.7205\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.7859 - val_loss: 113.0419\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.2089 - val_loss: 111.5845\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.8260 - val_loss: 110.4499\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.1312 - val_loss: 108.6652\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.5471 - val_loss: 106.9986\n",
            "Epoch 69/100\n",
            "73/73 - 1s - 8ms/step - loss: 97.1356 - val_loss: 105.5539\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.6222 - val_loss: 104.1731\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.2621 - val_loss: 102.7594\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 92.7896 - val_loss: 101.4515\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.4230 - val_loss: 100.1537\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.9443 - val_loss: 98.7196\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 2ms/step - loss: 88.6017 - val_loss: 97.3065\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.2429 - val_loss: 95.6162\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 85.9481 - val_loss: 94.4984\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.6150 - val_loss: 92.8207\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 83.3499 - val_loss: 91.5022\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.9823 - val_loss: 89.8432\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.7271 - val_loss: 88.2320\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.5062 - val_loss: 87.2608\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.3062 - val_loss: 86.2573\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.2743 - val_loss: 85.3490\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 76.0851 - val_loss: 83.7512\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.9576 - val_loss: 83.2054\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.2128 - val_loss: 81.9898\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.0411 - val_loss: 81.1349\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.3561 - val_loss: 80.0237\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.2467 - val_loss: 79.1301\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.4854 - val_loss: 78.1733\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.7138 - val_loss: 77.2636\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 68.8905 - val_loss: 76.6214\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 2ms/step - loss: 68.0602 - val_loss: 75.3473\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 67.2720 - val_loss: 74.3556\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 2ms/step - loss: 66.6380 - val_loss: 73.5584\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 2ms/step - loss: 65.8584 - val_loss: 72.9161\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.2148 - val_loss: 72.0143\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 5ms/step - loss: 64.6238 - val_loss: 71.3024\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.9669 - val_loss: 70.6230\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 15ms/step - loss: 1516.8184 - val_loss: 1530.5773\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1471.2821 - val_loss: 1484.0625\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1421.8021 - val_loss: 1430.9087\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1364.1729 - val_loss: 1369.0085\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1296.3883 - val_loss: 1295.3921\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 2ms/step - loss: 1218.7582 - val_loss: 1214.7537\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 6ms/step - loss: 1133.5768 - val_loss: 1128.4537\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1045.0824 - val_loss: 1039.3966\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 954.8348 - val_loss: 948.1002\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 865.9443 - val_loss: 861.7395\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 779.0229 - val_loss: 776.5821\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 696.0763 - val_loss: 697.1167\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 5ms/step - loss: 618.2619 - val_loss: 622.7813\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 545.7326 - val_loss: 554.4061\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 481.1465 - val_loss: 494.1718\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 425.1855 - val_loss: 442.2264\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 376.6981 - val_loss: 398.2440\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 335.8039 - val_loss: 360.1503\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 300.5971 - val_loss: 328.0584\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 272.0705 - val_loss: 302.5526\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 249.9334 - val_loss: 281.8463\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 231.5729 - val_loss: 265.0316\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 216.2926 - val_loss: 249.8517\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 203.4459 - val_loss: 237.2596\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 2ms/step - loss: 193.4113 - val_loss: 227.5813\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 3ms/step - loss: 185.3024 - val_loss: 219.3846\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.4245 - val_loss: 212.2061\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 5ms/step - loss: 172.3794 - val_loss: 205.5113\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.5372 - val_loss: 200.2695\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 163.3647 - val_loss: 195.5810\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.6294 - val_loss: 191.5966\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 2ms/step - loss: 156.1626 - val_loss: 187.9420\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 2ms/step - loss: 153.2099 - val_loss: 184.4192\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.4580 - val_loss: 181.6780\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 2ms/step - loss: 147.8436 - val_loss: 178.7137\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 5ms/step - loss: 145.5381 - val_loss: 176.1574\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 3ms/step - loss: 143.1207 - val_loss: 173.4734\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.9887 - val_loss: 171.3654\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.8345 - val_loss: 169.2153\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.8502 - val_loss: 166.7960\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 134.9983 - val_loss: 164.6938\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.2159 - val_loss: 162.4536\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 131.6423 - val_loss: 160.5293\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 130.1945 - val_loss: 158.8728\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.6258 - val_loss: 157.1463\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.2065 - val_loss: 155.5042\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.4897 - val_loss: 153.1485\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.9519 - val_loss: 151.4676\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.2049 - val_loss: 149.4884\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.4587 - val_loss: 147.5525\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.5866 - val_loss: 145.5225\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 116.6156 - val_loss: 143.3327\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.6380 - val_loss: 141.1918\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7175 - val_loss: 139.0862\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.8271 - val_loss: 136.9338\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.9363 - val_loss: 134.8597\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 2ms/step - loss: 106.9430 - val_loss: 132.8935\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.2259 - val_loss: 130.4372\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.0970 - val_loss: 128.4384\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 6ms/step - loss: 101.3019 - val_loss: 126.4419\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.4592 - val_loss: 124.2985\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.5988 - val_loss: 122.3388\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.7364 - val_loss: 120.3608\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.1445 - val_loss: 118.8572\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.0020 - val_loss: 116.6352\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.2837 - val_loss: 114.7895\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.4268 - val_loss: 112.6772\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.6047 - val_loss: 111.1242\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.9833 - val_loss: 109.2273\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.2820 - val_loss: 107.2511\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.7521 - val_loss: 105.5214\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.1703 - val_loss: 103.9290\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 7ms/step - loss: 78.6451 - val_loss: 102.6792\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 77.3072 - val_loss: 101.4765\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.7885 - val_loss: 99.9899\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.3917 - val_loss: 98.6533\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.1332 - val_loss: 97.2074\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.7442 - val_loss: 95.8457\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 70.5577 - val_loss: 94.1780\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.3686 - val_loss: 93.1292\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 2ms/step - loss: 68.1696 - val_loss: 91.8234\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.9263 - val_loss: 90.5340\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.8489 - val_loss: 89.5521\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.8745 - val_loss: 88.4107\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 63.7866 - val_loss: 87.3842\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 5ms/step - loss: 62.8645 - val_loss: 86.1519\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 61.8604 - val_loss: 85.3662\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 60.9074 - val_loss: 84.4710\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 5ms/step - loss: 59.9016 - val_loss: 83.2082\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 59.0658 - val_loss: 82.4668\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 58.2941 - val_loss: 81.5775\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 57.4460 - val_loss: 80.8395\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 56.7570 - val_loss: 80.0547\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 56.0494 - val_loss: 79.4838\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 55.2941 - val_loss: 78.5735\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 54.5406 - val_loss: 77.9345\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 53.8636 - val_loss: 77.2250\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 53.3413 - val_loss: 76.6148\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 52.7456 - val_loss: 75.9939\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 52.0104 - val_loss: 75.3935\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 15ms/step - loss: 1586.9326 - val_loss: 1464.2706\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 7ms/step - loss: 1533.7821 - val_loss: 1415.9332\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1482.3800 - val_loss: 1366.3821\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1429.9939 - val_loss: 1314.6827\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1374.8193 - val_loss: 1259.6868\n",
            "Epoch 6/100\n",
            "73/73 - 1s - 8ms/step - loss: 1315.6550 - val_loss: 1200.2168\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1252.6964 - val_loss: 1136.8344\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1185.9185 - val_loss: 1071.5872\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 3ms/step - loss: 1116.2870 - val_loss: 1003.8508\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1044.9657 - val_loss: 934.7499\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 972.4268 - val_loss: 864.8128\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 5ms/step - loss: 897.3873 - val_loss: 795.5458\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 821.7094 - val_loss: 723.8560\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 745.8312 - val_loss: 654.3244\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 671.4727 - val_loss: 588.4052\n",
            "Epoch 16/100\n",
            "73/73 - 1s - 7ms/step - loss: 600.0747 - val_loss: 526.5505\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 536.0337 - val_loss: 472.4473\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 480.6655 - val_loss: 424.6720\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 431.6430 - val_loss: 383.1501\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 388.6420 - val_loss: 347.8785\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 5ms/step - loss: 352.7157 - val_loss: 317.5507\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 322.9225 - val_loss: 293.3906\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 298.3919 - val_loss: 272.4822\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 277.4344 - val_loss: 254.9911\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 260.6107 - val_loss: 241.0540\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 246.9031 - val_loss: 228.9207\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 234.8191 - val_loss: 218.4113\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 224.4275 - val_loss: 209.3060\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 3ms/step - loss: 215.4511 - val_loss: 201.0883\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 207.4352 - val_loss: 194.2597\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 200.2871 - val_loss: 187.8093\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 193.9086 - val_loss: 181.7822\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 5ms/step - loss: 188.1748 - val_loss: 176.6331\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 182.8027 - val_loss: 171.8114\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.0726 - val_loss: 167.3645\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.5203 - val_loss: 163.5363\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 169.4070 - val_loss: 159.8970\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.5149 - val_loss: 156.3287\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 161.9377 - val_loss: 152.9294\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.2894 - val_loss: 149.9471\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 154.8983 - val_loss: 146.9095\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.7380 - val_loss: 144.0898\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 148.4091 - val_loss: 141.0637\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.4426 - val_loss: 138.3170\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.4865 - val_loss: 135.7962\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.7786 - val_loss: 133.5377\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.1587 - val_loss: 131.2267\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.7380 - val_loss: 129.0027\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 132.2731 - val_loss: 126.7126\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 5ms/step - loss: 129.8827 - val_loss: 124.7528\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.5990 - val_loss: 122.6550\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.4159 - val_loss: 120.9590\n",
            "Epoch 53/100\n",
            "73/73 - 1s - 8ms/step - loss: 123.6584 - val_loss: 119.0583\n",
            "Epoch 54/100\n",
            "73/73 - 1s - 8ms/step - loss: 121.5601 - val_loss: 117.5686\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.8778 - val_loss: 115.9971\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.3140 - val_loss: 114.8211\n",
            "Epoch 57/100\n",
            "73/73 - 1s - 8ms/step - loss: 116.7828 - val_loss: 113.6799\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 5ms/step - loss: 115.3515 - val_loss: 112.7180\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.9775 - val_loss: 111.5865\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.5034 - val_loss: 110.5719\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.2485 - val_loss: 109.6533\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.9372 - val_loss: 108.6887\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.8203 - val_loss: 107.6348\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 107.4963 - val_loss: 106.7693\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.3268 - val_loss: 105.9841\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.1605 - val_loss: 104.8886\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 2ms/step - loss: 103.9752 - val_loss: 103.8559\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.0083 - val_loss: 102.9341\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 5ms/step - loss: 101.8324 - val_loss: 102.0421\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 100.8699 - val_loss: 101.4209\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.6465 - val_loss: 100.6381\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 98.7812 - val_loss: 99.8392\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.7294 - val_loss: 99.0659\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.8944 - val_loss: 98.0637\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.6617 - val_loss: 97.5299\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.8244 - val_loss: 96.5088\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.7245 - val_loss: 95.8144\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.8225 - val_loss: 95.0198\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.7943 - val_loss: 94.2696\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.9684 - val_loss: 93.5332\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.9623 - val_loss: 92.8966\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 5ms/step - loss: 89.1586 - val_loss: 92.1555\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.2179 - val_loss: 91.4591\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.3408 - val_loss: 90.7929\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.5539 - val_loss: 90.1517\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.6656 - val_loss: 89.5030\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.8258 - val_loss: 88.6378\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.1609 - val_loss: 88.3026\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.3882 - val_loss: 87.7551\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.8173 - val_loss: 87.0748\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.0398 - val_loss: 86.5708\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.1797 - val_loss: 85.8655\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.5202 - val_loss: 85.3248\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 5ms/step - loss: 79.8378 - val_loss: 84.8681\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 79.3587 - val_loss: 84.1857\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.6090 - val_loss: 83.7397\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.9337 - val_loss: 83.3247\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 5ms/step - loss: 77.3398 - val_loss: 82.6592\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.6992 - val_loss: 82.1145\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.2078 - val_loss: 81.5383\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 2s - 23ms/step - loss: 1515.7062 - val_loss: 1560.4777\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 5ms/step - loss: 1471.2278 - val_loss: 1512.9161\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1422.7897 - val_loss: 1459.5785\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1366.9888 - val_loss: 1397.9391\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1305.3253 - val_loss: 1329.1165\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1236.7158 - val_loss: 1254.4921\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 2ms/step - loss: 1161.2075 - val_loss: 1173.9457\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1081.4487 - val_loss: 1089.0305\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 999.8531 - val_loss: 1000.8185\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 916.4346 - val_loss: 915.5893\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 5ms/step - loss: 835.2064 - val_loss: 830.4369\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 756.1900 - val_loss: 751.0769\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 681.2474 - val_loss: 675.2065\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 611.4540 - val_loss: 604.6144\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 547.4011 - val_loss: 540.2430\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 488.2974 - val_loss: 482.1480\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 436.3704 - val_loss: 430.1670\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 389.9093 - val_loss: 385.5516\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 349.8439 - val_loss: 346.6661\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 315.9330 - val_loss: 313.6897\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 3ms/step - loss: 286.9342 - val_loss: 285.7467\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 5ms/step - loss: 263.7122 - val_loss: 263.0895\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 244.1740 - val_loss: 243.3599\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 228.8759 - val_loss: 227.7316\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 2ms/step - loss: 215.4186 - val_loss: 214.5020\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 2ms/step - loss: 204.5929 - val_loss: 203.1222\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 195.7112 - val_loss: 194.3804\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 188.2004 - val_loss: 186.6786\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 181.8013 - val_loss: 180.2928\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 3ms/step - loss: 175.9877 - val_loss: 174.1781\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.0980 - val_loss: 168.7800\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 166.4231 - val_loss: 163.9129\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.1795 - val_loss: 159.3306\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 158.4103 - val_loss: 154.8769\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 2ms/step - loss: 154.7900 - val_loss: 151.1173\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.2796 - val_loss: 146.9499\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 5ms/step - loss: 148.2636 - val_loss: 143.2072\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.9291 - val_loss: 140.7622\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 141.9958 - val_loss: 137.3307\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 3ms/step - loss: 139.0877 - val_loss: 133.5737\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.2608 - val_loss: 130.4193\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.4508 - val_loss: 127.5403\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 6ms/step - loss: 130.8787 - val_loss: 124.5768\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.5516 - val_loss: 121.8413\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.0301 - val_loss: 119.3188\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.5767 - val_loss: 116.7662\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.4117 - val_loss: 114.3154\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.2605 - val_loss: 112.0651\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 116.8951 - val_loss: 109.6976\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.9983 - val_loss: 108.1101\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.0468 - val_loss: 105.6779\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.2735 - val_loss: 103.9707\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.3704 - val_loss: 102.0956\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.7481 - val_loss: 100.2383\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.8341 - val_loss: 98.8988\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.1856 - val_loss: 97.7299\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.7057 - val_loss: 95.7410\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.9882 - val_loss: 95.0097\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.5493 - val_loss: 93.1664\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.1101 - val_loss: 91.4269\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.5864 - val_loss: 89.3674\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.0252 - val_loss: 88.0695\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 2ms/step - loss: 93.4605 - val_loss: 86.6936\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.1549 - val_loss: 85.2424\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.5249 - val_loss: 83.6347\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.2380 - val_loss: 82.0544\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.8540 - val_loss: 81.0068\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.7624 - val_loss: 79.4795\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 5ms/step - loss: 85.2623 - val_loss: 78.4988\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.1001 - val_loss: 77.3625\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 2ms/step - loss: 82.9937 - val_loss: 76.1732\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.1678 - val_loss: 74.7609\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.4870 - val_loss: 73.7493\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3807 - val_loss: 72.8495\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.1667 - val_loss: 71.8430\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.0746 - val_loss: 71.1168\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 5ms/step - loss: 76.1018 - val_loss: 70.0044\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.1068 - val_loss: 69.2229\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.9574 - val_loss: 68.5820\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.8021 - val_loss: 67.4679\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.8079 - val_loss: 66.6855\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.8123 - val_loss: 66.0641\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 2ms/step - loss: 70.0289 - val_loss: 65.3079\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 3ms/step - loss: 69.0184 - val_loss: 64.6031\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 3ms/step - loss: 68.1310 - val_loss: 63.8979\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 67.3325 - val_loss: 63.0406\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.3437 - val_loss: 62.4993\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.5419 - val_loss: 61.8196\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 2ms/step - loss: 64.7729 - val_loss: 61.3456\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 2ms/step - loss: 64.1284 - val_loss: 60.4226\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 63.2177 - val_loss: 59.8119\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 2ms/step - loss: 62.4822 - val_loss: 58.9478\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 2ms/step - loss: 61.8574 - val_loss: 58.4859\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 2ms/step - loss: 61.0799 - val_loss: 57.9765\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 60.3763 - val_loss: 57.5227\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 59.8289 - val_loss: 56.9510\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 59.1675 - val_loss: 56.3607\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 5ms/step - loss: 58.4623 - val_loss: 55.6258\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 57.9990 - val_loss: 55.4364\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 5ms/step - loss: 57.3260 - val_loss: 55.0493\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 20ms/step - loss: 1542.4283 - val_loss: 1531.1899\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1489.0094 - val_loss: 1479.3414\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1433.6406 - val_loss: 1423.8187\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1374.8289 - val_loss: 1364.6652\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1311.8737 - val_loss: 1300.4927\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1243.3225 - val_loss: 1231.5929\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1172.0358 - val_loss: 1159.7983\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 5ms/step - loss: 1096.4445 - val_loss: 1081.8705\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1016.5880 - val_loss: 999.1005\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 931.3768 - val_loss: 911.8375\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 843.1846 - val_loss: 821.9394\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 753.0259 - val_loss: 730.9194\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 666.4303 - val_loss: 645.2002\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 583.3672 - val_loss: 561.0881\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 507.0491 - val_loss: 487.5423\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 440.1629 - val_loss: 423.2259\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 382.7074 - val_loss: 367.5639\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 335.3951 - val_loss: 323.5940\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 297.4651 - val_loss: 287.2255\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 267.4912 - val_loss: 258.5764\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 244.2778 - val_loss: 236.5446\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 226.1263 - val_loss: 218.5443\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 211.6442 - val_loss: 205.0146\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 3ms/step - loss: 200.2945 - val_loss: 194.1515\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 191.5685 - val_loss: 185.3801\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 3ms/step - loss: 183.8664 - val_loss: 177.8321\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 177.4119 - val_loss: 171.6967\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 171.7525 - val_loss: 165.9556\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 166.8553 - val_loss: 161.3088\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 3ms/step - loss: 162.4863 - val_loss: 157.1960\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 158.4761 - val_loss: 153.4616\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 155.1189 - val_loss: 149.9205\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.6289 - val_loss: 146.4546\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.0502 - val_loss: 143.8206\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 146.6168 - val_loss: 141.4119\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 3ms/step - loss: 144.3579 - val_loss: 139.0919\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 2ms/step - loss: 142.0443 - val_loss: 136.5913\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 139.9176 - val_loss: 134.6272\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 137.8382 - val_loss: 132.4427\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.6609 - val_loss: 130.3769\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.7915 - val_loss: 128.4648\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.7821 - val_loss: 126.4702\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 129.9583 - val_loss: 124.3055\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 5ms/step - loss: 128.2058 - val_loss: 122.2316\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.4190 - val_loss: 120.5353\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.5015 - val_loss: 119.0967\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.9252 - val_loss: 117.2781\n",
            "Epoch 48/100\n",
            "73/73 - 1s - 8ms/step - loss: 121.3503 - val_loss: 115.8462\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.6435 - val_loss: 114.1961\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.4306 - val_loss: 112.6857\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.7233 - val_loss: 111.2143\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.3448 - val_loss: 109.4430\n",
            "Epoch 53/100\n",
            "73/73 - 1s - 9ms/step - loss: 113.8273 - val_loss: 108.0584\n",
            "Epoch 54/100\n",
            "73/73 - 1s - 7ms/step - loss: 112.4670 - val_loss: 106.5218\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 2ms/step - loss: 111.1599 - val_loss: 105.3415\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.7700 - val_loss: 103.9890\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.4472 - val_loss: 102.7710\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 107.3240 - val_loss: 101.5556\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.0331 - val_loss: 100.3731\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 5ms/step - loss: 104.7529 - val_loss: 99.2433\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.6968 - val_loss: 98.5938\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 5ms/step - loss: 102.6572 - val_loss: 97.5851\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.5231 - val_loss: 96.6118\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 5ms/step - loss: 100.3016 - val_loss: 95.4280\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.2298 - val_loss: 94.5013\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.1304 - val_loss: 93.5016\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.1011 - val_loss: 92.7703\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.2217 - val_loss: 91.9174\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.2123 - val_loss: 91.1063\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.9743 - val_loss: 90.0473\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.1122 - val_loss: 89.2954\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 92.1091 - val_loss: 88.4519\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.2171 - val_loss: 87.7187\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 90.2892 - val_loss: 86.9158\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.2574 - val_loss: 86.0708\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.3719 - val_loss: 85.0498\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.5202 - val_loss: 84.4765\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.8463 - val_loss: 83.8233\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.9395 - val_loss: 83.1860\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 85.0459 - val_loss: 82.7648\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.5766 - val_loss: 82.4046\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.6755 - val_loss: 81.7856\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.0575 - val_loss: 81.2284\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 82.1968 - val_loss: 80.7241\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.4933 - val_loss: 80.3826\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 2ms/step - loss: 80.9057 - val_loss: 79.9336\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.2463 - val_loss: 79.4238\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.4021 - val_loss: 79.0522\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.8773 - val_loss: 78.7773\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.0327 - val_loss: 78.0652\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 5ms/step - loss: 77.5244 - val_loss: 77.5327\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.7124 - val_loss: 77.0541\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.0455 - val_loss: 76.5935\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.4306 - val_loss: 76.3243\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.8042 - val_loss: 75.6958\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.1675 - val_loss: 75.0538\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.3529 - val_loss: 74.4388\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.8245 - val_loss: 74.0199\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.9564 - val_loss: 73.1960\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.3820 - val_loss: 72.7936\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 19ms/step - loss: 1595.0759 - val_loss: 1561.5127\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1547.6877 - val_loss: 1517.1377\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1505.4983 - val_loss: 1476.2048\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1465.8728 - val_loss: 1436.6725\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1426.2791 - val_loss: 1396.1367\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1384.7136 - val_loss: 1354.3140\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1343.0740 - val_loss: 1311.7184\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1299.3723 - val_loss: 1266.9983\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1253.3927 - val_loss: 1220.6017\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1205.2235 - val_loss: 1171.4796\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 1155.9913 - val_loss: 1120.6427\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 1105.0482 - val_loss: 1069.5337\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 1052.9956 - val_loss: 1016.0743\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 1000.7788 - val_loss: 962.8322\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 948.9254 - val_loss: 911.1830\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 5ms/step - loss: 898.1349 - val_loss: 859.0071\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 847.5416 - val_loss: 808.8038\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 797.7823 - val_loss: 758.3870\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 748.3881 - val_loss: 709.4365\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 699.6207 - val_loss: 661.1476\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 3ms/step - loss: 651.3586 - val_loss: 612.7988\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 603.3422 - val_loss: 567.5468\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 5ms/step - loss: 558.1777 - val_loss: 522.5028\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 513.2404 - val_loss: 479.0383\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 472.6555 - val_loss: 439.4172\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 432.9920 - val_loss: 401.6401\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 397.3892 - val_loss: 367.4348\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 363.6791 - val_loss: 334.5071\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 333.3853 - val_loss: 304.4693\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 5ms/step - loss: 304.9328 - val_loss: 277.3392\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 281.1454 - val_loss: 254.8902\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 260.6326 - val_loss: 235.0801\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 241.8872 - val_loss: 217.9434\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 226.6017 - val_loss: 204.4982\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 213.8283 - val_loss: 192.8027\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 203.1288 - val_loss: 183.1372\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 7ms/step - loss: 193.4531 - val_loss: 174.8480\n",
            "Epoch 38/100\n",
            "73/73 - 1s - 7ms/step - loss: 186.2157 - val_loss: 168.3997\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 180.0585 - val_loss: 163.3605\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.8255 - val_loss: 159.2636\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 170.1681 - val_loss: 155.8361\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 166.5803 - val_loss: 153.0188\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 163.5990 - val_loss: 150.3613\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 5ms/step - loss: 160.7737 - val_loss: 148.2707\n",
            "Epoch 45/100\n",
            "73/73 - 1s - 7ms/step - loss: 158.1464 - val_loss: 146.3752\n",
            "Epoch 46/100\n",
            "73/73 - 1s - 7ms/step - loss: 155.7303 - val_loss: 144.3764\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 2ms/step - loss: 153.5503 - val_loss: 142.6472\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.2122 - val_loss: 140.7918\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 148.9024 - val_loss: 138.8434\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 146.5493 - val_loss: 136.8903\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 2ms/step - loss: 144.2885 - val_loss: 134.9137\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 141.8495 - val_loss: 132.8786\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 139.4525 - val_loss: 130.7807\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.9212 - val_loss: 128.7850\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 134.5376 - val_loss: 126.4550\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.1904 - val_loss: 124.4298\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.7560 - val_loss: 122.4350\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.4149 - val_loss: 120.4469\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.0564 - val_loss: 118.2327\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.7898 - val_loss: 115.9162\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 120.5663 - val_loss: 113.5568\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.1088 - val_loss: 111.2795\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.6191 - val_loss: 108.9761\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.4113 - val_loss: 106.6402\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.0193 - val_loss: 104.4076\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.6216 - val_loss: 102.3660\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 2ms/step - loss: 106.3292 - val_loss: 100.2746\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 2ms/step - loss: 103.9532 - val_loss: 98.1399\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.5658 - val_loss: 95.9766\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.3817 - val_loss: 93.5216\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.0069 - val_loss: 91.9702\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.7654 - val_loss: 89.7353\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.5611 - val_loss: 87.8382\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.4215 - val_loss: 85.8233\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 5ms/step - loss: 88.4391 - val_loss: 84.0478\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.4663 - val_loss: 82.5186\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.7327 - val_loss: 81.1446\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 82.9705 - val_loss: 79.5677\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.2080 - val_loss: 78.0695\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.6162 - val_loss: 76.6833\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.1777 - val_loss: 75.2453\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.7161 - val_loss: 73.9539\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.3188 - val_loss: 72.8142\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.0068 - val_loss: 71.8827\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.9355 - val_loss: 70.7749\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 5ms/step - loss: 71.6455 - val_loss: 69.7717\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.4314 - val_loss: 68.6081\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.4363 - val_loss: 67.9427\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 5ms/step - loss: 68.2631 - val_loss: 66.9113\n",
            "Epoch 90/100\n",
            "73/73 - 1s - 7ms/step - loss: 67.1463 - val_loss: 66.0081\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.1074 - val_loss: 64.8998\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.0148 - val_loss: 63.8289\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.0188 - val_loss: 63.1118\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.3606 - val_loss: 62.9503\n",
            "Epoch 95/100\n",
            "73/73 - 1s - 8ms/step - loss: 62.0977 - val_loss: 61.8788\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 61.1930 - val_loss: 61.0993\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 60.3032 - val_loss: 60.1583\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 59.5574 - val_loss: 59.5055\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 58.6278 - val_loss: 58.7438\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 2ms/step - loss: 57.9400 - val_loss: 58.0876\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1531.3671 - val_loss: 1442.4904\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 7ms/step - loss: 1476.3079 - val_loss: 1383.2010\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1414.9766 - val_loss: 1319.5648\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1347.9215 - val_loss: 1248.5724\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1274.1228 - val_loss: 1172.7238\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1194.3965 - val_loss: 1092.4373\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1108.8065 - val_loss: 1008.1767\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 2ms/step - loss: 1020.3167 - val_loss: 921.7271\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 5ms/step - loss: 930.3719 - val_loss: 836.9966\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 2ms/step - loss: 841.5123 - val_loss: 752.8841\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 5ms/step - loss: 753.9167 - val_loss: 670.1508\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 668.3142 - val_loss: 590.4070\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 586.1187 - val_loss: 516.6331\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 508.7891 - val_loss: 446.2426\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 438.4843 - val_loss: 385.0183\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 377.9623 - val_loss: 335.1155\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 2ms/step - loss: 329.1303 - val_loss: 294.1850\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 289.3161 - val_loss: 263.1397\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 258.3368 - val_loss: 239.7103\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 235.2619 - val_loss: 221.7920\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 2ms/step - loss: 217.7844 - val_loss: 210.1365\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 204.7884 - val_loss: 199.8486\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 195.0747 - val_loss: 193.0304\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 187.4771 - val_loss: 187.5449\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 181.0148 - val_loss: 182.7686\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 175.6291 - val_loss: 178.6995\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 5ms/step - loss: 170.9491 - val_loss: 175.1409\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 166.7743 - val_loss: 172.1002\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 5ms/step - loss: 162.7371 - val_loss: 168.4715\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 5ms/step - loss: 159.1546 - val_loss: 165.5060\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.9315 - val_loss: 162.6416\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.7567 - val_loss: 159.8848\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 5ms/step - loss: 150.0840 - val_loss: 157.8195\n",
            "Epoch 34/100\n",
            "73/73 - 1s - 7ms/step - loss: 147.4868 - val_loss: 155.3968\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.3900 - val_loss: 153.9089\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.4504 - val_loss: 152.1534\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.5487 - val_loss: 150.0340\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.8299 - val_loss: 148.6172\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.1770 - val_loss: 147.2828\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.6069 - val_loss: 145.4251\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.0447 - val_loss: 144.2782\n",
            "Epoch 42/100\n",
            "73/73 - 1s - 7ms/step - loss: 133.8671 - val_loss: 143.4277\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.4134 - val_loss: 142.2614\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.1145 - val_loss: 141.4545\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.2259 - val_loss: 140.1659\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 5ms/step - loss: 129.0563 - val_loss: 139.4428\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.9937 - val_loss: 138.4747\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 126.8321 - val_loss: 137.4113\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.7829 - val_loss: 136.2316\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 5ms/step - loss: 124.7661 - val_loss: 135.5612\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.7633 - val_loss: 135.0529\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.7739 - val_loss: 134.2744\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.0854 - val_loss: 133.1233\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.0845 - val_loss: 132.2310\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 5ms/step - loss: 120.3026 - val_loss: 130.4018\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 2ms/step - loss: 119.2800 - val_loss: 129.8983\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 2ms/step - loss: 118.3836 - val_loss: 129.3940\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 5ms/step - loss: 117.6593 - val_loss: 128.5772\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.7721 - val_loss: 128.1406\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.0105 - val_loss: 127.1963\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 2ms/step - loss: 115.1365 - val_loss: 126.1101\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.3408 - val_loss: 125.6679\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 2ms/step - loss: 113.5212 - val_loss: 125.0239\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.7258 - val_loss: 124.3220\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.1334 - val_loss: 124.0003\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.2355 - val_loss: 122.7354\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.3729 - val_loss: 121.9906\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.6660 - val_loss: 121.2302\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.8743 - val_loss: 120.5537\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.2427 - val_loss: 120.1587\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.5522 - val_loss: 119.4228\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.8814 - val_loss: 119.0462\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.1444 - val_loss: 118.3991\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.5845 - val_loss: 117.8259\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.0109 - val_loss: 117.2671\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.3034 - val_loss: 117.0125\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.7932 - val_loss: 116.5614\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 5ms/step - loss: 103.3536 - val_loss: 115.8163\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.5796 - val_loss: 115.6921\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.0147 - val_loss: 115.0346\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.5857 - val_loss: 114.3750\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.8665 - val_loss: 113.7861\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.2398 - val_loss: 113.8686\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.8488 - val_loss: 113.4187\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.3721 - val_loss: 112.7893\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.8898 - val_loss: 112.6054\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.4515 - val_loss: 111.8049\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.0055 - val_loss: 111.1477\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.3963 - val_loss: 110.7372\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.1714 - val_loss: 110.5042\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.3963 - val_loss: 110.2740\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.2957 - val_loss: 109.8999\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 95.5246 - val_loss: 109.2303\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.2668 - val_loss: 109.1371\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 94.6754 - val_loss: 108.3426\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.3094 - val_loss: 107.8952\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.0094 - val_loss: 107.3130\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.4692 - val_loss: 107.2542\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 5ms/step - loss: 93.0190 - val_loss: 106.6667\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.6250 - val_loss: 106.4992\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1568.8186 - val_loss: 1448.7322\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1524.2456 - val_loss: 1402.4482\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1475.3679 - val_loss: 1350.2434\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1420.5443 - val_loss: 1294.0233\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1360.0160 - val_loss: 1231.1111\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1293.1995 - val_loss: 1164.6141\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1221.0533 - val_loss: 1092.4849\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1143.3695 - val_loss: 1017.0353\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 1062.5370 - val_loss: 940.5482\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 980.6968 - val_loss: 863.5212\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 5ms/step - loss: 899.3176 - val_loss: 788.6296\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 819.5137 - val_loss: 715.2705\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 742.0961 - val_loss: 647.2722\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 669.3939 - val_loss: 583.0774\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 602.1834 - val_loss: 526.0306\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 540.5315 - val_loss: 474.5246\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 485.5276 - val_loss: 428.4586\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 436.0398 - val_loss: 388.8975\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 392.1046 - val_loss: 354.7256\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 2ms/step - loss: 355.0071 - val_loss: 326.5549\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 2ms/step - loss: 324.3430 - val_loss: 302.9254\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 298.3081 - val_loss: 283.2955\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 5ms/step - loss: 276.6780 - val_loss: 267.5427\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 259.3213 - val_loss: 254.5736\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 5ms/step - loss: 244.9402 - val_loss: 244.1133\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 232.9335 - val_loss: 235.1583\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 222.9848 - val_loss: 226.8854\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 214.2284 - val_loss: 220.1618\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 206.5592 - val_loss: 214.4772\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 200.4524 - val_loss: 209.0324\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 194.6035 - val_loss: 204.0157\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 189.3630 - val_loss: 199.5463\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 184.4846 - val_loss: 194.9835\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 179.9166 - val_loss: 191.0797\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 175.7704 - val_loss: 187.1315\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 172.2708 - val_loss: 183.6455\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.6906 - val_loss: 180.5100\n",
            "Epoch 38/100\n",
            "73/73 - 1s - 7ms/step - loss: 165.2765 - val_loss: 177.4850\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.0948 - val_loss: 174.0063\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.2400 - val_loss: 170.8704\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.0920 - val_loss: 167.8909\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 5ms/step - loss: 153.2758 - val_loss: 165.1473\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.5950 - val_loss: 162.2157\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.8179 - val_loss: 159.6520\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.3409 - val_loss: 157.0822\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.8364 - val_loss: 154.2373\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.2608 - val_loss: 151.5374\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.9108 - val_loss: 149.0260\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 135.7372 - val_loss: 146.0117\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.5157 - val_loss: 143.9056\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 2ms/step - loss: 131.6860 - val_loss: 141.8476\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 129.7844 - val_loss: 139.8542\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.9329 - val_loss: 138.3737\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.0881 - val_loss: 136.4079\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.4124 - val_loss: 134.5901\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 2ms/step - loss: 122.7380 - val_loss: 132.2566\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 121.1361 - val_loss: 130.7231\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.5045 - val_loss: 128.9227\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.9666 - val_loss: 127.4492\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.5391 - val_loss: 125.8094\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.9945 - val_loss: 124.2290\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.6534 - val_loss: 123.0321\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.1895 - val_loss: 121.3135\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.7447 - val_loss: 119.2056\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.0406 - val_loss: 117.5312\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.3349 - val_loss: 115.5422\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.6313 - val_loss: 113.7097\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.7631 - val_loss: 111.7039\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.8399 - val_loss: 109.5774\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.9928 - val_loss: 107.9202\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 2ms/step - loss: 98.3244 - val_loss: 106.0069\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.5165 - val_loss: 104.3172\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.8229 - val_loss: 102.4554\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.3828 - val_loss: 100.4710\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.8560 - val_loss: 98.8598\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.2462 - val_loss: 97.2185\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.7641 - val_loss: 95.8085\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3253 - val_loss: 94.2312\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.9079 - val_loss: 92.6115\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.5519 - val_loss: 90.9757\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.9958 - val_loss: 89.4126\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.4465 - val_loss: 87.6049\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.9746 - val_loss: 85.8329\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.3207 - val_loss: 84.1237\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.5883 - val_loss: 82.3745\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.0497 - val_loss: 80.5321\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.4490 - val_loss: 79.1196\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.9380 - val_loss: 77.6329\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 70.4835 - val_loss: 76.0616\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 69.2150 - val_loss: 74.9302\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 68.1400 - val_loss: 73.5226\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 67.1595 - val_loss: 72.3164\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 65.9356 - val_loss: 70.9044\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 5ms/step - loss: 65.0118 - val_loss: 69.7828\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 64.0099 - val_loss: 68.9504\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 5ms/step - loss: 63.1398 - val_loss: 67.7845\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.2907 - val_loss: 66.8290\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 5ms/step - loss: 61.3831 - val_loss: 65.7246\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 60.6131 - val_loss: 65.0094\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 59.9215 - val_loss: 63.9381\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1563.5161 - val_loss: 1536.9769\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1524.2311 - val_loss: 1497.3766\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1478.2375 - val_loss: 1450.4325\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1422.0007 - val_loss: 1393.3959\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1354.4287 - val_loss: 1327.0272\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 2ms/step - loss: 1276.6199 - val_loss: 1250.2891\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 2ms/step - loss: 1190.7653 - val_loss: 1167.6927\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 5ms/step - loss: 1098.1478 - val_loss: 1079.5739\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 1005.3531 - val_loss: 990.6016\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 2ms/step - loss: 912.7349 - val_loss: 900.8013\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 822.3832 - val_loss: 811.3266\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 734.8917 - val_loss: 723.3632\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 650.7064 - val_loss: 636.5162\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 571.9056 - val_loss: 554.7925\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 499.7018 - val_loss: 479.8849\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 435.0935 - val_loss: 416.8141\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 379.3190 - val_loss: 361.2057\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 332.7780 - val_loss: 317.0878\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 294.8259 - val_loss: 281.6598\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 264.3197 - val_loss: 254.6281\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 240.6051 - val_loss: 232.9061\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 222.3236 - val_loss: 217.1469\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 208.0800 - val_loss: 205.5554\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 3ms/step - loss: 196.2905 - val_loss: 194.6565\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 187.2734 - val_loss: 187.0003\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 179.8409 - val_loss: 180.5928\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.8350 - val_loss: 175.3595\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.5939 - val_loss: 171.3269\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.3161 - val_loss: 167.7292\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.6260 - val_loss: 164.4281\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.2133 - val_loss: 161.1629\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.0025 - val_loss: 158.7741\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.1387 - val_loss: 155.6591\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.2896 - val_loss: 153.2719\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.9675 - val_loss: 151.6862\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.6071 - val_loss: 149.4426\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.3313 - val_loss: 147.4403\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.5701 - val_loss: 144.4538\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 137.7819 - val_loss: 143.3810\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.2241 - val_loss: 142.6142\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 2ms/step - loss: 135.0391 - val_loss: 141.8570\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 2ms/step - loss: 133.9534 - val_loss: 141.3436\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.6366 - val_loss: 140.3006\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 131.7333 - val_loss: 139.6084\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.7632 - val_loss: 139.6177\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 129.8019 - val_loss: 138.5731\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 129.1231 - val_loss: 137.1615\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 2ms/step - loss: 128.0572 - val_loss: 136.6685\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.1653 - val_loss: 135.6745\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.3820 - val_loss: 135.1655\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 5ms/step - loss: 125.5632 - val_loss: 134.6829\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 124.7634 - val_loss: 134.0081\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.9757 - val_loss: 133.2298\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.1745 - val_loss: 132.0258\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.2510 - val_loss: 131.3824\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 2ms/step - loss: 121.5365 - val_loss: 130.8018\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 120.6405 - val_loss: 130.0331\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.9316 - val_loss: 128.9300\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.1884 - val_loss: 128.5388\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.5621 - val_loss: 127.5651\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 117.5774 - val_loss: 127.0154\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.9535 - val_loss: 125.8023\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.2557 - val_loss: 124.9299\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.3493 - val_loss: 123.9955\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.6294 - val_loss: 123.4170\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.0017 - val_loss: 121.8636\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.2084 - val_loss: 120.9987\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.6592 - val_loss: 120.3083\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.9041 - val_loss: 118.9662\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.0669 - val_loss: 118.8937\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.4184 - val_loss: 118.4033\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.5163 - val_loss: 116.9496\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 108.7423 - val_loss: 116.0579\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.2062 - val_loss: 115.5042\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.4218 - val_loss: 114.4796\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.8379 - val_loss: 113.9409\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 5ms/step - loss: 106.0477 - val_loss: 112.8525\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.4052 - val_loss: 112.9139\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.7520 - val_loss: 111.6298\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.0021 - val_loss: 110.7356\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.3785 - val_loss: 110.0254\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.6732 - val_loss: 108.9729\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.9786 - val_loss: 108.0600\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.4644 - val_loss: 107.6040\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.7699 - val_loss: 106.7495\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.1180 - val_loss: 105.7143\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.4761 - val_loss: 105.1199\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.9120 - val_loss: 104.3771\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.2185 - val_loss: 103.6377\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.6555 - val_loss: 103.0229\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.0183 - val_loss: 102.6926\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.6005 - val_loss: 101.4844\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.0025 - val_loss: 100.7698\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.3780 - val_loss: 100.3051\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 94.8596 - val_loss: 99.3815\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.2197 - val_loss: 98.2612\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.8140 - val_loss: 98.6058\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.1725 - val_loss: 97.8064\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.6776 - val_loss: 97.0229\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.1311 - val_loss: 96.5678\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1553.4922 - val_loss: 1443.6218\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1505.1383 - val_loss: 1394.9741\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1454.2405 - val_loss: 1343.1326\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 2ms/step - loss: 1398.9114 - val_loss: 1286.8757\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 5ms/step - loss: 1336.6735 - val_loss: 1224.6023\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1266.1969 - val_loss: 1154.9565\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 2ms/step - loss: 1186.7554 - val_loss: 1078.4747\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1100.3198 - val_loss: 995.3208\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 1009.7208 - val_loss: 910.1833\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 917.0650 - val_loss: 822.3085\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 823.5687 - val_loss: 737.9088\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 732.6961 - val_loss: 656.1888\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 647.2189 - val_loss: 579.6157\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 568.5473 - val_loss: 509.9703\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 500.0407 - val_loss: 447.9164\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 440.0610 - val_loss: 396.7762\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 388.6119 - val_loss: 351.0655\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 344.8799 - val_loss: 312.9908\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 309.0435 - val_loss: 282.6718\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 280.0374 - val_loss: 256.8775\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 3ms/step - loss: 256.7986 - val_loss: 236.9165\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 238.1770 - val_loss: 220.8982\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 223.9413 - val_loss: 208.1798\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 3ms/step - loss: 212.1375 - val_loss: 198.0791\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 202.3486 - val_loss: 189.0567\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 194.2108 - val_loss: 182.2426\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 187.8329 - val_loss: 176.3205\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 182.1438 - val_loss: 171.1970\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 177.2945 - val_loss: 166.3081\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.1551 - val_loss: 162.4538\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 169.0506 - val_loss: 158.8253\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.8392 - val_loss: 155.5816\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.4675 - val_loss: 152.5353\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.2030 - val_loss: 149.5733\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.2746 - val_loss: 146.9563\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 3ms/step - loss: 153.3742 - val_loss: 144.4447\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.6591 - val_loss: 141.8132\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 5ms/step - loss: 147.8888 - val_loss: 139.5966\n",
            "Epoch 39/100\n",
            "73/73 - 1s - 8ms/step - loss: 145.2610 - val_loss: 136.8041\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 3ms/step - loss: 142.7462 - val_loss: 134.5675\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.2057 - val_loss: 132.3949\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.6782 - val_loss: 129.9989\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 135.1418 - val_loss: 127.8295\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 132.8866 - val_loss: 126.3785\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.7435 - val_loss: 124.6001\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.5008 - val_loss: 122.8813\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.5848 - val_loss: 121.0398\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 124.5800 - val_loss: 119.1881\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.6420 - val_loss: 117.8134\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 120.7075 - val_loss: 115.9300\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.1569 - val_loss: 114.4693\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 117.3110 - val_loss: 112.4868\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.5965 - val_loss: 111.2812\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.0517 - val_loss: 110.0356\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.5599 - val_loss: 108.6991\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.9023 - val_loss: 107.4359\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.3561 - val_loss: 106.4014\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 5ms/step - loss: 107.9463 - val_loss: 105.0887\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.7661 - val_loss: 104.0313\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.3064 - val_loss: 102.4520\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.0003 - val_loss: 101.7694\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 2ms/step - loss: 102.8387 - val_loss: 100.4509\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.7611 - val_loss: 99.7521\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.6172 - val_loss: 98.8773\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 5ms/step - loss: 99.3481 - val_loss: 98.1741\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 2ms/step - loss: 98.2962 - val_loss: 97.4346\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 2ms/step - loss: 97.2982 - val_loss: 96.1449\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.2365 - val_loss: 95.3484\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.2169 - val_loss: 94.4546\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 94.2503 - val_loss: 93.2755\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 2ms/step - loss: 93.2619 - val_loss: 92.4474\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.6779 - val_loss: 91.5192\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.5168 - val_loss: 90.5546\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.6420 - val_loss: 90.2505\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.8108 - val_loss: 89.3496\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 2ms/step - loss: 88.9313 - val_loss: 88.5904\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.2357 - val_loss: 88.0608\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.3828 - val_loss: 87.8082\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 5ms/step - loss: 86.5905 - val_loss: 87.4293\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.6512 - val_loss: 86.2965\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.9785 - val_loss: 85.4396\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.3587 - val_loss: 84.3058\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.5262 - val_loss: 83.5502\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.9646 - val_loss: 82.9633\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.2503 - val_loss: 81.4877\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.6881 - val_loss: 81.3237\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.7571 - val_loss: 80.6547\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.1917 - val_loss: 80.2159\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.5438 - val_loss: 79.2128\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.7491 - val_loss: 78.8053\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.8230 - val_loss: 78.0048\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.1009 - val_loss: 77.6746\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.2787 - val_loss: 76.9711\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.3871 - val_loss: 76.6048\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.5805 - val_loss: 75.7603\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.7827 - val_loss: 74.8480\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.0158 - val_loss: 74.2472\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.1652 - val_loss: 73.4143\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.5879 - val_loss: 72.9559\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.9412 - val_loss: 71.6854\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1468.3555 - val_loss: 1497.6931\n",
            "Epoch 2/100\n",
            "73/73 - 1s - 7ms/step - loss: 1405.6725 - val_loss: 1434.8069\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1337.4113 - val_loss: 1367.0874\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1263.7808 - val_loss: 1292.3430\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1183.0564 - val_loss: 1210.4781\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1096.8280 - val_loss: 1125.2954\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1006.9739 - val_loss: 1034.1670\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 915.0902 - val_loss: 941.1835\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 823.2802 - val_loss: 848.3824\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 735.3856 - val_loss: 760.0955\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 2ms/step - loss: 652.6036 - val_loss: 675.9658\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 576.2217 - val_loss: 596.7675\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 5ms/step - loss: 508.0035 - val_loss: 527.2968\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 448.5965 - val_loss: 465.0342\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 397.6566 - val_loss: 411.0056\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 354.5785 - val_loss: 366.0780\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 318.7639 - val_loss: 326.8439\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 290.4058 - val_loss: 296.6079\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 267.7972 - val_loss: 271.3448\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 249.2860 - val_loss: 252.1213\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 234.6944 - val_loss: 237.2716\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 222.9833 - val_loss: 224.9460\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 213.2089 - val_loss: 214.7947\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 205.1476 - val_loss: 206.2644\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 198.3018 - val_loss: 199.8143\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 192.6094 - val_loss: 194.6643\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 187.6980 - val_loss: 189.6268\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 182.9601 - val_loss: 185.5089\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.7612 - val_loss: 181.3321\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.8263 - val_loss: 177.8493\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.3487 - val_loss: 174.4190\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.0242 - val_loss: 171.8024\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.8086 - val_loss: 170.0494\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.0432 - val_loss: 168.2840\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.0017 - val_loss: 164.1256\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 156.5833 - val_loss: 161.4426\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.3169 - val_loss: 159.2657\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.9839 - val_loss: 157.2592\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.2528 - val_loss: 155.7751\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.0055 - val_loss: 153.4118\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 146.2784 - val_loss: 151.5812\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 144.4405 - val_loss: 150.2202\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.7743 - val_loss: 149.1552\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 141.2730 - val_loss: 147.1544\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 2ms/step - loss: 139.8384 - val_loss: 145.4087\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 138.5600 - val_loss: 144.2000\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 137.1308 - val_loss: 142.4353\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.8231 - val_loss: 142.5165\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 2ms/step - loss: 134.5485 - val_loss: 139.3479\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.2817 - val_loss: 138.3395\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 132.0421 - val_loss: 136.7094\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.8681 - val_loss: 135.3743\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 129.5912 - val_loss: 134.4390\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.3433 - val_loss: 131.9187\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 5ms/step - loss: 126.8880 - val_loss: 130.7034\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.4789 - val_loss: 129.4066\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 124.2029 - val_loss: 128.0146\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.7584 - val_loss: 126.0983\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.4394 - val_loss: 125.1254\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.9016 - val_loss: 123.2693\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.3473 - val_loss: 121.8302\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.9384 - val_loss: 120.7162\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 5ms/step - loss: 115.5092 - val_loss: 119.3458\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.1085 - val_loss: 117.8799\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7420 - val_loss: 116.8375\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.3410 - val_loss: 115.0387\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.9993 - val_loss: 114.0425\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.4610 - val_loss: 112.7617\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.0035 - val_loss: 111.0445\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.7321 - val_loss: 110.1782\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 2ms/step - loss: 104.4316 - val_loss: 109.1135\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 103.0788 - val_loss: 107.5664\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.8176 - val_loss: 106.9652\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.3572 - val_loss: 104.7902\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.1022 - val_loss: 103.2641\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.6187 - val_loss: 102.0443\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 96.4828 - val_loss: 100.8923\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 94.8594 - val_loss: 99.0569\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 2ms/step - loss: 93.6613 - val_loss: 97.5658\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.3728 - val_loss: 96.4306\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.9440 - val_loss: 95.4168\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 5ms/step - loss: 89.8500 - val_loss: 94.2704\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.6291 - val_loss: 92.6649\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3090 - val_loss: 91.8196\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.1925 - val_loss: 90.3766\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.9702 - val_loss: 89.4123\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.7853 - val_loss: 88.0376\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.6303 - val_loss: 87.1507\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.5514 - val_loss: 85.9045\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.4444 - val_loss: 84.6981\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3725 - val_loss: 83.6179\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 5ms/step - loss: 78.4508 - val_loss: 82.5161\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.4891 - val_loss: 81.8069\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.5254 - val_loss: 80.9290\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 7ms/step - loss: 75.7344 - val_loss: 79.8516\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.8699 - val_loss: 79.5443\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.9572 - val_loss: 78.4297\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.1976 - val_loss: 77.7190\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.4677 - val_loss: 76.9587\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.8140 - val_loss: 75.9068\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1571.3655 - val_loss: 1522.6897\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1527.5459 - val_loss: 1478.7509\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1481.4413 - val_loss: 1431.5275\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1431.6815 - val_loss: 1379.5742\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 5ms/step - loss: 1377.0464 - val_loss: 1322.4988\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1316.2740 - val_loss: 1258.8750\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1249.5184 - val_loss: 1189.4105\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 5ms/step - loss: 1176.8088 - val_loss: 1114.0819\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 1098.6660 - val_loss: 1034.8590\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 5ms/step - loss: 1015.5462 - val_loss: 950.7398\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 929.5720 - val_loss: 866.3074\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 2ms/step - loss: 842.9973 - val_loss: 779.8226\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 2ms/step - loss: 755.7776 - val_loss: 695.5055\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 670.2732 - val_loss: 613.9609\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 589.6336 - val_loss: 538.5584\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 515.0817 - val_loss: 471.4754\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 2ms/step - loss: 449.4924 - val_loss: 412.5181\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 2ms/step - loss: 392.3777 - val_loss: 362.2574\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 345.5004 - val_loss: 321.4136\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 307.1701 - val_loss: 289.6509\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 277.0899 - val_loss: 264.3030\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 253.8287 - val_loss: 243.9450\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 236.2751 - val_loss: 228.9860\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 222.6654 - val_loss: 215.7484\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 211.7033 - val_loss: 206.1626\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 3ms/step - loss: 203.2575 - val_loss: 197.5816\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 196.2903 - val_loss: 190.2203\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 190.0124 - val_loss: 183.3889\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 184.9472 - val_loss: 177.8912\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 180.1205 - val_loss: 173.0797\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 175.7907 - val_loss: 168.1068\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.9532 - val_loss: 164.1601\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.2905 - val_loss: 160.3527\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.0294 - val_loss: 157.1232\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 161.7339 - val_loss: 153.5732\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.6608 - val_loss: 150.5872\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.8477 - val_loss: 147.5091\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.9368 - val_loss: 144.8309\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.4335 - val_loss: 142.2566\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.0833 - val_loss: 139.7517\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.4389 - val_loss: 136.5353\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 5ms/step - loss: 143.0888 - val_loss: 134.1803\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 140.6923 - val_loss: 131.9779\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.4937 - val_loss: 129.5342\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.1654 - val_loss: 127.0094\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.0080 - val_loss: 124.5406\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 131.7689 - val_loss: 122.1786\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 129.7384 - val_loss: 119.9812\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.7976 - val_loss: 117.8081\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 125.3829 - val_loss: 115.3597\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 2ms/step - loss: 123.4246 - val_loss: 113.4271\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 121.5659 - val_loss: 111.2392\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 2ms/step - loss: 119.4885 - val_loss: 109.0795\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 2ms/step - loss: 117.7547 - val_loss: 106.8272\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.0296 - val_loss: 105.3718\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.2857 - val_loss: 103.5374\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.5986 - val_loss: 101.8087\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.8560 - val_loss: 100.2486\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.4334 - val_loss: 98.9826\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 107.9955 - val_loss: 97.4742\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.6165 - val_loss: 96.0507\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 2ms/step - loss: 105.2683 - val_loss: 94.4902\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.9517 - val_loss: 93.3750\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.7144 - val_loss: 91.7731\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 2ms/step - loss: 101.5553 - val_loss: 90.8148\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 2ms/step - loss: 100.3081 - val_loss: 89.6764\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.0653 - val_loss: 87.9220\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.8963 - val_loss: 86.8887\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.6261 - val_loss: 85.3305\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.6890 - val_loss: 84.8064\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.4782 - val_loss: 83.5991\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.6460 - val_loss: 82.8686\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.4508 - val_loss: 81.8269\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 91.4919 - val_loss: 80.7638\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.6689 - val_loss: 79.6220\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 2ms/step - loss: 89.6812 - val_loss: 78.6964\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 88.8686 - val_loss: 77.7812\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 2ms/step - loss: 87.9444 - val_loss: 76.9818\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.1027 - val_loss: 75.9791\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 2ms/step - loss: 86.1465 - val_loss: 75.4242\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.4483 - val_loss: 74.6872\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.6634 - val_loss: 73.9151\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.7459 - val_loss: 72.9126\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.9686 - val_loss: 72.4582\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.1217 - val_loss: 71.6312\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.4490 - val_loss: 71.2269\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.7131 - val_loss: 70.5351\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.0282 - val_loss: 69.4117\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3389 - val_loss: 69.0100\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.5891 - val_loss: 68.3394\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.0190 - val_loss: 67.9011\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.3552 - val_loss: 67.4823\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.7925 - val_loss: 66.6396\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.1629 - val_loss: 65.9491\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.5850 - val_loss: 65.3268\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.9813 - val_loss: 64.6541\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 5ms/step - loss: 74.4747 - val_loss: 64.5275\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 7ms/step - loss: 73.8870 - val_loss: 63.9176\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.4505 - val_loss: 63.6507\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 2ms/step - loss: 72.8742 - val_loss: 63.0975\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 14ms/step - loss: 1566.1045 - val_loss: 1529.3691\n",
            "Epoch 2/100\n",
            "73/73 - 1s - 7ms/step - loss: 1517.7318 - val_loss: 1479.9408\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1466.2540 - val_loss: 1426.1382\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1409.3241 - val_loss: 1367.0236\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1345.9943 - val_loss: 1303.1752\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1277.8811 - val_loss: 1233.9493\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1203.7378 - val_loss: 1159.3533\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1125.6744 - val_loss: 1080.9642\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 3ms/step - loss: 1044.3586 - val_loss: 999.2689\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 959.7311 - val_loss: 915.2776\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 873.4868 - val_loss: 830.4761\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 788.5046 - val_loss: 747.3482\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 704.7169 - val_loss: 667.9896\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 5ms/step - loss: 627.0171 - val_loss: 594.9752\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 554.4507 - val_loss: 525.6483\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 487.4080 - val_loss: 464.1539\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 429.4808 - val_loss: 411.2529\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 379.8325 - val_loss: 366.9698\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 338.2200 - val_loss: 329.2901\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 303.2052 - val_loss: 298.6852\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 2ms/step - loss: 274.1260 - val_loss: 273.7401\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 251.1427 - val_loss: 253.9475\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 2ms/step - loss: 232.7406 - val_loss: 238.5034\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 218.9336 - val_loss: 226.9845\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 208.6075 - val_loss: 218.5101\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 200.1452 - val_loss: 211.4154\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 193.4771 - val_loss: 205.8267\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 188.0888 - val_loss: 201.1240\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 5ms/step - loss: 183.1602 - val_loss: 196.6854\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.9252 - val_loss: 192.9480\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 5ms/step - loss: 175.0953 - val_loss: 189.3653\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.8842 - val_loss: 186.4307\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.6094 - val_loss: 183.4587\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.7122 - val_loss: 180.8065\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.8621 - val_loss: 178.0617\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.0561 - val_loss: 175.2483\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.2483 - val_loss: 172.8195\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 154.6076 - val_loss: 169.9123\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.8366 - val_loss: 167.4796\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.2633 - val_loss: 165.0184\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.9522 - val_loss: 162.6828\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.4808 - val_loss: 160.6462\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.2411 - val_loss: 158.3945\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.9234 - val_loss: 155.9934\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.6074 - val_loss: 153.7464\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 135.3862 - val_loss: 151.7184\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.1048 - val_loss: 149.7489\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.9504 - val_loss: 147.6200\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.7583 - val_loss: 145.4663\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 126.6123 - val_loss: 143.8543\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 124.3538 - val_loss: 141.7399\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 2ms/step - loss: 122.1663 - val_loss: 139.8899\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.0247 - val_loss: 137.6557\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.0450 - val_loss: 135.8008\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.1630 - val_loss: 134.1293\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.0416 - val_loss: 131.6586\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.2993 - val_loss: 129.6968\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.3591 - val_loss: 128.2805\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.8274 - val_loss: 126.1483\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.8359 - val_loss: 124.1071\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 5ms/step - loss: 105.0435 - val_loss: 122.4276\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.3057 - val_loss: 120.7465\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.8156 - val_loss: 119.2028\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.0328 - val_loss: 117.1550\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.4780 - val_loss: 115.4106\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.8063 - val_loss: 113.5090\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 95.2305 - val_loss: 111.4869\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.6964 - val_loss: 110.4966\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.0121 - val_loss: 108.3003\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.6401 - val_loss: 106.8280\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.9952 - val_loss: 104.5077\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.5214 - val_loss: 103.3320\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.0376 - val_loss: 101.4130\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.6741 - val_loss: 99.8192\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.4270 - val_loss: 98.4467\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.1955 - val_loss: 96.8932\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 80.8630 - val_loss: 95.3152\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.7847 - val_loss: 94.4345\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.5339 - val_loss: 92.3425\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.5769 - val_loss: 92.3609\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.3001 - val_loss: 90.0618\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 5ms/step - loss: 75.3184 - val_loss: 88.8858\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.4107 - val_loss: 87.6811\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 5ms/step - loss: 73.4235 - val_loss: 86.1050\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.3841 - val_loss: 85.0688\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.5501 - val_loss: 84.1550\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 70.6424 - val_loss: 82.9813\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.8093 - val_loss: 81.9074\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.9727 - val_loss: 81.1535\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.2470 - val_loss: 80.2147\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.3358 - val_loss: 79.3787\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.7282 - val_loss: 78.1001\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.1621 - val_loss: 77.6801\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.4167 - val_loss: 76.8125\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.8610 - val_loss: 76.1736\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.3064 - val_loss: 75.1155\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.6627 - val_loss: 74.2473\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 63.0651 - val_loss: 73.4649\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.6362 - val_loss: 72.6577\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.1235 - val_loss: 72.0606\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 13ms/step - loss: 1553.8796 - val_loss: 1381.6793\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1510.4000 - val_loss: 1338.0881\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1459.9133 - val_loss: 1287.2689\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1399.2249 - val_loss: 1225.5016\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1324.5435 - val_loss: 1148.3569\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1235.2260 - val_loss: 1059.0715\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 2ms/step - loss: 1131.6097 - val_loss: 959.2386\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 2ms/step - loss: 1018.3315 - val_loss: 854.0968\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 903.0099 - val_loss: 750.7003\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 2ms/step - loss: 789.0161 - val_loss: 653.8291\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 2ms/step - loss: 681.1479 - val_loss: 562.8909\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 584.9902 - val_loss: 485.1413\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 499.1715 - val_loss: 419.4119\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 428.3701 - val_loss: 367.3718\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 371.0562 - val_loss: 324.9793\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 324.7215 - val_loss: 293.0788\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 289.8603 - val_loss: 269.3109\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 263.1241 - val_loss: 251.7033\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 242.7966 - val_loss: 238.6771\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 227.4958 - val_loss: 228.2852\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 3ms/step - loss: 215.2346 - val_loss: 219.9447\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 205.7988 - val_loss: 213.2243\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 198.0932 - val_loss: 207.3708\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 191.7292 - val_loss: 202.0504\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 185.9651 - val_loss: 197.5347\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 3ms/step - loss: 180.9938 - val_loss: 192.8530\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 176.3290 - val_loss: 188.7609\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 172.3098 - val_loss: 184.9707\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 2ms/step - loss: 168.4711 - val_loss: 180.9002\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 164.9046 - val_loss: 177.1935\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 161.4634 - val_loss: 173.9026\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 2ms/step - loss: 158.2998 - val_loss: 170.7547\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 3ms/step - loss: 155.2384 - val_loss: 167.9969\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.4364 - val_loss: 165.3314\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.8662 - val_loss: 162.6971\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.2559 - val_loss: 160.3420\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.0395 - val_loss: 158.2591\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.9083 - val_loss: 156.1963\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.0224 - val_loss: 154.6984\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.2618 - val_loss: 152.6043\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.4993 - val_loss: 150.5291\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.0410 - val_loss: 149.0031\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.4832 - val_loss: 147.8489\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.1666 - val_loss: 146.6784\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.9290 - val_loss: 145.2547\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.5735 - val_loss: 144.1146\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.6532 - val_loss: 143.2973\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.5181 - val_loss: 142.2137\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.5394 - val_loss: 140.9840\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 126.5460 - val_loss: 140.0176\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 2ms/step - loss: 125.5735 - val_loss: 138.8730\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 124.6651 - val_loss: 137.6686\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 2ms/step - loss: 123.8549 - val_loss: 136.9475\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.9873 - val_loss: 135.9100\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 122.1606 - val_loss: 135.5822\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.4863 - val_loss: 134.6080\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.0013 - val_loss: 133.8152\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 120.1621 - val_loss: 133.4091\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.8117 - val_loss: 132.4106\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 5ms/step - loss: 119.0061 - val_loss: 131.9226\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.4888 - val_loss: 131.4572\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.1016 - val_loss: 130.6363\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 5ms/step - loss: 117.6026 - val_loss: 130.0847\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.2670 - val_loss: 129.6772\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 116.7666 - val_loss: 129.0156\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.3514 - val_loss: 128.7719\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.0499 - val_loss: 128.0883\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.8162 - val_loss: 127.6738\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.3055 - val_loss: 127.4031\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 114.9808 - val_loss: 126.9336\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.6993 - val_loss: 126.6140\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.1775 - val_loss: 125.9753\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 114.0393 - val_loss: 125.7950\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.7460 - val_loss: 125.1497\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.3136 - val_loss: 124.7031\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 5ms/step - loss: 112.9324 - val_loss: 123.9467\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7062 - val_loss: 123.9452\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.3647 - val_loss: 123.5274\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.1308 - val_loss: 123.4015\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.8351 - val_loss: 122.9759\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.6626 - val_loss: 122.8622\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.2556 - val_loss: 122.5862\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 2ms/step - loss: 111.0334 - val_loss: 122.2516\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.8156 - val_loss: 121.5226\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.6808 - val_loss: 120.5992\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.4043 - val_loss: 120.8465\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.1110 - val_loss: 120.6647\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 109.7925 - val_loss: 120.9381\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.5953 - val_loss: 120.2116\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 5ms/step - loss: 109.3894 - val_loss: 120.0493\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.3495 - val_loss: 119.8810\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.0577 - val_loss: 119.8447\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.8810 - val_loss: 119.3161\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.6985 - val_loss: 119.1846\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.4118 - val_loss: 118.6621\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.3396 - val_loss: 118.8734\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.2138 - val_loss: 118.4357\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.9395 - val_loss: 118.0984\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.5596 - val_loss: 117.8259\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.6098 - val_loss: 117.5756\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 18ms/step - loss: 1542.1595 - val_loss: 1477.1036\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1493.0663 - val_loss: 1426.4125\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1440.3264 - val_loss: 1369.9707\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1381.1451 - val_loss: 1307.2119\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 2ms/step - loss: 1314.4956 - val_loss: 1235.2837\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 2ms/step - loss: 1238.2083 - val_loss: 1156.5264\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1159.2573 - val_loss: 1074.1879\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1074.0076 - val_loss: 987.9657\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 984.1102 - val_loss: 896.7674\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 890.9879 - val_loss: 804.3149\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 798.2251 - val_loss: 716.2579\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 708.2137 - val_loss: 633.6020\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 622.5389 - val_loss: 555.6218\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 546.0651 - val_loss: 489.1678\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 478.3352 - val_loss: 430.2535\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 420.3658 - val_loss: 381.7527\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 370.2787 - val_loss: 339.9407\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 328.5482 - val_loss: 305.7455\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 295.6012 - val_loss: 279.2882\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 268.8275 - val_loss: 257.0786\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 2ms/step - loss: 247.3750 - val_loss: 240.1276\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 230.1413 - val_loss: 226.2032\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 216.3145 - val_loss: 215.3906\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 205.5785 - val_loss: 206.8331\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 196.7049 - val_loss: 199.7428\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 189.6111 - val_loss: 194.0860\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 183.8115 - val_loss: 189.2558\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 178.9700 - val_loss: 185.0690\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.5380 - val_loss: 181.6404\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 5ms/step - loss: 170.6007 - val_loss: 178.4043\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.1111 - val_loss: 175.1026\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 5ms/step - loss: 163.9459 - val_loss: 172.6916\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 161.0433 - val_loss: 170.1534\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 158.2234 - val_loss: 167.4990\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.6669 - val_loss: 165.1401\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 3ms/step - loss: 153.0834 - val_loss: 163.4809\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 3ms/step - loss: 150.5878 - val_loss: 161.2595\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 148.0476 - val_loss: 159.1534\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 145.8920 - val_loss: 157.1502\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.6515 - val_loss: 155.4541\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.3277 - val_loss: 153.4496\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 139.1352 - val_loss: 151.6459\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 5ms/step - loss: 136.9677 - val_loss: 149.9115\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.0703 - val_loss: 148.1913\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.2807 - val_loss: 146.6529\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.5436 - val_loss: 145.2717\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.8474 - val_loss: 143.7738\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 128.1441 - val_loss: 142.4326\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 5ms/step - loss: 126.3578 - val_loss: 140.8820\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.6969 - val_loss: 139.5568\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 123.0741 - val_loss: 138.1762\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 121.6198 - val_loss: 136.9152\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 6ms/step - loss: 119.9051 - val_loss: 135.4836\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 2ms/step - loss: 118.4918 - val_loss: 134.2578\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 116.8600 - val_loss: 132.6586\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.4071 - val_loss: 131.5271\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.0379 - val_loss: 130.0785\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.6841 - val_loss: 128.7926\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 2ms/step - loss: 111.4571 - val_loss: 127.4860\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.9955 - val_loss: 126.1096\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.5761 - val_loss: 124.8087\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.2614 - val_loss: 123.5180\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.8799 - val_loss: 122.2139\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 2ms/step - loss: 104.5521 - val_loss: 120.9695\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 2ms/step - loss: 103.3496 - val_loss: 119.7507\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.9350 - val_loss: 118.4513\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.7035 - val_loss: 117.3008\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.3711 - val_loss: 116.0860\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.2240 - val_loss: 114.8674\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 97.0742 - val_loss: 113.5622\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 5ms/step - loss: 95.6680 - val_loss: 112.4914\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 94.6007 - val_loss: 111.2670\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 2ms/step - loss: 93.3801 - val_loss: 110.0873\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.1872 - val_loss: 108.9395\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 91.0232 - val_loss: 107.6895\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.7753 - val_loss: 106.4889\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.8365 - val_loss: 105.3567\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.5695 - val_loss: 104.1993\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.5534 - val_loss: 103.0307\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.2714 - val_loss: 102.0511\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 5ms/step - loss: 84.2138 - val_loss: 100.9003\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.1770 - val_loss: 99.8649\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.1396 - val_loss: 98.8288\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 5ms/step - loss: 81.2313 - val_loss: 97.9233\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.1641 - val_loss: 96.8757\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3771 - val_loss: 96.2815\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.1546 - val_loss: 94.8453\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 5ms/step - loss: 77.1927 - val_loss: 93.5543\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.2994 - val_loss: 92.7710\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.4926 - val_loss: 91.7078\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.4856 - val_loss: 90.8363\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 5ms/step - loss: 73.6141 - val_loss: 89.7666\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.7800 - val_loss: 88.9197\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.0195 - val_loss: 88.0761\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.1484 - val_loss: 87.1474\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.3781 - val_loss: 86.2728\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.5474 - val_loss: 85.1852\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.6171 - val_loss: 84.2146\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.7555 - val_loss: 83.7495\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.0815 - val_loss: 82.8721\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 18ms/step - loss: 1512.0609 - val_loss: 1413.0547\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1462.9929 - val_loss: 1361.4561\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1408.6160 - val_loss: 1304.8250\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1347.8658 - val_loss: 1242.3781\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1281.5110 - val_loss: 1174.0167\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1208.8479 - val_loss: 1100.0221\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1128.3743 - val_loss: 1020.7660\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1043.3623 - val_loss: 934.9169\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 953.1871 - val_loss: 845.8430\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 859.2719 - val_loss: 755.2718\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 766.7300 - val_loss: 666.9556\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 676.6155 - val_loss: 582.6723\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 589.8627 - val_loss: 503.9048\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 510.2402 - val_loss: 433.6041\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 439.8824 - val_loss: 372.7452\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 379.2164 - val_loss: 322.8935\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 329.2588 - val_loss: 282.4798\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 290.0859 - val_loss: 251.6387\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 258.6954 - val_loss: 227.8701\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 234.9697 - val_loss: 209.8613\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 217.3981 - val_loss: 197.6442\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 204.2751 - val_loss: 187.7414\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 5ms/step - loss: 194.1405 - val_loss: 180.0717\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 186.1020 - val_loss: 174.6169\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 2ms/step - loss: 179.4129 - val_loss: 169.2433\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 2ms/step - loss: 174.1578 - val_loss: 164.9990\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 5ms/step - loss: 169.7612 - val_loss: 161.9541\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 165.9860 - val_loss: 158.5525\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 2ms/step - loss: 162.7450 - val_loss: 155.5684\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 159.7338 - val_loss: 153.1780\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 157.2674 - val_loss: 150.9044\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 5ms/step - loss: 154.7762 - val_loss: 148.6062\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.5523 - val_loss: 146.8162\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.5267 - val_loss: 144.9169\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.5440 - val_loss: 143.2940\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 5ms/step - loss: 146.7806 - val_loss: 141.4570\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.0712 - val_loss: 140.0314\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.2988 - val_loss: 138.5260\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 5ms/step - loss: 141.8951 - val_loss: 137.2111\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.4563 - val_loss: 135.5201\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.9583 - val_loss: 134.3740\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.6051 - val_loss: 132.8727\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.2885 - val_loss: 132.0832\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.1248 - val_loss: 130.9932\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.7282 - val_loss: 129.7992\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.4713 - val_loss: 128.4333\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.9947 - val_loss: 127.2650\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.5633 - val_loss: 125.7584\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.1115 - val_loss: 124.8972\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.8728 - val_loss: 123.6863\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.4648 - val_loss: 122.6499\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 124.2253 - val_loss: 121.4557\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 2ms/step - loss: 123.1647 - val_loss: 121.1805\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.6030 - val_loss: 120.0095\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.6007 - val_loss: 119.2346\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 2ms/step - loss: 119.3438 - val_loss: 117.6555\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.1669 - val_loss: 116.7010\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 117.0722 - val_loss: 115.5108\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.7347 - val_loss: 114.4846\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 2ms/step - loss: 114.4160 - val_loss: 112.9487\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 5ms/step - loss: 113.3526 - val_loss: 112.0023\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.8786 - val_loss: 110.8833\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 5ms/step - loss: 110.6010 - val_loss: 109.6515\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.4616 - val_loss: 108.3219\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 2ms/step - loss: 108.2028 - val_loss: 107.3021\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 5ms/step - loss: 106.8558 - val_loss: 106.3403\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.6121 - val_loss: 104.9773\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.3686 - val_loss: 103.7015\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.0362 - val_loss: 102.7119\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 101.8757 - val_loss: 101.3154\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.7278 - val_loss: 100.6333\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.6310 - val_loss: 99.0732\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.4050 - val_loss: 98.3291\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.2846 - val_loss: 97.2136\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.1440 - val_loss: 96.0710\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.9176 - val_loss: 95.2706\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.9211 - val_loss: 94.1405\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.7794 - val_loss: 92.5716\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.9354 - val_loss: 91.7092\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.9873 - val_loss: 91.1296\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 5ms/step - loss: 89.9690 - val_loss: 90.6125\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.0962 - val_loss: 89.9160\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.9949 - val_loss: 89.0110\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.1329 - val_loss: 87.9999\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 86.2325 - val_loss: 87.2554\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 5ms/step - loss: 85.2887 - val_loss: 86.5644\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.4214 - val_loss: 85.8580\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.6692 - val_loss: 85.1495\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 82.7974 - val_loss: 84.0106\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.0038 - val_loss: 83.3150\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.1324 - val_loss: 82.7742\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.3175 - val_loss: 81.8182\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.4963 - val_loss: 80.9013\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.6308 - val_loss: 80.4295\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.8658 - val_loss: 79.8038\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 77.1707 - val_loss: 79.2858\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.6230 - val_loss: 78.2124\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.7094 - val_loss: 77.6870\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.0577 - val_loss: 77.4779\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.4896 - val_loss: 76.6666\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 18ms/step - loss: 1506.2241 - val_loss: 1501.7573\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 2ms/step - loss: 1458.0979 - val_loss: 1452.4708\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1405.5609 - val_loss: 1398.6797\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 2ms/step - loss: 1347.6729 - val_loss: 1336.2246\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1280.6420 - val_loss: 1264.8695\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1205.9089 - val_loss: 1184.1862\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1121.0315 - val_loss: 1093.2025\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 2ms/step - loss: 1029.9979 - val_loss: 998.8359\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 936.5181 - val_loss: 902.8638\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 3ms/step - loss: 844.3451 - val_loss: 807.5461\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 755.4235 - val_loss: 717.2652\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 673.5796 - val_loss: 635.2308\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 601.0316 - val_loss: 562.2897\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 536.6376 - val_loss: 496.9252\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 480.5811 - val_loss: 440.7104\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 432.3371 - val_loss: 393.6197\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 389.5821 - val_loss: 351.0684\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 352.2229 - val_loss: 315.4980\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 320.1736 - val_loss: 284.2363\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 292.4607 - val_loss: 258.4882\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 268.3299 - val_loss: 237.0570\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 248.0402 - val_loss: 219.0643\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 5ms/step - loss: 230.7298 - val_loss: 203.4158\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 216.0078 - val_loss: 191.2747\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 204.1181 - val_loss: 181.7066\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 2ms/step - loss: 194.7800 - val_loss: 174.2098\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 187.1428 - val_loss: 168.3146\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 180.8193 - val_loss: 163.9311\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 3ms/step - loss: 175.2350 - val_loss: 159.0549\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 171.0609 - val_loss: 156.3819\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 167.4336 - val_loss: 153.7685\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 164.4955 - val_loss: 151.4019\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 2ms/step - loss: 161.5736 - val_loss: 149.4341\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.8424 - val_loss: 147.5131\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 2ms/step - loss: 156.3018 - val_loss: 145.4436\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.9135 - val_loss: 144.4080\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 2ms/step - loss: 151.8771 - val_loss: 142.7421\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 5ms/step - loss: 149.6145 - val_loss: 140.6664\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 5ms/step - loss: 147.5257 - val_loss: 138.8952\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.3642 - val_loss: 137.3442\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.3197 - val_loss: 135.6497\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.6824 - val_loss: 134.1011\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.8727 - val_loss: 132.3389\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.3737 - val_loss: 130.7746\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.7412 - val_loss: 129.8440\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.2922 - val_loss: 128.4984\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.8106 - val_loss: 126.8369\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 132.4461 - val_loss: 125.9048\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.1796 - val_loss: 124.7286\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.9569 - val_loss: 123.8469\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.5974 - val_loss: 122.6562\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 127.3983 - val_loss: 122.0301\n",
            "Epoch 53/100\n",
            "73/73 - 1s - 8ms/step - loss: 126.2797 - val_loss: 120.8472\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 3ms/step - loss: 124.8997 - val_loss: 119.8459\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.8086 - val_loss: 119.1036\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.8491 - val_loss: 118.2238\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.8297 - val_loss: 117.4353\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.8055 - val_loss: 116.8802\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 2ms/step - loss: 119.7424 - val_loss: 116.1290\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 2ms/step - loss: 118.8287 - val_loss: 115.2739\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 2ms/step - loss: 117.8376 - val_loss: 114.4790\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.8304 - val_loss: 113.8421\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.8626 - val_loss: 112.8922\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 5ms/step - loss: 115.0748 - val_loss: 112.3419\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.1015 - val_loss: 111.2995\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 2ms/step - loss: 113.2743 - val_loss: 110.5113\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 2ms/step - loss: 112.4075 - val_loss: 109.7368\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 2ms/step - loss: 111.6510 - val_loss: 109.0494\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.8006 - val_loss: 108.4163\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 109.8873 - val_loss: 107.6226\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 5ms/step - loss: 109.0591 - val_loss: 106.9859\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 108.5207 - val_loss: 106.3350\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 5ms/step - loss: 107.6519 - val_loss: 105.1991\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.9239 - val_loss: 104.7074\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 2ms/step - loss: 105.9506 - val_loss: 103.8637\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.1402 - val_loss: 102.9816\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.3777 - val_loss: 102.4534\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.5445 - val_loss: 101.6886\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.7557 - val_loss: 100.6562\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.9883 - val_loss: 99.8515\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.0469 - val_loss: 99.2788\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 100.2067 - val_loss: 98.4721\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 2ms/step - loss: 99.5466 - val_loss: 97.9603\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 98.6798 - val_loss: 97.0017\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 97.8685 - val_loss: 96.2239\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.1376 - val_loss: 96.0268\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.3252 - val_loss: 95.1014\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.5151 - val_loss: 94.4062\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.6768 - val_loss: 93.5151\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 94.1756 - val_loss: 92.8892\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.2287 - val_loss: 92.2213\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 5ms/step - loss: 92.6994 - val_loss: 91.6742\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.8242 - val_loss: 91.2196\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.1950 - val_loss: 90.2612\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.5244 - val_loss: 89.5447\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.8339 - val_loss: 89.1143\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.3083 - val_loss: 88.5039\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.8184 - val_loss: 88.1419\n",
            "Epoch 99/100\n",
            "73/73 - 1s - 8ms/step - loss: 88.1777 - val_loss: 88.0179\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.7658 - val_loss: 87.5231\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 20ms/step - loss: 1515.2872 - val_loss: 1505.3562\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 5ms/step - loss: 1469.9790 - val_loss: 1460.1381\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1417.6844 - val_loss: 1407.3527\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1356.1392 - val_loss: 1343.4832\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1283.6891 - val_loss: 1269.8101\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1200.5693 - val_loss: 1185.2190\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 5ms/step - loss: 1106.0366 - val_loss: 1091.6674\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1002.1755 - val_loss: 987.6784\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 890.4352 - val_loss: 880.0733\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 3ms/step - loss: 778.1392 - val_loss: 773.3229\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 2ms/step - loss: 673.4684 - val_loss: 674.9273\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 577.9470 - val_loss: 584.2484\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 495.6133 - val_loss: 507.1660\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 426.5200 - val_loss: 442.0992\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 370.0481 - val_loss: 388.2647\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 325.7507 - val_loss: 345.1086\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 291.9550 - val_loss: 310.4667\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 265.6399 - val_loss: 283.2856\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 245.7320 - val_loss: 261.3061\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 230.1731 - val_loss: 243.5068\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 217.7571 - val_loss: 229.8295\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 208.1409 - val_loss: 218.6626\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 2ms/step - loss: 200.1790 - val_loss: 209.1912\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 193.4806 - val_loss: 201.5578\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 2ms/step - loss: 187.6353 - val_loss: 194.2670\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 182.4495 - val_loss: 187.9753\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 177.8539 - val_loss: 182.4811\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 173.8407 - val_loss: 177.7498\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 2ms/step - loss: 170.0606 - val_loss: 173.0479\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 5ms/step - loss: 166.4989 - val_loss: 167.9367\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 163.3492 - val_loss: 164.4467\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.4034 - val_loss: 160.6991\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 2ms/step - loss: 157.4897 - val_loss: 157.2231\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 154.8500 - val_loss: 153.9248\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 152.4264 - val_loss: 151.5807\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.0907 - val_loss: 148.6890\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.6107 - val_loss: 146.2658\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 145.4064 - val_loss: 143.6172\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.3354 - val_loss: 140.8688\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 3ms/step - loss: 141.0444 - val_loss: 138.1396\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 2ms/step - loss: 139.2898 - val_loss: 135.5864\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 5ms/step - loss: 137.1419 - val_loss: 133.6422\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.2556 - val_loss: 131.1067\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.4468 - val_loss: 129.2409\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 131.5154 - val_loss: 126.9068\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.3980 - val_loss: 124.2255\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.6781 - val_loss: 122.1331\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.0303 - val_loss: 120.5948\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.2276 - val_loss: 118.5358\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.5004 - val_loss: 116.3447\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.9170 - val_loss: 114.5297\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.4310 - val_loss: 112.8878\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.9168 - val_loss: 111.0761\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.2378 - val_loss: 109.5013\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.7881 - val_loss: 107.6850\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.4121 - val_loss: 106.2620\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.1384 - val_loss: 104.8239\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 2ms/step - loss: 110.7195 - val_loss: 103.3726\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.1530 - val_loss: 101.4844\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.0166 - val_loss: 100.3668\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.6679 - val_loss: 98.8565\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.4789 - val_loss: 97.7736\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 2ms/step - loss: 104.2467 - val_loss: 96.0937\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.1319 - val_loss: 95.0038\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 5ms/step - loss: 101.9445 - val_loss: 93.5785\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.8809 - val_loss: 92.7067\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 2ms/step - loss: 99.7162 - val_loss: 91.3962\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.7029 - val_loss: 90.2995\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 97.7171 - val_loss: 89.3208\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.7030 - val_loss: 88.2858\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.7066 - val_loss: 87.2450\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.8512 - val_loss: 86.4981\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 5ms/step - loss: 93.8557 - val_loss: 85.4033\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.0970 - val_loss: 84.6410\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.9926 - val_loss: 83.6013\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.0418 - val_loss: 82.4399\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.2151 - val_loss: 81.9826\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 5ms/step - loss: 89.3063 - val_loss: 80.9641\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.4131 - val_loss: 80.2022\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.6779 - val_loss: 78.9334\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 2ms/step - loss: 86.5921 - val_loss: 77.9124\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 85.8182 - val_loss: 77.2462\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.1090 - val_loss: 76.5190\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.0786 - val_loss: 75.8167\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 83.4508 - val_loss: 74.9980\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 2ms/step - loss: 82.5494 - val_loss: 74.1483\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 5ms/step - loss: 81.5526 - val_loss: 73.3756\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.7453 - val_loss: 72.6221\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.0592 - val_loss: 71.8926\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.1929 - val_loss: 71.5341\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.4685 - val_loss: 70.7816\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 77.5625 - val_loss: 69.9400\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.8943 - val_loss: 69.2562\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 5ms/step - loss: 76.3608 - val_loss: 68.6093\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.5382 - val_loss: 67.9334\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.8306 - val_loss: 67.4402\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 5ms/step - loss: 74.1901 - val_loss: 67.0200\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.4491 - val_loss: 66.2731\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.7814 - val_loss: 65.8274\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.3093 - val_loss: 65.0519\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 18ms/step - loss: 1536.1521 - val_loss: 1485.4729\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1487.1836 - val_loss: 1437.9697\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1434.6206 - val_loss: 1386.1877\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 3ms/step - loss: 1376.2812 - val_loss: 1327.1194\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 2ms/step - loss: 1308.8809 - val_loss: 1259.1361\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1234.4326 - val_loss: 1185.0535\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1154.0558 - val_loss: 1106.4688\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 2ms/step - loss: 1067.7982 - val_loss: 1024.7111\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 979.9783 - val_loss: 940.6011\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 5ms/step - loss: 891.9874 - val_loss: 857.7266\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 804.8248 - val_loss: 775.9855\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 719.5246 - val_loss: 695.5722\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 639.4037 - val_loss: 619.0643\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 2ms/step - loss: 563.8156 - val_loss: 548.4052\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 5ms/step - loss: 494.7877 - val_loss: 482.9033\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 432.8932 - val_loss: 421.9697\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 377.6432 - val_loss: 371.1220\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 331.8844 - val_loss: 327.7456\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 294.1353 - val_loss: 291.2235\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 264.1301 - val_loss: 262.2391\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 2ms/step - loss: 239.6927 - val_loss: 238.7301\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 220.8996 - val_loss: 219.2664\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 2ms/step - loss: 206.7055 - val_loss: 206.7402\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 195.5164 - val_loss: 195.1805\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 186.8861 - val_loss: 186.4662\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 3ms/step - loss: 179.7556 - val_loss: 179.3476\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 2ms/step - loss: 173.7214 - val_loss: 173.8856\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 169.2002 - val_loss: 169.4590\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 165.6781 - val_loss: 165.6410\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 162.1599 - val_loss: 162.3623\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.2272 - val_loss: 159.2265\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 156.2831 - val_loss: 156.5803\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 2ms/step - loss: 153.8112 - val_loss: 154.3350\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.9734 - val_loss: 152.1364\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.7886 - val_loss: 150.2345\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.6579 - val_loss: 148.3281\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.5634 - val_loss: 146.1829\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 2ms/step - loss: 142.4446 - val_loss: 144.2519\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 5ms/step - loss: 140.2773 - val_loss: 142.8326\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.1921 - val_loss: 140.6451\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 2ms/step - loss: 136.0724 - val_loss: 138.1738\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.5868 - val_loss: 135.3490\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.4892 - val_loss: 133.7088\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 5ms/step - loss: 129.3564 - val_loss: 132.1769\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.1853 - val_loss: 130.0159\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.3929 - val_loss: 128.0257\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.2380 - val_loss: 126.1140\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 121.2260 - val_loss: 124.3104\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.2174 - val_loss: 122.2290\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.1570 - val_loss: 120.3334\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.2672 - val_loss: 118.7033\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.4653 - val_loss: 116.6661\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.7482 - val_loss: 115.4149\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.1872 - val_loss: 113.3929\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.7454 - val_loss: 112.0048\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.0029 - val_loss: 110.7124\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 105.3967 - val_loss: 109.2382\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.9716 - val_loss: 107.5784\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 5ms/step - loss: 102.4489 - val_loss: 106.2642\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.0368 - val_loss: 104.7068\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.5979 - val_loss: 103.1159\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 2ms/step - loss: 98.3257 - val_loss: 101.7501\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.8206 - val_loss: 100.4411\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.6131 - val_loss: 99.2724\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.4803 - val_loss: 98.2841\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.2336 - val_loss: 96.9115\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.0846 - val_loss: 95.7989\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 5ms/step - loss: 90.9756 - val_loss: 94.6492\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.0847 - val_loss: 93.6879\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 5ms/step - loss: 89.0348 - val_loss: 92.7148\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.1896 - val_loss: 91.4221\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3542 - val_loss: 90.6482\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.5959 - val_loss: 89.9525\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.7434 - val_loss: 89.2182\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 2ms/step - loss: 84.9494 - val_loss: 88.2732\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 2ms/step - loss: 84.2912 - val_loss: 87.4322\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 83.5952 - val_loss: 86.6925\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 2ms/step - loss: 82.7892 - val_loss: 85.6075\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.2519 - val_loss: 85.1493\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.6005 - val_loss: 84.1847\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.9501 - val_loss: 83.3832\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.4554 - val_loss: 82.8317\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 2ms/step - loss: 79.9506 - val_loss: 82.2627\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3434 - val_loss: 81.4366\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.8958 - val_loss: 81.1128\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.3171 - val_loss: 80.2426\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 2ms/step - loss: 77.8819 - val_loss: 79.6633\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.3409 - val_loss: 78.9377\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.0264 - val_loss: 78.0918\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.6222 - val_loss: 77.8597\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 2ms/step - loss: 76.1296 - val_loss: 77.5772\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.6194 - val_loss: 77.1533\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.2590 - val_loss: 76.5529\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.8318 - val_loss: 76.0473\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.2038 - val_loss: 75.1972\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 5ms/step - loss: 73.8758 - val_loss: 74.6038\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 5ms/step - loss: 73.3064 - val_loss: 74.3010\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.8096 - val_loss: 73.6356\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.5064 - val_loss: 72.9535\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.7995 - val_loss: 72.3189\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 19ms/step - loss: 1454.5312 - val_loss: 1594.5863\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 4ms/step - loss: 1406.6129 - val_loss: 1534.2173\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1348.7810 - val_loss: 1461.5302\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1279.8019 - val_loss: 1376.4160\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1199.8490 - val_loss: 1279.9150\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1110.6522 - val_loss: 1173.9352\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1015.1386 - val_loss: 1063.6914\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 916.3352 - val_loss: 952.4249\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 817.6544 - val_loss: 844.2457\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 3ms/step - loss: 723.5217 - val_loss: 741.5152\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 635.5406 - val_loss: 648.2213\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 2ms/step - loss: 557.0286 - val_loss: 569.8277\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 486.4488 - val_loss: 499.5089\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 426.4488 - val_loss: 441.1142\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 376.1077 - val_loss: 394.0196\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 2ms/step - loss: 334.6354 - val_loss: 356.0574\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 301.0741 - val_loss: 325.7443\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 274.4605 - val_loss: 302.9361\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 252.5450 - val_loss: 283.5674\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 235.9738 - val_loss: 268.0710\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 222.5726 - val_loss: 255.7904\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 211.7522 - val_loss: 245.3442\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 203.1177 - val_loss: 236.4798\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 5ms/step - loss: 195.7161 - val_loss: 228.9194\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 189.0428 - val_loss: 220.9516\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 183.6683 - val_loss: 214.5451\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 2ms/step - loss: 178.9415 - val_loss: 208.3270\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 174.4567 - val_loss: 202.6887\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 3ms/step - loss: 170.8335 - val_loss: 197.8313\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.1257 - val_loss: 192.2951\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 163.9240 - val_loss: 187.7217\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.8017 - val_loss: 183.6913\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.8850 - val_loss: 179.3293\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.1196 - val_loss: 175.5817\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 2ms/step - loss: 152.5526 - val_loss: 172.5344\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.1811 - val_loss: 168.8176\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 3ms/step - loss: 147.8427 - val_loss: 165.6244\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 145.5758 - val_loss: 162.8277\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.5324 - val_loss: 159.5973\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 141.5376 - val_loss: 156.7884\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.7003 - val_loss: 154.1825\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.1459 - val_loss: 151.5969\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.5233 - val_loss: 149.3901\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 5ms/step - loss: 134.9830 - val_loss: 147.1465\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 5ms/step - loss: 133.6053 - val_loss: 145.5307\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.2441 - val_loss: 143.1140\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.0124 - val_loss: 141.2472\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.6716 - val_loss: 139.3913\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.3056 - val_loss: 137.7295\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.0301 - val_loss: 135.3537\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.2844 - val_loss: 133.8134\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.8434 - val_loss: 131.6724\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.0849 - val_loss: 129.2165\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.8424 - val_loss: 127.7235\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.2033 - val_loss: 126.7599\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.8356 - val_loss: 124.7213\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.3766 - val_loss: 122.7673\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.1168 - val_loss: 120.8386\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.7479 - val_loss: 119.6298\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.4553 - val_loss: 117.9208\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 5ms/step - loss: 111.0979 - val_loss: 116.4847\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.8056 - val_loss: 114.5693\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.5334 - val_loss: 112.8616\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 2ms/step - loss: 107.2691 - val_loss: 111.8789\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 5ms/step - loss: 105.9677 - val_loss: 109.8074\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.9010 - val_loss: 108.0845\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.6800 - val_loss: 106.9591\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 2ms/step - loss: 102.5692 - val_loss: 105.3902\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 2ms/step - loss: 101.2942 - val_loss: 104.2100\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.0849 - val_loss: 102.8390\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.0925 - val_loss: 102.2002\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.8038 - val_loss: 100.9559\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.7670 - val_loss: 98.7365\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.4307 - val_loss: 97.4398\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 5ms/step - loss: 94.4379 - val_loss: 96.4683\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.1190 - val_loss: 94.8915\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.9071 - val_loss: 93.6430\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 5ms/step - loss: 90.6554 - val_loss: 92.1184\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 2ms/step - loss: 89.6652 - val_loss: 91.2741\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.5298 - val_loss: 90.2694\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3316 - val_loss: 88.8514\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 2ms/step - loss: 86.2666 - val_loss: 87.7750\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 85.1281 - val_loss: 86.5191\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 84.4517 - val_loss: 85.5816\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 83.1925 - val_loss: 84.1381\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 2ms/step - loss: 82.2042 - val_loss: 83.4139\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.1917 - val_loss: 82.3488\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.1615 - val_loss: 81.3987\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 79.1676 - val_loss: 80.2313\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.2890 - val_loss: 79.0206\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.3883 - val_loss: 78.4602\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 5ms/step - loss: 76.5758 - val_loss: 77.4934\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.5293 - val_loss: 76.4041\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.7665 - val_loss: 75.7881\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 73.8784 - val_loss: 74.5538\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 5ms/step - loss: 72.9677 - val_loss: 73.9477\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 2ms/step - loss: 72.2503 - val_loss: 73.5733\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 2ms/step - loss: 71.3211 - val_loss: 72.9264\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 2ms/step - loss: 70.5906 - val_loss: 71.6312\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 69.7780 - val_loss: 70.8413\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 20ms/step - loss: 1502.5137 - val_loss: 1582.2396\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1448.3237 - val_loss: 1521.0675\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1388.3429 - val_loss: 1453.6556\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1320.3652 - val_loss: 1378.2507\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1246.4308 - val_loss: 1295.3911\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1165.3474 - val_loss: 1205.3553\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1079.5149 - val_loss: 1111.2905\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 989.5961 - val_loss: 1014.4466\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 899.1900 - val_loss: 917.3177\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 2ms/step - loss: 809.9415 - val_loss: 823.3782\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 724.4072 - val_loss: 733.8409\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 2ms/step - loss: 643.8538 - val_loss: 648.8442\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 3ms/step - loss: 569.6005 - val_loss: 572.6686\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 503.4047 - val_loss: 504.7101\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 445.2134 - val_loss: 447.3223\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 2ms/step - loss: 395.6797 - val_loss: 399.0079\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 353.8899 - val_loss: 358.0484\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 319.5070 - val_loss: 326.6813\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 291.2512 - val_loss: 300.6777\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 268.9264 - val_loss: 280.9343\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 250.9701 - val_loss: 264.9710\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 5ms/step - loss: 236.5182 - val_loss: 252.5669\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 224.7823 - val_loss: 242.4777\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 5ms/step - loss: 214.8942 - val_loss: 234.0557\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 206.7312 - val_loss: 226.3226\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 2ms/step - loss: 199.5502 - val_loss: 219.2788\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 193.3062 - val_loss: 213.4581\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 187.7545 - val_loss: 207.7459\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 182.7321 - val_loss: 202.3436\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 177.9138 - val_loss: 197.4094\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.4274 - val_loss: 191.7496\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 169.4359 - val_loss: 187.3651\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 3ms/step - loss: 165.0427 - val_loss: 182.0304\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 161.2324 - val_loss: 177.9356\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 157.3240 - val_loss: 172.9007\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 153.6800 - val_loss: 169.3547\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 5ms/step - loss: 150.1088 - val_loss: 165.0799\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 2ms/step - loss: 146.7106 - val_loss: 161.2649\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.3007 - val_loss: 157.5729\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 140.1625 - val_loss: 153.8565\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.0364 - val_loss: 150.0504\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.4081 - val_loss: 147.1839\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 5ms/step - loss: 131.5051 - val_loss: 143.2380\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.9185 - val_loss: 140.3597\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 126.6061 - val_loss: 137.2806\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.9698 - val_loss: 134.6730\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.5708 - val_loss: 131.5518\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 119.1938 - val_loss: 128.5630\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.5096 - val_loss: 125.8084\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.5369 - val_loss: 123.6572\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.2229 - val_loss: 120.6624\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.2859 - val_loss: 118.3758\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.3501 - val_loss: 115.8071\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.6030 - val_loss: 113.7154\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.7818 - val_loss: 111.3565\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.0136 - val_loss: 109.5381\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.4721 - val_loss: 107.8409\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.8438 - val_loss: 105.6931\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.5048 - val_loss: 104.0062\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.7633 - val_loss: 102.3251\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.2664 - val_loss: 100.7583\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.8567 - val_loss: 98.9376\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.4476 - val_loss: 97.5987\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.9906 - val_loss: 95.5314\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.7393 - val_loss: 94.1392\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.5814 - val_loss: 92.4845\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.4108 - val_loss: 91.0536\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.1236 - val_loss: 89.4027\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 84.8783 - val_loss: 88.5052\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.9426 - val_loss: 87.6279\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.8207 - val_loss: 86.5129\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 5ms/step - loss: 81.9032 - val_loss: 85.4178\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.8608 - val_loss: 84.1841\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 79.8226 - val_loss: 83.2400\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 78.9976 - val_loss: 82.5182\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.0061 - val_loss: 81.4311\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.2510 - val_loss: 80.4565\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 2ms/step - loss: 76.3831 - val_loss: 79.8136\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.5732 - val_loss: 78.4246\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.7783 - val_loss: 78.1099\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.8116 - val_loss: 77.5126\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.9463 - val_loss: 76.3076\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 72.1453 - val_loss: 75.2352\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 71.1697 - val_loss: 74.3947\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.3837 - val_loss: 73.1869\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 69.5737 - val_loss: 72.2488\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.9189 - val_loss: 71.8628\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 68.2457 - val_loss: 71.0385\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.3591 - val_loss: 69.8776\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 66.6305 - val_loss: 69.1358\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.8014 - val_loss: 68.4963\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 65.2681 - val_loss: 67.5456\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 64.3767 - val_loss: 67.3470\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.8068 - val_loss: 66.3273\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.1781 - val_loss: 65.9085\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 62.4889 - val_loss: 64.8081\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.0758 - val_loss: 64.5502\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 61.5194 - val_loss: 64.1404\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 2ms/step - loss: 61.0067 - val_loss: 63.3736\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 2ms/step - loss: 60.5310 - val_loss: 62.8642\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 16ms/step - loss: 1502.0354 - val_loss: 1494.7286\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1451.2117 - val_loss: 1442.7135\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1393.1646 - val_loss: 1382.3098\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1325.9214 - val_loss: 1312.8398\n",
            "Epoch 5/100\n",
            "73/73 - 1s - 7ms/step - loss: 1249.5698 - val_loss: 1235.4742\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1165.4092 - val_loss: 1148.4558\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1074.3124 - val_loss: 1057.2699\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 978.0860 - val_loss: 963.6125\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 884.4099 - val_loss: 870.7757\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 792.4142 - val_loss: 779.5012\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 704.2720 - val_loss: 692.3724\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 621.9875 - val_loss: 612.6440\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 547.6783 - val_loss: 539.4246\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 481.2240 - val_loss: 474.0237\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 424.3820 - val_loss: 416.8831\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 375.8859 - val_loss: 369.6518\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 2ms/step - loss: 335.6313 - val_loss: 328.7971\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 303.2850 - val_loss: 296.2112\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 2ms/step - loss: 277.3159 - val_loss: 268.9801\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 256.4599 - val_loss: 247.2855\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 5ms/step - loss: 239.2420 - val_loss: 228.5427\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 226.0728 - val_loss: 214.1573\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 214.6088 - val_loss: 201.8857\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 205.8019 - val_loss: 192.0116\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 198.5296 - val_loss: 184.2865\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 2ms/step - loss: 192.5553 - val_loss: 177.5645\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 186.7277 - val_loss: 170.9478\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 3ms/step - loss: 181.9082 - val_loss: 166.1779\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 177.8139 - val_loss: 161.8331\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 5ms/step - loss: 174.1598 - val_loss: 157.8244\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 170.8136 - val_loss: 154.4954\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 167.7213 - val_loss: 151.4314\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 3ms/step - loss: 164.4396 - val_loss: 148.5487\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 2ms/step - loss: 161.3253 - val_loss: 145.3481\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 158.5458 - val_loss: 142.3399\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 155.6435 - val_loss: 139.6972\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.7910 - val_loss: 136.9070\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.9124 - val_loss: 133.7951\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.1751 - val_loss: 131.5603\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 144.2552 - val_loss: 129.1410\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.6804 - val_loss: 127.0056\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.0701 - val_loss: 124.6654\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 136.4896 - val_loss: 122.4038\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.1857 - val_loss: 120.4144\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 2ms/step - loss: 131.8438 - val_loss: 118.4238\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.6120 - val_loss: 116.1706\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 2ms/step - loss: 127.5014 - val_loss: 114.1700\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 5ms/step - loss: 125.0887 - val_loss: 112.7132\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 123.0463 - val_loss: 110.5141\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 2ms/step - loss: 120.9326 - val_loss: 108.5828\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 119.0000 - val_loss: 106.8477\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 116.7534 - val_loss: 104.9541\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.7959 - val_loss: 103.2087\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.9057 - val_loss: 101.4235\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.8400 - val_loss: 99.9125\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.9339 - val_loss: 98.3932\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.2290 - val_loss: 97.8372\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.4192 - val_loss: 95.9953\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.6447 - val_loss: 94.6146\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.9945 - val_loss: 93.3503\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.3198 - val_loss: 91.8953\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 5ms/step - loss: 98.7008 - val_loss: 90.4771\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.0209 - val_loss: 89.7119\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.6613 - val_loss: 88.9451\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.7530 - val_loss: 87.4585\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.2191 - val_loss: 86.0461\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.6666 - val_loss: 84.6038\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.4707 - val_loss: 83.3108\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 2ms/step - loss: 87.7477 - val_loss: 82.5979\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.4684 - val_loss: 81.5115\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 5ms/step - loss: 85.0384 - val_loss: 80.3282\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.6534 - val_loss: 79.2527\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.3814 - val_loss: 78.4196\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 81.1482 - val_loss: 77.2251\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.7967 - val_loss: 76.4770\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.7580 - val_loss: 75.8061\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 2ms/step - loss: 77.6748 - val_loss: 74.8956\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.5015 - val_loss: 74.3035\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 2ms/step - loss: 75.4321 - val_loss: 73.1940\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 5ms/step - loss: 74.5647 - val_loss: 72.7919\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 2ms/step - loss: 73.3564 - val_loss: 71.9033\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.4190 - val_loss: 70.7990\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.5791 - val_loss: 70.1818\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 70.6406 - val_loss: 69.4295\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 5ms/step - loss: 69.8048 - val_loss: 68.7103\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.8146 - val_loss: 68.1837\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.2258 - val_loss: 67.5467\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 67.1675 - val_loss: 67.0676\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.3432 - val_loss: 66.6172\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.6786 - val_loss: 66.1022\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 64.8064 - val_loss: 65.5533\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 64.2114 - val_loss: 64.8624\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 63.4716 - val_loss: 64.4756\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 62.8399 - val_loss: 64.0423\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 5ms/step - loss: 62.2115 - val_loss: 63.3622\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 61.6833 - val_loss: 63.2181\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 61.3007 - val_loss: 63.0290\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 60.5478 - val_loss: 62.2702\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 60.0454 - val_loss: 61.8801\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 3ms/step - loss: 59.3209 - val_loss: 61.6036\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 15ms/step - loss: 1566.6456 - val_loss: 1436.1248\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1527.6122 - val_loss: 1396.7191\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1481.2385 - val_loss: 1349.8314\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1424.1191 - val_loss: 1289.7430\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1350.2701 - val_loss: 1215.5348\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1262.5283 - val_loss: 1129.5267\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1161.3467 - val_loss: 1034.0410\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1051.4446 - val_loss: 933.3472\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 938.7151 - val_loss: 831.1819\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 5ms/step - loss: 826.8717 - val_loss: 730.8672\n",
            "Epoch 11/100\n",
            "73/73 - 1s - 7ms/step - loss: 719.0750 - val_loss: 635.8832\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 618.6072 - val_loss: 547.0438\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 2ms/step - loss: 525.1917 - val_loss: 467.0988\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 445.2419 - val_loss: 398.2469\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 5ms/step - loss: 377.7694 - val_loss: 341.2063\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 322.5755 - val_loss: 295.6508\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 278.0771 - val_loss: 258.8381\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 243.6367 - val_loss: 231.5614\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 217.3095 - val_loss: 211.0851\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 4ms/step - loss: 197.7279 - val_loss: 196.3940\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 183.1147 - val_loss: 186.3642\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 172.6749 - val_loss: 179.9714\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 165.1462 - val_loss: 175.3064\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.3444 - val_loss: 171.9586\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 5ms/step - loss: 154.9759 - val_loss: 170.0870\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 151.6053 - val_loss: 170.1053\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 148.7268 - val_loss: 168.8226\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 146.0933 - val_loss: 167.8887\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.9820 - val_loss: 167.3424\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.0643 - val_loss: 166.6228\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.4403 - val_loss: 165.8336\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 138.7671 - val_loss: 165.5134\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.2112 - val_loss: 164.4590\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.8284 - val_loss: 163.6431\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 134.1618 - val_loss: 162.7547\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 2ms/step - loss: 132.8590 - val_loss: 161.7756\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 2ms/step - loss: 131.3536 - val_loss: 161.1048\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.9040 - val_loss: 159.9003\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 128.4645 - val_loss: 158.9901\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.0055 - val_loss: 157.4874\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.6764 - val_loss: 156.3247\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 2ms/step - loss: 124.2073 - val_loss: 154.9831\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 2ms/step - loss: 122.7931 - val_loss: 154.4942\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 2ms/step - loss: 121.5982 - val_loss: 153.2307\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 120.2939 - val_loss: 152.2719\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 119.0607 - val_loss: 151.5107\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 117.6196 - val_loss: 149.7196\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.3449 - val_loss: 148.5905\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.0617 - val_loss: 147.2170\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.9069 - val_loss: 145.9938\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7239 - val_loss: 144.7938\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 111.4044 - val_loss: 143.8450\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.5939 - val_loss: 143.4719\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.2385 - val_loss: 141.9436\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.8940 - val_loss: 140.9156\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.7738 - val_loss: 139.5763\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.6167 - val_loss: 138.5879\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.5371 - val_loss: 137.3026\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.4310 - val_loss: 135.7660\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 102.3444 - val_loss: 134.0800\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.1725 - val_loss: 133.3964\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.0792 - val_loss: 132.1890\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.0126 - val_loss: 131.0083\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 6ms/step - loss: 98.0111 - val_loss: 129.5220\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 6ms/step - loss: 96.8870 - val_loss: 128.6329\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 5ms/step - loss: 95.8198 - val_loss: 127.6899\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 94.8187 - val_loss: 126.7480\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 2ms/step - loss: 93.8522 - val_loss: 125.5136\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.0729 - val_loss: 124.7444\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.1598 - val_loss: 123.9394\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.1887 - val_loss: 123.0275\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.2243 - val_loss: 122.1149\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.4487 - val_loss: 120.9854\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.4216 - val_loss: 119.8724\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.7226 - val_loss: 119.2549\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.8231 - val_loss: 118.2762\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.2597 - val_loss: 117.0133\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.2743 - val_loss: 116.3729\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.5304 - val_loss: 115.3782\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.8143 - val_loss: 114.4859\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.0812 - val_loss: 113.8860\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.5140 - val_loss: 112.6477\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.7212 - val_loss: 112.0380\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 81.0570 - val_loss: 111.0135\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 5ms/step - loss: 80.2192 - val_loss: 110.7575\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.6260 - val_loss: 109.8846\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.9250 - val_loss: 109.4298\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.3559 - val_loss: 108.8137\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 3ms/step - loss: 77.6552 - val_loss: 107.9036\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 76.9864 - val_loss: 107.6460\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.6874 - val_loss: 106.4247\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.7264 - val_loss: 106.1245\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 2ms/step - loss: 75.1186 - val_loss: 105.3908\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.5667 - val_loss: 105.1363\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.8202 - val_loss: 104.5669\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.2544 - val_loss: 103.8662\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.4174 - val_loss: 103.1342\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.7688 - val_loss: 102.9555\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.1586 - val_loss: 102.1521\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.3025 - val_loss: 101.1410\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 17ms/step - loss: 1530.4967 - val_loss: 1482.3693\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1484.9885 - val_loss: 1436.6805\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1437.3462 - val_loss: 1387.4426\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1384.2854 - val_loss: 1333.0011\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 3ms/step - loss: 1325.3392 - val_loss: 1271.1029\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1258.0046 - val_loss: 1199.8707\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1179.6941 - val_loss: 1117.0891\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1092.3550 - val_loss: 1025.6688\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 997.7493 - val_loss: 929.5219\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 899.5045 - val_loss: 831.3133\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 800.0782 - val_loss: 734.3148\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 3ms/step - loss: 704.7901 - val_loss: 643.2114\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 615.7939 - val_loss: 560.3895\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 534.9843 - val_loss: 484.5682\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 3ms/step - loss: 460.7935 - val_loss: 418.9859\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 396.1676 - val_loss: 363.4257\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 344.6206 - val_loss: 318.1532\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 303.1711 - val_loss: 284.1925\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 270.9575 - val_loss: 257.4566\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 2ms/step - loss: 245.8397 - val_loss: 237.3830\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 226.6650 - val_loss: 222.4431\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 213.1985 - val_loss: 210.5407\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 4ms/step - loss: 202.6811 - val_loss: 202.5577\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 194.8377 - val_loss: 195.9360\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 188.7397 - val_loss: 190.1996\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 183.5024 - val_loss: 185.5440\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 5ms/step - loss: 179.1137 - val_loss: 181.4132\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 175.2978 - val_loss: 177.5853\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 3ms/step - loss: 171.8491 - val_loss: 174.3956\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 168.6740 - val_loss: 171.3101\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 2ms/step - loss: 165.7864 - val_loss: 168.3118\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 5ms/step - loss: 162.9026 - val_loss: 165.3885\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.2677 - val_loss: 162.9162\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 4ms/step - loss: 157.9092 - val_loss: 160.2603\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 155.1155 - val_loss: 157.6114\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 152.7908 - val_loss: 155.2973\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.5353 - val_loss: 153.1102\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 148.6181 - val_loss: 151.2061\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.7894 - val_loss: 149.2166\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.1047 - val_loss: 147.2933\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 143.4414 - val_loss: 145.5253\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.1038 - val_loss: 143.6889\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.5464 - val_loss: 141.7848\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 2ms/step - loss: 139.0101 - val_loss: 140.3527\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 2ms/step - loss: 137.5578 - val_loss: 138.7762\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 136.4275 - val_loss: 137.3649\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.7870 - val_loss: 135.8207\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.4418 - val_loss: 134.4724\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 5ms/step - loss: 132.3826 - val_loss: 133.1764\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.1189 - val_loss: 131.8893\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 129.7913 - val_loss: 130.9875\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.6346 - val_loss: 129.7767\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.4048 - val_loss: 128.7695\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.3535 - val_loss: 127.6417\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.3876 - val_loss: 126.9602\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.4576 - val_loss: 126.0196\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.3897 - val_loss: 125.0046\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.4311 - val_loss: 124.1139\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.5701 - val_loss: 123.1927\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.6470 - val_loss: 122.5460\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.9778 - val_loss: 121.5714\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.9844 - val_loss: 120.9447\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.0747 - val_loss: 120.0534\n",
            "Epoch 64/100\n",
            "73/73 - 1s - 7ms/step - loss: 117.3011 - val_loss: 119.3673\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.3649 - val_loss: 118.7231\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.6980 - val_loss: 117.7768\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.9239 - val_loss: 116.8894\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 113.8993 - val_loss: 115.7190\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.8807 - val_loss: 114.7168\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.7245 - val_loss: 113.7931\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.8900 - val_loss: 112.5701\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.7590 - val_loss: 111.5506\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.7030 - val_loss: 110.6547\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 5ms/step - loss: 107.6278 - val_loss: 109.6857\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.5851 - val_loss: 108.5525\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 2ms/step - loss: 105.4198 - val_loss: 107.3791\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.2153 - val_loss: 106.2657\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.9782 - val_loss: 105.1795\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.9205 - val_loss: 103.9547\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.7772 - val_loss: 102.9078\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.5209 - val_loss: 101.5714\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.2504 - val_loss: 100.3798\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.2259 - val_loss: 98.9764\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.1040 - val_loss: 97.8480\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 3ms/step - loss: 95.0051 - val_loss: 96.7653\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.8754 - val_loss: 95.7249\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.1268 - val_loss: 94.4986\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.9281 - val_loss: 93.4143\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 91.0283 - val_loss: 92.1914\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 2ms/step - loss: 90.0913 - val_loss: 91.1751\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.9932 - val_loss: 90.3452\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.0521 - val_loss: 89.1792\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.1931 - val_loss: 88.1498\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 3ms/step - loss: 86.2494 - val_loss: 87.2676\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.3176 - val_loss: 86.3177\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 84.4693 - val_loss: 85.3867\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.5173 - val_loss: 84.6681\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.7765 - val_loss: 83.5822\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.8506 - val_loss: 82.6473\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 5ms/step - loss: 81.0247 - val_loss: 81.8272\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 19ms/step - loss: 1556.3247 - val_loss: 1450.0190\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 4ms/step - loss: 1504.5890 - val_loss: 1399.1265\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1447.0665 - val_loss: 1341.9187\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1380.0852 - val_loss: 1275.4097\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1302.8318 - val_loss: 1198.9779\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1217.3585 - val_loss: 1115.2030\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1123.7701 - val_loss: 1025.3435\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1026.7538 - val_loss: 933.6212\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 927.4908 - val_loss: 840.2229\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 830.7045 - val_loss: 749.6733\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 736.9761 - val_loss: 664.5611\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 5ms/step - loss: 651.0772 - val_loss: 586.1533\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 2ms/step - loss: 572.1746 - val_loss: 515.4530\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 501.4315 - val_loss: 451.4213\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 441.1662 - val_loss: 399.9018\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 390.7926 - val_loss: 356.1746\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 348.5914 - val_loss: 320.5399\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 314.6910 - val_loss: 290.7214\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 287.6817 - val_loss: 268.6925\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 2ms/step - loss: 265.9898 - val_loss: 250.3378\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 249.0234 - val_loss: 236.5325\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 235.3841 - val_loss: 225.2447\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 224.6794 - val_loss: 215.8770\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 2ms/step - loss: 215.8265 - val_loss: 208.7236\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 208.3857 - val_loss: 202.1910\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 3ms/step - loss: 201.9921 - val_loss: 196.5300\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 196.2366 - val_loss: 191.5763\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 5ms/step - loss: 191.2291 - val_loss: 187.1387\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 3ms/step - loss: 186.4873 - val_loss: 182.7227\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 3ms/step - loss: 182.1911 - val_loss: 178.5679\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 178.0444 - val_loss: 174.8019\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 3ms/step - loss: 174.1514 - val_loss: 171.3040\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 170.3316 - val_loss: 168.2847\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 2ms/step - loss: 166.9747 - val_loss: 165.3768\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 163.8905 - val_loss: 162.6419\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.7426 - val_loss: 159.9107\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 2ms/step - loss: 158.0438 - val_loss: 157.4417\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.0881 - val_loss: 155.1974\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 152.4849 - val_loss: 153.0384\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 5ms/step - loss: 150.2146 - val_loss: 150.9878\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 147.8064 - val_loss: 149.1232\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 145.7577 - val_loss: 147.1837\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 3ms/step - loss: 143.6178 - val_loss: 145.7539\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.5734 - val_loss: 144.2519\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 139.8808 - val_loss: 142.3205\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 2ms/step - loss: 137.9325 - val_loss: 141.1684\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.3358 - val_loss: 139.8567\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.6022 - val_loss: 138.4448\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.1697 - val_loss: 137.1111\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 131.7585 - val_loss: 135.6611\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.4706 - val_loss: 134.3746\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 5ms/step - loss: 128.9382 - val_loss: 133.0322\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.7717 - val_loss: 131.7970\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.3985 - val_loss: 131.0373\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.1393 - val_loss: 129.6031\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 3ms/step - loss: 123.8590 - val_loss: 128.5801\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.6744 - val_loss: 127.1857\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.4823 - val_loss: 126.0734\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.4236 - val_loss: 124.8681\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 5ms/step - loss: 119.1779 - val_loss: 124.0281\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.1570 - val_loss: 122.6997\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 116.9326 - val_loss: 121.3837\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.7781 - val_loss: 120.4240\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.8113 - val_loss: 119.2715\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.7296 - val_loss: 117.8157\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.7378 - val_loss: 116.8997\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.7837 - val_loss: 116.3504\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 111.0386 - val_loss: 115.2508\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.0223 - val_loss: 114.3368\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.1588 - val_loss: 113.6080\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.0162 - val_loss: 112.7623\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.1304 - val_loss: 111.8755\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.2849 - val_loss: 111.0076\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.4880 - val_loss: 110.2430\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.7348 - val_loss: 109.3707\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.7373 - val_loss: 108.2923\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.0618 - val_loss: 107.8013\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 102.2035 - val_loss: 107.3658\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 4ms/step - loss: 101.6312 - val_loss: 106.2811\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.6727 - val_loss: 105.8422\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.0143 - val_loss: 104.7760\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 99.3270 - val_loss: 104.2380\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.6345 - val_loss: 103.4294\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.9568 - val_loss: 103.0502\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.2517 - val_loss: 102.0829\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.4054 - val_loss: 101.5643\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.9107 - val_loss: 100.5505\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.1502 - val_loss: 99.8546\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.5617 - val_loss: 99.4445\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 5ms/step - loss: 93.9257 - val_loss: 98.7627\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.1002 - val_loss: 98.0121\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.2878 - val_loss: 97.0568\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.5075 - val_loss: 96.2451\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.6903 - val_loss: 95.3394\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.7436 - val_loss: 94.6743\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 2ms/step - loss: 88.9662 - val_loss: 93.8145\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 88.1219 - val_loss: 92.8837\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.3153 - val_loss: 92.2450\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 5ms/step - loss: 86.4019 - val_loss: 90.9988\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 5ms/step - loss: 85.6364 - val_loss: 90.2764\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 2s - 21ms/step - loss: 1591.7158 - val_loss: 1499.2480\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1540.2196 - val_loss: 1451.5258\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 3ms/step - loss: 1487.0863 - val_loss: 1401.4946\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1430.3440 - val_loss: 1347.8042\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1369.3539 - val_loss: 1288.7339\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1302.3787 - val_loss: 1226.4911\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1230.1692 - val_loss: 1158.4878\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1154.0710 - val_loss: 1087.3784\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 2ms/step - loss: 1074.0320 - val_loss: 1012.2042\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 5ms/step - loss: 993.9295 - val_loss: 939.0482\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 913.6926 - val_loss: 864.7568\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 833.5249 - val_loss: 792.4651\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 755.7234 - val_loss: 722.1021\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 681.8821 - val_loss: 654.5016\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 612.3320 - val_loss: 594.7206\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 2ms/step - loss: 548.6448 - val_loss: 537.7392\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 4ms/step - loss: 491.3476 - val_loss: 487.6283\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 442.0687 - val_loss: 443.8395\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 4ms/step - loss: 399.4820 - val_loss: 406.4249\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 5ms/step - loss: 362.5481 - val_loss: 373.3162\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 2ms/step - loss: 331.0997 - val_loss: 345.1288\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 3ms/step - loss: 303.8966 - val_loss: 320.4323\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 280.9049 - val_loss: 299.2827\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 260.7142 - val_loss: 280.9224\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 3ms/step - loss: 244.0275 - val_loss: 265.1419\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 229.9068 - val_loss: 250.9907\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 217.4166 - val_loss: 238.6176\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 206.4362 - val_loss: 227.6924\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 197.1305 - val_loss: 218.3369\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 4ms/step - loss: 188.9177 - val_loss: 209.7933\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 182.4648 - val_loss: 202.9867\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 176.8184 - val_loss: 196.8728\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 3ms/step - loss: 171.8001 - val_loss: 191.4342\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 167.6624 - val_loss: 187.0683\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 2ms/step - loss: 164.0751 - val_loss: 182.7553\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.6947 - val_loss: 179.0774\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 5ms/step - loss: 157.9402 - val_loss: 175.7652\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 3ms/step - loss: 155.3466 - val_loss: 172.5786\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 2ms/step - loss: 153.0965 - val_loss: 170.0389\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 3ms/step - loss: 151.2634 - val_loss: 167.5300\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 3ms/step - loss: 149.2946 - val_loss: 165.1780\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 4ms/step - loss: 147.6149 - val_loss: 162.7726\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.6547 - val_loss: 160.5787\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 2ms/step - loss: 143.8359 - val_loss: 158.2671\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 142.1445 - val_loss: 156.1916\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 5ms/step - loss: 140.2890 - val_loss: 153.9670\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 5ms/step - loss: 138.7233 - val_loss: 151.8029\n",
            "Epoch 48/100\n",
            "73/73 - 1s - 8ms/step - loss: 136.8303 - val_loss: 149.8830\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.1318 - val_loss: 147.9199\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 133.5312 - val_loss: 146.0545\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 3ms/step - loss: 131.8728 - val_loss: 144.1611\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.3183 - val_loss: 142.1380\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 3ms/step - loss: 128.5063 - val_loss: 140.1468\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.9630 - val_loss: 138.4316\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.3240 - val_loss: 136.4194\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.6766 - val_loss: 134.6114\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.0694 - val_loss: 132.7731\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 5ms/step - loss: 120.5907 - val_loss: 130.7419\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.8892 - val_loss: 128.9939\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 117.3749 - val_loss: 127.0347\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.6655 - val_loss: 125.1601\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.0500 - val_loss: 123.3500\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 112.3881 - val_loss: 121.5246\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 2ms/step - loss: 110.8026 - val_loss: 119.5499\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 3ms/step - loss: 109.2668 - val_loss: 117.8130\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.3912 - val_loss: 116.1373\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 105.8225 - val_loss: 114.2999\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 104.1246 - val_loss: 112.3461\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 102.3409 - val_loss: 110.2006\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.6495 - val_loss: 108.3977\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.9362 - val_loss: 106.4327\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 2ms/step - loss: 97.1433 - val_loss: 104.5091\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 95.4384 - val_loss: 102.5868\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.8938 - val_loss: 100.8977\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 2ms/step - loss: 92.2306 - val_loss: 98.9283\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 90.5828 - val_loss: 97.1835\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 3ms/step - loss: 88.8713 - val_loss: 95.4369\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.3035 - val_loss: 93.7782\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 85.8449 - val_loss: 92.1262\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 84.2946 - val_loss: 90.6459\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.9444 - val_loss: 88.9482\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 81.4149 - val_loss: 87.5576\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.0126 - val_loss: 85.7551\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.6486 - val_loss: 84.2764\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.3850 - val_loss: 83.0644\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 76.0107 - val_loss: 81.5399\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.7567 - val_loss: 80.4021\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 73.4733 - val_loss: 79.0651\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 5ms/step - loss: 72.3761 - val_loss: 77.8150\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.1099 - val_loss: 76.5280\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.0174 - val_loss: 75.3416\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 68.8582 - val_loss: 74.3804\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 67.9646 - val_loss: 73.2233\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.8322 - val_loss: 72.4111\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.9526 - val_loss: 71.3866\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.1607 - val_loss: 70.2211\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 64.1183 - val_loss: 69.4027\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 63.2417 - val_loss: 68.3568\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 62.3660 - val_loss: 67.6173\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 5ms/step - loss: 61.6571 - val_loss: 67.1721\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 20ms/step - loss: 1486.5466 - val_loss: 1529.8715\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1430.1814 - val_loss: 1466.4275\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1370.2842 - val_loss: 1398.4719\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1308.5920 - val_loss: 1327.3887\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1241.5699 - val_loss: 1250.7466\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 4ms/step - loss: 1168.3973 - val_loss: 1167.3311\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1090.8289 - val_loss: 1080.5442\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 3ms/step - loss: 1009.5876 - val_loss: 990.6487\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 4ms/step - loss: 927.1650 - val_loss: 901.0008\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 844.8168 - val_loss: 811.9573\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 763.1945 - val_loss: 725.0336\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 682.6953 - val_loss: 641.9747\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 609.6381 - val_loss: 566.6298\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 2ms/step - loss: 542.0135 - val_loss: 498.7384\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 5ms/step - loss: 479.7825 - val_loss: 439.5206\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 2ms/step - loss: 425.5970 - val_loss: 388.6226\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 379.5713 - val_loss: 346.4492\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 339.7888 - val_loss: 312.5200\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 307.0662 - val_loss: 285.2266\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 278.9205 - val_loss: 262.5795\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 256.8328 - val_loss: 246.2103\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 2ms/step - loss: 238.9733 - val_loss: 233.7121\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 224.4899 - val_loss: 224.3564\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 213.1918 - val_loss: 217.4149\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 203.2370 - val_loss: 211.4612\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 195.7776 - val_loss: 207.0741\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 188.7253 - val_loss: 203.2914\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 182.7522 - val_loss: 200.1943\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 5ms/step - loss: 177.8639 - val_loss: 197.5338\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 173.5224 - val_loss: 195.3413\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 169.6416 - val_loss: 193.4128\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 4ms/step - loss: 166.4278 - val_loss: 191.2715\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 162.9121 - val_loss: 189.7965\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 5ms/step - loss: 159.8360 - val_loss: 188.1505\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 3ms/step - loss: 157.1911 - val_loss: 184.7717\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 3ms/step - loss: 154.3413 - val_loss: 183.5309\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 5ms/step - loss: 151.9134 - val_loss: 182.4865\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.5434 - val_loss: 181.1595\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 147.2547 - val_loss: 179.9412\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.1142 - val_loss: 179.0341\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 143.1396 - val_loss: 177.7768\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 141.0213 - val_loss: 176.4713\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.9790 - val_loss: 174.9583\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.0695 - val_loss: 172.7990\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 5ms/step - loss: 134.7520 - val_loss: 171.1320\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 3ms/step - loss: 132.5804 - val_loss: 168.4553\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 3ms/step - loss: 130.6662 - val_loss: 167.2337\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 3ms/step - loss: 128.3991 - val_loss: 164.5429\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 126.3335 - val_loss: 162.4394\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.1222 - val_loss: 160.4703\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.1039 - val_loss: 158.2003\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.1223 - val_loss: 156.2981\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.9723 - val_loss: 154.4597\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 115.9904 - val_loss: 152.3100\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 114.0812 - val_loss: 150.0529\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.1723 - val_loss: 147.8948\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 110.3495 - val_loss: 145.4794\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 5ms/step - loss: 108.7409 - val_loss: 143.7897\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 106.8441 - val_loss: 141.5174\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 2ms/step - loss: 105.1540 - val_loss: 140.4481\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 103.6009 - val_loss: 138.8410\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 3ms/step - loss: 102.0110 - val_loss: 136.6003\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.4717 - val_loss: 134.6014\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 98.9867 - val_loss: 133.2101\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 5ms/step - loss: 97.7552 - val_loss: 131.3417\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 96.2996 - val_loss: 130.3306\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.2364 - val_loss: 128.4796\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 93.9457 - val_loss: 127.7410\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.7325 - val_loss: 126.2024\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.4215 - val_loss: 124.2933\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.1941 - val_loss: 123.3992\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 89.2022 - val_loss: 121.7225\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.9926 - val_loss: 120.3000\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 87.0323 - val_loss: 118.4910\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 4ms/step - loss: 85.9736 - val_loss: 116.9684\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 2ms/step - loss: 85.0612 - val_loss: 115.7165\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 5ms/step - loss: 84.0979 - val_loss: 114.6121\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 2ms/step - loss: 83.2208 - val_loss: 114.4475\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.4892 - val_loss: 112.1230\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 2ms/step - loss: 81.8160 - val_loss: 111.4914\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 3ms/step - loss: 80.7503 - val_loss: 110.4536\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.0904 - val_loss: 109.7355\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.3412 - val_loss: 108.7671\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 2ms/step - loss: 78.6406 - val_loss: 107.4403\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 4ms/step - loss: 78.0376 - val_loss: 106.4639\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 4ms/step - loss: 77.3290 - val_loss: 105.7178\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 2ms/step - loss: 76.7905 - val_loss: 105.1395\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 76.0283 - val_loss: 103.8739\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 4ms/step - loss: 75.3928 - val_loss: 102.9007\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 4ms/step - loss: 74.8169 - val_loss: 102.0814\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 2ms/step - loss: 74.2691 - val_loss: 101.0856\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 3ms/step - loss: 73.4856 - val_loss: 100.4063\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.9630 - val_loss: 99.9563\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 72.4087 - val_loss: 99.3944\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.7476 - val_loss: 99.1862\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 3ms/step - loss: 71.2990 - val_loss: 97.9734\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 70.8178 - val_loss: 97.0805\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 70.2638 - val_loss: 96.0890\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 3ms/step - loss: 69.7714 - val_loss: 95.6248\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.2592 - val_loss: 94.9186\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 18ms/step - loss: 1499.2784 - val_loss: 1563.4905\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 3ms/step - loss: 1458.9603 - val_loss: 1518.1936\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 5ms/step - loss: 1410.7017 - val_loss: 1462.5046\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 5ms/step - loss: 1351.7510 - val_loss: 1392.4866\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1279.9817 - val_loss: 1310.9108\n",
            "Epoch 6/100\n",
            "73/73 - 1s - 8ms/step - loss: 1196.0200 - val_loss: 1216.4509\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 3ms/step - loss: 1103.5638 - val_loss: 1115.0354\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1005.1583 - val_loss: 1010.3430\n",
            "Epoch 9/100\n",
            "73/73 - 0s - 3ms/step - loss: 903.1598 - val_loss: 901.9070\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 801.8340 - val_loss: 795.5828\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 3ms/step - loss: 702.7541 - val_loss: 695.3539\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 4ms/step - loss: 611.9161 - val_loss: 603.6934\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 4ms/step - loss: 529.2444 - val_loss: 521.5085\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 3ms/step - loss: 457.1382 - val_loss: 449.5315\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 4ms/step - loss: 394.0802 - val_loss: 390.4156\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 3ms/step - loss: 343.0307 - val_loss: 340.4320\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 2ms/step - loss: 302.0355 - val_loss: 301.4197\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 4ms/step - loss: 269.0622 - val_loss: 270.1564\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 244.5201 - val_loss: 246.1437\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 225.0302 - val_loss: 227.9632\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 4ms/step - loss: 210.5652 - val_loss: 214.0020\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 198.2091 - val_loss: 202.4062\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 188.4795 - val_loss: 193.2536\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 180.7812 - val_loss: 185.7075\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 174.1485 - val_loss: 179.7262\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 3ms/step - loss: 168.6301 - val_loss: 174.4748\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 3ms/step - loss: 164.0062 - val_loss: 169.8793\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 4ms/step - loss: 159.8947 - val_loss: 166.4088\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 2ms/step - loss: 156.4292 - val_loss: 163.3120\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 153.4096 - val_loss: 160.5092\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 4ms/step - loss: 150.3271 - val_loss: 158.0091\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 5ms/step - loss: 147.5455 - val_loss: 155.3368\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 4ms/step - loss: 145.0605 - val_loss: 153.2315\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 142.8335 - val_loss: 151.6775\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 4ms/step - loss: 140.5799 - val_loss: 149.8576\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 4ms/step - loss: 138.7731 - val_loss: 148.1767\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 3ms/step - loss: 136.9186 - val_loss: 146.5501\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 135.1744 - val_loss: 145.1319\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 133.5670 - val_loss: 143.4045\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 132.0860 - val_loss: 142.5452\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 2ms/step - loss: 130.8011 - val_loss: 141.3777\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 5ms/step - loss: 129.4862 - val_loss: 140.4393\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 128.2897 - val_loss: 139.7246\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 127.4255 - val_loss: 138.6165\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 3ms/step - loss: 126.3318 - val_loss: 137.9044\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 5ms/step - loss: 125.3316 - val_loss: 137.0130\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 124.6080 - val_loss: 136.5730\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.9034 - val_loss: 135.7318\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.0412 - val_loss: 135.4065\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 122.3317 - val_loss: 134.6977\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.7380 - val_loss: 134.4924\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 3ms/step - loss: 120.8788 - val_loss: 133.8404\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 120.2821 - val_loss: 133.2498\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 119.6151 - val_loss: 132.4239\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 3ms/step - loss: 118.8335 - val_loss: 131.8521\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.0240 - val_loss: 131.3021\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 4ms/step - loss: 117.4235 - val_loss: 130.6862\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 116.6561 - val_loss: 130.0710\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 5ms/step - loss: 116.0709 - val_loss: 129.2915\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 3ms/step - loss: 115.4373 - val_loss: 129.0072\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.7418 - val_loss: 128.2891\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 2ms/step - loss: 114.1031 - val_loss: 127.3097\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 3ms/step - loss: 113.2292 - val_loss: 126.5863\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.3964 - val_loss: 125.5975\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 111.5668 - val_loss: 124.3820\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 2ms/step - loss: 110.5888 - val_loss: 123.6051\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 4ms/step - loss: 109.6861 - val_loss: 122.2733\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 3ms/step - loss: 108.6090 - val_loss: 121.3382\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 4ms/step - loss: 107.5894 - val_loss: 120.1598\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.6241 - val_loss: 119.2274\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 2ms/step - loss: 105.6855 - val_loss: 117.9875\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.5619 - val_loss: 116.9726\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 103.4294 - val_loss: 115.7273\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 3ms/step - loss: 102.3389 - val_loss: 114.3810\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 3ms/step - loss: 101.2839 - val_loss: 113.6711\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 100.1040 - val_loss: 112.2975\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 3ms/step - loss: 99.0014 - val_loss: 111.2674\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.1088 - val_loss: 110.0401\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.9640 - val_loss: 108.9831\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 3ms/step - loss: 96.1942 - val_loss: 107.9503\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 95.2712 - val_loss: 107.1277\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 4ms/step - loss: 94.0397 - val_loss: 105.9851\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.3694 - val_loss: 105.1918\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 4ms/step - loss: 92.3367 - val_loss: 104.5341\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 2ms/step - loss: 91.4054 - val_loss: 103.4811\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 3ms/step - loss: 90.6536 - val_loss: 103.4972\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 2ms/step - loss: 89.7631 - val_loss: 102.0415\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 5ms/step - loss: 89.0062 - val_loss: 100.9715\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 2ms/step - loss: 88.1163 - val_loss: 100.0909\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 5ms/step - loss: 87.2043 - val_loss: 98.9893\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.2784 - val_loss: 98.1040\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 2ms/step - loss: 85.4373 - val_loss: 96.9709\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 2ms/step - loss: 84.6156 - val_loss: 95.8271\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.7939 - val_loss: 94.9107\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 2ms/step - loss: 82.9083 - val_loss: 93.8747\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 82.3314 - val_loss: 92.9342\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.3542 - val_loss: 92.3402\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 4ms/step - loss: 80.4818 - val_loss: 91.3416\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.7463 - val_loss: 90.1682\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 79.1002 - val_loss: 89.5385\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 - 1s - 20ms/step - loss: 1558.3594 - val_loss: 1714.3328\n",
            "Epoch 2/100\n",
            "73/73 - 0s - 6ms/step - loss: 1515.2831 - val_loss: 1667.5834\n",
            "Epoch 3/100\n",
            "73/73 - 0s - 4ms/step - loss: 1477.0425 - val_loss: 1625.8562\n",
            "Epoch 4/100\n",
            "73/73 - 0s - 4ms/step - loss: 1441.5209 - val_loss: 1585.5920\n",
            "Epoch 5/100\n",
            "73/73 - 0s - 4ms/step - loss: 1407.5884 - val_loss: 1546.7296\n",
            "Epoch 6/100\n",
            "73/73 - 0s - 3ms/step - loss: 1373.0643 - val_loss: 1506.6562\n",
            "Epoch 7/100\n",
            "73/73 - 0s - 4ms/step - loss: 1337.1324 - val_loss: 1464.0582\n",
            "Epoch 8/100\n",
            "73/73 - 0s - 4ms/step - loss: 1297.0039 - val_loss: 1415.1262\n",
            "Epoch 9/100\n",
            "73/73 - 1s - 7ms/step - loss: 1247.0864 - val_loss: 1353.7610\n",
            "Epoch 10/100\n",
            "73/73 - 0s - 4ms/step - loss: 1187.8424 - val_loss: 1283.5240\n",
            "Epoch 11/100\n",
            "73/73 - 0s - 4ms/step - loss: 1120.4866 - val_loss: 1203.0083\n",
            "Epoch 12/100\n",
            "73/73 - 0s - 2ms/step - loss: 1046.7235 - val_loss: 1119.4590\n",
            "Epoch 13/100\n",
            "73/73 - 0s - 2ms/step - loss: 971.9941 - val_loss: 1033.9873\n",
            "Epoch 14/100\n",
            "73/73 - 0s - 4ms/step - loss: 896.6918 - val_loss: 951.2939\n",
            "Epoch 15/100\n",
            "73/73 - 0s - 2ms/step - loss: 821.4129 - val_loss: 868.4894\n",
            "Epoch 16/100\n",
            "73/73 - 0s - 4ms/step - loss: 751.0024 - val_loss: 792.3882\n",
            "Epoch 17/100\n",
            "73/73 - 0s - 3ms/step - loss: 684.7466 - val_loss: 722.0818\n",
            "Epoch 18/100\n",
            "73/73 - 0s - 3ms/step - loss: 623.3039 - val_loss: 654.5093\n",
            "Epoch 19/100\n",
            "73/73 - 0s - 3ms/step - loss: 566.2377 - val_loss: 595.4323\n",
            "Epoch 20/100\n",
            "73/73 - 0s - 3ms/step - loss: 513.5522 - val_loss: 539.2766\n",
            "Epoch 21/100\n",
            "73/73 - 0s - 2ms/step - loss: 467.2942 - val_loss: 491.1077\n",
            "Epoch 22/100\n",
            "73/73 - 0s - 4ms/step - loss: 425.6994 - val_loss: 449.0923\n",
            "Epoch 23/100\n",
            "73/73 - 0s - 3ms/step - loss: 388.7902 - val_loss: 412.6752\n",
            "Epoch 24/100\n",
            "73/73 - 0s - 4ms/step - loss: 357.8546 - val_loss: 380.9256\n",
            "Epoch 25/100\n",
            "73/73 - 0s - 4ms/step - loss: 331.0265 - val_loss: 354.0234\n",
            "Epoch 26/100\n",
            "73/73 - 0s - 4ms/step - loss: 307.2444 - val_loss: 330.7150\n",
            "Epoch 27/100\n",
            "73/73 - 0s - 4ms/step - loss: 287.5067 - val_loss: 310.8463\n",
            "Epoch 28/100\n",
            "73/73 - 0s - 2ms/step - loss: 269.8524 - val_loss: 293.2895\n",
            "Epoch 29/100\n",
            "73/73 - 0s - 4ms/step - loss: 255.3490 - val_loss: 278.8549\n",
            "Epoch 30/100\n",
            "73/73 - 0s - 2ms/step - loss: 242.9898 - val_loss: 266.1686\n",
            "Epoch 31/100\n",
            "73/73 - 0s - 3ms/step - loss: 232.0397 - val_loss: 255.5196\n",
            "Epoch 32/100\n",
            "73/73 - 0s - 2ms/step - loss: 222.2188 - val_loss: 245.7888\n",
            "Epoch 33/100\n",
            "73/73 - 0s - 2ms/step - loss: 213.9707 - val_loss: 237.0929\n",
            "Epoch 34/100\n",
            "73/73 - 0s - 3ms/step - loss: 206.8367 - val_loss: 229.6436\n",
            "Epoch 35/100\n",
            "73/73 - 0s - 2ms/step - loss: 200.4137 - val_loss: 222.7362\n",
            "Epoch 36/100\n",
            "73/73 - 0s - 5ms/step - loss: 194.6938 - val_loss: 216.0402\n",
            "Epoch 37/100\n",
            "73/73 - 0s - 4ms/step - loss: 189.8253 - val_loss: 210.9009\n",
            "Epoch 38/100\n",
            "73/73 - 0s - 4ms/step - loss: 185.5299 - val_loss: 205.2945\n",
            "Epoch 39/100\n",
            "73/73 - 0s - 3ms/step - loss: 181.0955 - val_loss: 200.4404\n",
            "Epoch 40/100\n",
            "73/73 - 0s - 4ms/step - loss: 177.1219 - val_loss: 195.4903\n",
            "Epoch 41/100\n",
            "73/73 - 0s - 4ms/step - loss: 173.4364 - val_loss: 191.5672\n",
            "Epoch 42/100\n",
            "73/73 - 0s - 3ms/step - loss: 170.1127 - val_loss: 187.4402\n",
            "Epoch 43/100\n",
            "73/73 - 0s - 4ms/step - loss: 166.9128 - val_loss: 183.7554\n",
            "Epoch 44/100\n",
            "73/73 - 0s - 3ms/step - loss: 163.6048 - val_loss: 180.3120\n",
            "Epoch 45/100\n",
            "73/73 - 0s - 4ms/step - loss: 160.9212 - val_loss: 176.9793\n",
            "Epoch 46/100\n",
            "73/73 - 0s - 4ms/step - loss: 158.3703 - val_loss: 174.5478\n",
            "Epoch 47/100\n",
            "73/73 - 0s - 4ms/step - loss: 155.9780 - val_loss: 172.2423\n",
            "Epoch 48/100\n",
            "73/73 - 0s - 4ms/step - loss: 153.6818 - val_loss: 169.5730\n",
            "Epoch 49/100\n",
            "73/73 - 0s - 3ms/step - loss: 151.4857 - val_loss: 166.8105\n",
            "Epoch 50/100\n",
            "73/73 - 0s - 4ms/step - loss: 149.1246 - val_loss: 164.3564\n",
            "Epoch 51/100\n",
            "73/73 - 0s - 4ms/step - loss: 146.7485 - val_loss: 161.3002\n",
            "Epoch 52/100\n",
            "73/73 - 0s - 4ms/step - loss: 144.3878 - val_loss: 158.4398\n",
            "Epoch 53/100\n",
            "73/73 - 0s - 4ms/step - loss: 141.9668 - val_loss: 155.3822\n",
            "Epoch 54/100\n",
            "73/73 - 0s - 4ms/step - loss: 139.4558 - val_loss: 152.3986\n",
            "Epoch 55/100\n",
            "73/73 - 0s - 4ms/step - loss: 137.1940 - val_loss: 149.4997\n",
            "Epoch 56/100\n",
            "73/73 - 0s - 4ms/step - loss: 134.7102 - val_loss: 147.4792\n",
            "Epoch 57/100\n",
            "73/73 - 0s - 3ms/step - loss: 132.4178 - val_loss: 144.6932\n",
            "Epoch 58/100\n",
            "73/73 - 0s - 4ms/step - loss: 130.0582 - val_loss: 141.4135\n",
            "Epoch 59/100\n",
            "73/73 - 0s - 4ms/step - loss: 127.7563 - val_loss: 138.2843\n",
            "Epoch 60/100\n",
            "73/73 - 0s - 4ms/step - loss: 125.5134 - val_loss: 135.2946\n",
            "Epoch 61/100\n",
            "73/73 - 0s - 4ms/step - loss: 123.4784 - val_loss: 132.8231\n",
            "Epoch 62/100\n",
            "73/73 - 0s - 4ms/step - loss: 121.1734 - val_loss: 129.8144\n",
            "Epoch 63/100\n",
            "73/73 - 0s - 4ms/step - loss: 118.9503 - val_loss: 127.0950\n",
            "Epoch 64/100\n",
            "73/73 - 0s - 3ms/step - loss: 116.7186 - val_loss: 124.2431\n",
            "Epoch 65/100\n",
            "73/73 - 0s - 4ms/step - loss: 114.5328 - val_loss: 121.6359\n",
            "Epoch 66/100\n",
            "73/73 - 0s - 4ms/step - loss: 112.4628 - val_loss: 118.7268\n",
            "Epoch 67/100\n",
            "73/73 - 0s - 3ms/step - loss: 110.2370 - val_loss: 115.7628\n",
            "Epoch 68/100\n",
            "73/73 - 0s - 4ms/step - loss: 108.1907 - val_loss: 113.0517\n",
            "Epoch 69/100\n",
            "73/73 - 0s - 3ms/step - loss: 106.2176 - val_loss: 110.4524\n",
            "Epoch 70/100\n",
            "73/73 - 0s - 4ms/step - loss: 104.2178 - val_loss: 108.2990\n",
            "Epoch 71/100\n",
            "73/73 - 0s - 2ms/step - loss: 102.2731 - val_loss: 106.2434\n",
            "Epoch 72/100\n",
            "73/73 - 0s - 4ms/step - loss: 100.5004 - val_loss: 103.9948\n",
            "Epoch 73/100\n",
            "73/73 - 0s - 3ms/step - loss: 98.7541 - val_loss: 101.8852\n",
            "Epoch 74/100\n",
            "73/73 - 0s - 4ms/step - loss: 97.0653 - val_loss: 99.7275\n",
            "Epoch 75/100\n",
            "73/73 - 0s - 2ms/step - loss: 95.3374 - val_loss: 97.4744\n",
            "Epoch 76/100\n",
            "73/73 - 0s - 3ms/step - loss: 93.7326 - val_loss: 95.4773\n",
            "Epoch 77/100\n",
            "73/73 - 0s - 3ms/step - loss: 92.1409 - val_loss: 93.6959\n",
            "Epoch 78/100\n",
            "73/73 - 0s - 4ms/step - loss: 90.5943 - val_loss: 91.7037\n",
            "Epoch 79/100\n",
            "73/73 - 0s - 3ms/step - loss: 89.3913 - val_loss: 89.8175\n",
            "Epoch 80/100\n",
            "73/73 - 0s - 4ms/step - loss: 87.8966 - val_loss: 87.8547\n",
            "Epoch 81/100\n",
            "73/73 - 0s - 4ms/step - loss: 86.3188 - val_loss: 86.0925\n",
            "Epoch 82/100\n",
            "73/73 - 0s - 3ms/step - loss: 85.0868 - val_loss: 85.1226\n",
            "Epoch 83/100\n",
            "73/73 - 0s - 4ms/step - loss: 83.8242 - val_loss: 83.5235\n",
            "Epoch 84/100\n",
            "73/73 - 0s - 5ms/step - loss: 82.6228 - val_loss: 81.8854\n",
            "Epoch 85/100\n",
            "73/73 - 0s - 3ms/step - loss: 81.4903 - val_loss: 80.3887\n",
            "Epoch 86/100\n",
            "73/73 - 0s - 2ms/step - loss: 80.2466 - val_loss: 79.4012\n",
            "Epoch 87/100\n",
            "73/73 - 0s - 5ms/step - loss: 79.0578 - val_loss: 78.0916\n",
            "Epoch 88/100\n",
            "73/73 - 0s - 2ms/step - loss: 77.8419 - val_loss: 76.9562\n",
            "Epoch 89/100\n",
            "73/73 - 0s - 2ms/step - loss: 76.7994 - val_loss: 75.8495\n",
            "Epoch 90/100\n",
            "73/73 - 0s - 3ms/step - loss: 75.7149 - val_loss: 74.3852\n",
            "Epoch 91/100\n",
            "73/73 - 0s - 3ms/step - loss: 74.6531 - val_loss: 73.1040\n",
            "Epoch 92/100\n",
            "73/73 - 0s - 4ms/step - loss: 73.6335 - val_loss: 72.2866\n",
            "Epoch 93/100\n",
            "73/73 - 0s - 5ms/step - loss: 72.5369 - val_loss: 70.7756\n",
            "Epoch 94/100\n",
            "73/73 - 0s - 4ms/step - loss: 71.6326 - val_loss: 69.8097\n",
            "Epoch 95/100\n",
            "73/73 - 0s - 5ms/step - loss: 70.5658 - val_loss: 68.6783\n",
            "Epoch 96/100\n",
            "73/73 - 0s - 4ms/step - loss: 69.7243 - val_loss: 67.6398\n",
            "Epoch 97/100\n",
            "73/73 - 0s - 4ms/step - loss: 68.7185 - val_loss: 66.4930\n",
            "Epoch 98/100\n",
            "73/73 - 0s - 3ms/step - loss: 67.7675 - val_loss: 65.8511\n",
            "Epoch 99/100\n",
            "73/73 - 0s - 4ms/step - loss: 66.8186 - val_loss: 64.9117\n",
            "Epoch 100/100\n",
            "73/73 - 0s - 4ms/step - loss: 65.9461 - val_loss: 64.0537\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calculate mean and standard deviation of MSE\n",
        "mean_mse = np.mean(mse_list)\n",
        "std_mse = np.std(mse_list)"
      ],
      "metadata": {
        "id": "NkuFS42MYb3W"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Print results after normalization with 100 epochs\n",
        "print(f\"Mean of MSE over 100 runs: {mean_mse}\")\n",
        "print(f\"Standard Deviation of MSE over 100 runs: {std_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T28jwauy2B-2",
        "outputId": "154f6274-cbe2-4071-8bda-4ba9282e637e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of MSE over 100 runs: 77.90864362902043\n",
            "Standard Deviation of MSE over 100 runs: 14.802098866276834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results after normalization with 50 epochs\n",
        "print(f\"Mean of MSE over 50 runs: {mean_mse}\")\n",
        "print(f\"Standard Deviation of MSE over 50 runs: {std_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grkIfqkUbuxd",
        "outputId": "1d2b9749-c9c3-4d14-b520-2a639f17d478"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of MSE over 50 runs: 130.31662939683622\n",
            "Standard Deviation of MSE over 50 runs: 11.836501926494584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dwjSi0uQm6Jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean MSE:\n",
        "\n",
        "## The mean MSE for 50 epochs is 130.31662993683622.\n",
        "## The mean MSE for 100 epochs is 77.90864362902043.\n",
        "Observation: The MSE decreased significantly when increasing the number of epochs, indicating better performance and fitting of the model with more training iterations.\n",
        "# Standard Deviation of MSE:\n",
        "\n",
        "## For 50 epochs, the standard deviation is 11.836501926494584.\n",
        "## For 100 epochs, the standard deviation is 14.80209886276834.\n",
        "Observation: The slight increase in standard deviation suggests that the model's performance varies slightly more across the 50 runs at 100 epochs. This could be due to overfitting in some cases, depending on the complexity of the model and data."
      ],
      "metadata": {
        "id": "H0pmqa_G3HVi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KvdC83fU3OX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}